from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Set, Optional
import json, os, math, logging

logger = logging.getLogger(__name__)

@dataclass
class RuleCard:
    id: str
    topic: str
    tags: List[str]
    priority: float = 0.0
    trigger: Optional[str] = None
    mechanism: Optional[str] = None
    interpretation: Optional[str] = None
    action: Optional[str] = None
    cautions: Optional[List[str]] = None

TAG_NORMALIZE = {
    "ì •ì œ": "ì •ì¬",
    "í¸ì œ": "í¸ì¬",
    "ê²ì œ": "ê²ì¬",
    "ì‹ì‹ ìƒì œ": "ì‹ì‹ ìƒì¬",
    "ìƒê´€ìƒì œ": "ìƒê´€ìƒì¬",
    "ì‹ìƒìƒì œ": "ì‹ìƒìƒì¬",
    "ê°„ëª©": "ì¸ëª©",
    "ì‹ ì§€ê¸ˆ": "ì‹ ê¸ˆ",
}

def canon_tag(t: str) -> str:
    s = " ".join(str(t).strip().split())
    return TAG_NORMALIZE.get(s, s)

def explode_tag_tokens(t: str) -> List[str]:
    """
    ì¹´ë“œ íƒœê·¸ë¥¼ í† í°í™”í•´ì„œ ë§¤ì¹­ ì•ˆì •ì„±ì„ ë†’ì„.
    - "í˜„ê¸ˆ íë¦„" ê°™ì€ íƒœê·¸ê°€ ìˆìœ¼ë©´ ["í˜„ê¸ˆ íë¦„","í˜„ê¸ˆ","íë¦„"] ëª¨ë‘ë¡œ ì·¨ê¸‰
    """
    c = canon_tag(t)
    parts = [canon_tag(p) for p in c.split(" ") if len(p) >= 2]
    out, seen = [], set()
    for x in [c] + parts:
        if x and x not in seen:
            seen.add(x)
            out.append(x)
    return out

def safe_priority(p) -> float:
    try:
        v = float(p)
    except Exception:
        return 0.0
    # 0~10 or 0~100 ëª¨ë‘ ëŒ€ì‘
    return min(v, 10.0) if v <= 10 else min(v, 100.0) / 10.0

class RuleCardStore:
    """
    JSONL ë£°ì¹´ë“œ ë¡œë“œ + í† í”½ ì¸ë±ìŠ¤ + IDF(í¬ì†Œ íƒœê·¸ ê°€ì¤‘ì¹˜) ìƒì„±
    """
    def __init__(self, path: str):
        self.path = path
        self.cards: List[RuleCard] = []
        self.by_topic: Dict[str, List[RuleCard]] = {}
        self.idf: Dict[str, float] = {}

    def load(self) -> None:
        p = self.path
        if not os.path.exists(p):
            raise FileNotFoundError(f"Rulecards JSONL not found: {p}")

        cards: List[RuleCard] = []
        skipped_count = 0
        
        with open(p, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                except Exception as e:
                    logger.warning(f"[RuleCardStore] JSON íŒŒì‹± ì‹¤íŒ¨ (line {line_num}): {e}")
                    skipped_count += 1
                    continue

                # ğŸ”¥ í•„ìˆ˜ í•„ë“œ ì²´í¬ ì™„í™”: idì™€ topicë§Œ í•„ìˆ˜
                if not obj.get("id") or not obj.get("topic"):
                    logger.warning(f"[RuleCardStore] í•„ìˆ˜ í•„ë“œ ëˆ„ë½ (line {line_num}): id ë˜ëŠ” topic")
                    skipped_count += 1
                    continue
                
                # ğŸ”¥ tagsê°€ ì—†ìœ¼ë©´ triggerì—ì„œ ìë™ ìƒì„±
                tags = obj.get("tags", [])
                if not tags:
                    # triggerì—ì„œ ì¶”ì¶œ ì‹œë„
                    trigger = obj.get("trigger")
                    if trigger:
                        if isinstance(trigger, list):
                            tags = [str(t) for t in trigger if t]
                        elif isinstance(trigger, str):
                            try:
                                # JSON íŒŒì‹± ì‹œë„
                                parsed = json.loads(trigger)
                                if isinstance(parsed, list):
                                    tags = [str(t) for t in parsed if t]
                                elif isinstance(parsed, dict):
                                    # dictì˜ values ì¶”ì¶œ
                                    for v in parsed.values():
                                        if isinstance(v, list):
                                            tags.extend([str(t) for t in v if t])
                                        elif isinstance(v, str) and v:
                                            tags.append(v)
                            except:
                                # JSON ì•„ë‹ˆë©´ ë¬¸ìì—´ ê·¸ëŒ€ë¡œ
                                tags = [trigger]
                    
                    # interpretationì—ì„œë„ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
                    if not tags:
                        interp = obj.get("interpretation", "")
                        if interp and len(interp) > 0:
                            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (topicì„ íƒœê·¸ë¡œ)
                            tags = [obj.get("topic")]
                
                # ì—¬ì „íˆ tagsê°€ ì—†ìœ¼ë©´ topicì„ ê¸°ë³¸ íƒœê·¸ë¡œ
                if not tags:
                    tags = [obj.get("topic")]
                    logger.debug(f"[RuleCardStore] tags ìë™ ìƒì„± (line {line_num}): {tags}")

                cards.append(RuleCard(
                    id=obj["id"],
                    topic=obj["topic"],
                    tags=[canon_tag(x) for x in tags],
                    priority=safe_priority(obj.get("priority", 0)),
                    trigger=obj.get("trigger"),
                    mechanism=obj.get("mechanism"),
                    interpretation=obj.get("interpretation"),
                    action=obj.get("action"),
                    cautions=obj.get("cautions"),
                ))

        self.cards = cards
        self.by_topic = self._build_topic_index(cards)
        self.idf = self._build_idf(cards)
        
        # ğŸ”¥ ë¡œë“œ ê²°ê³¼ ë¡œê·¸
        logger.info(f"[RuleCardStore] âœ… ë¡œë“œ ì™„ë£Œ: {len(cards)}ì¥ (ìŠ¤í‚µ: {skipped_count}ì¥)")
        logger.info(f"[RuleCardStore] í† í”½ë³„: {', '.join([f'{k}:{len(v)}' for k, v in self.by_topic.items()])}")

    def _build_topic_index(self, cards: List[RuleCard]) -> Dict[str, List[RuleCard]]:
        m: Dict[str, List[RuleCard]] = {}
        for c in cards:
            m.setdefault(c.topic, []).append(c)
        for k in list(m.keys()):
            m[k].sort(key=lambda x: x.priority, reverse=True)
        return m

    def _build_idf(self, cards: List[RuleCard]) -> Dict[str, float]:
        df: Dict[str, int] = {}
        N = len(cards)
        for c in cards:
            token_set: Set[str] = set()
            for t in c.tags:
                for x in explode_tag_tokens(t):
                    token_set.add(x)
            for t in token_set:
                df[t] = df.get(t, 0) + 1

        idf: Dict[str, float] = {}
        for t, d in df.items():
            idf[t] = math.log((N + 1) / (d + 1)) + 1.0
        return idf
