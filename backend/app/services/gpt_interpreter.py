"""
gpt_interpreter.py
Used for "interpret" endpoint (short answer / Q&A style).
We inject Truth Anchor so the model cannot invent stems/ten-gods.
"""

from __future__ import annotations

import json
import logging
import os
from typing import Any, Dict, Optional

import httpx

from app.services.truth_anchor import build_truth_anchor

logger = logging.getLogger(__name__)


class GPTInterpreter:
    def __init__(
        self,
        *,
        model: Optional[str] = None,
        temperature: float = 0.2,
        max_tokens: int = 900,
        timeout: float = 45.0,
    ):
        self.model = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        self.temperature = float(temperature)
        self.max_tokens = int(max_tokens)
        self.timeout = float(timeout)

    def _build_prompt(self, saju_data: Dict[str, Any], question: str, target_year: Optional[int] = None) -> str:
        summary = saju_data.get("saju_summary") or {}
        summary_json = json.dumps(summary, ensure_ascii=False, indent=2)

        # ğŸ”¥ P0: ì˜¬ë°”ë¥¸ ì‹œê·¸ë‹ˆì²˜ë¡œ í˜¸ì¶œ
        truth_anchor = build_truth_anchor(
            saju_data=saju_data,
            target_year=target_year,
            section_id="interpret",
        )

        return f"""{truth_anchor}

## ğŸ”´ Ground Truth saju_summary - ì´ ë°ì´í„°ê°€ ì •ë‹µì´ë‹¤
{summary_json}

## ë‹µë³€ ê·œì¹™
- ì§ˆë¬¸ì— ëŒ€í•´ 'ë¹„ì¦ˆë‹ˆìŠ¤/ì‹¤í–‰' ê´€ì ìœ¼ë¡œ ë‹µí•´ë¼.
- ì›êµ­/ë£°ì¹´ë“œì— ì—†ëŠ” ì˜¤í–‰/ì‹­ì„±/ê²©êµ­ì„ ë§Œë“¤ì§€ ë§ˆë¼.
- ì¶”ë¡ (ì§€ì¥ê°„/ìˆ¨ì€ ì‹­ì„±) ê¸ˆì§€.
- 'ì¶”ê°€ ì •ë³´ í•„ìš”', 'ë¶„ì„ ë¶ˆê°€' ê°™ì€ ê±°ì ˆ ë¬¸êµ¬ ê¸ˆì§€.

## ì‚¬ìš©ì ì§ˆë¬¸
{question}
""".strip()

    async def _call_openai(self, prompt: str) -> str:
        api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_KEY") or ""
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY is missing")

        payload = {
            "model": self.model,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "messages": [
                {"role": "system", "content": prompt},
            ],
        }
        headers = {"Authorization": f"Bearer {api_key}"}
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            r = await client.post("https://api.openai.com/v1/chat/completions", json=payload, headers=headers)
            r.raise_for_status()
            data = r.json()
            return (data["choices"][0]["message"]["content"] or "").strip()

    async def interpret(self, saju_data: Dict[str, Any], question: str, target_year: Optional[int] = None) -> str:
        prompt = self._build_prompt(saju_data, question, target_year=target_year)
        try:
            return await self._call_openai(prompt)
        except Exception as e:
            logger.error(f"[Interpreter] OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return f"[í•´ì„ ìƒì„± ì˜¤ë¥˜: {str(e)[:100]}]"


gpt_interpreter = GPTInterpreter()

__all__ = ["GPTInterpreter", "gpt_interpreter"]
