"""
report_worker.py
Background worker that generates premium report sections.

P0 fixes included:
- _ensure_dict(): Supabase JSON fields can arrive as strings
- daeun_direction reference bug fixed (read from saju_data)
- LLM quality guardrails + retry
- Forbidden rulecard physical filtering
- Output normalization for known typos (Í±∏Î°ù->Í±¥Î°ù etc)
"""

from __future__ import annotations

import json
import re
import time
from typing import Any, Dict, List, Optional, Tuple

from app.services.report_builder import PREMIUM_SECTIONS, premium_report_builder
from app.services.rulecard_scorer import RuleCardScorer
from app.services.supabase_service import SupabaseService
from app.services.truth_anchor import forbidden_words_for_rulecards

try:
    from app.services.saju_analyzer import get_saju_summary  # optional but recommended
except Exception:  # pragma: no cover
    get_saju_summary = None  # type: ignore


# -----------------------------
# Helpers
# -----------------------------

def _ensure_dict(v: Any) -> Dict[str, Any]:
    """Supabase/ÌîÑÎ°†Ìä∏ÏóêÏÑú JSONÏù¥ Î¨∏ÏûêÏó¥Î°ú Ïò¨ Îïå dictÎ°ú ÏïàÏ†Ñ Î≥ÄÌôò"""
    if isinstance(v, dict):
        return v
    if isinstance(v, str):
        try:
            vv = json.loads(v)
            return vv if isinstance(vv, dict) else {}
        except Exception:
            return {}
    return {}

def _ensure_list(v: Any) -> List[Any]:
    if isinstance(v, list):
        return v
    if isinstance(v, str):
        try:
            vv = json.loads(v)
            return vv if isinstance(vv, list) else []
        except Exception:
            return []
    return []

_NORMALIZE_REPLACEMENTS = {
    "Í±∏Î°ùÍ≤©": "Í±¥Î°ùÍ≤©",
    "Í±∏Î°ù": "Í±¥Î°ù",
}

def _normalize_text(s: str) -> str:
    out = s or ""
    for a, b in _NORMALIZE_REPLACEMENTS.items():
        out = out.replace(a, b)
    return out


# -----------------------------
# Worker
# -----------------------------

class ReportWorker:
    def __init__(self):
        self.supabase = SupabaseService()
        self.scorer = RuleCardScorer()

    async def process(self, job_id: str) -> Tuple[bool, str]:
        started = time.time()
        try:
            ok, msg = await self._execute_job(job_id)
            return ok, msg
        finally:
            _ = time.time() - started

    # -----------------------------------------------------------------
    # Backward-compat alias
    # reports.py / Í∏∞Ï°¥ ÏΩîÎìúÍ∞Ä run_job(...)ÏùÑ Ìò∏Ï∂úÌïòÎäî Í≤ΩÏö∞Í∞Ä ÏûàÏñ¥ aliasÎ•º Ïú†ÏßÄÌï©ÎãàÎã§.
    # -----------------------------------------------------------------
    async def run_job(self, job_id: str, rulestore: Any = None) -> Tuple[bool, str]:
        """Backward compatible entrypoint (alias of process)."""
        # rulestoreÎäî legacy signature Ìò∏ÌôòÏö©(ÌòÑÏû¨Îäî ÎÇ¥Î∂ÄÏóêÏÑú self.scorerÎ•º ÏÇ¨Ïö©)
        return await self.process(job_id)

    async def _execute_job(self, job_id: str, rulestore: Any = None) -> Tuple[bool, str]:
        job = await self.supabase.get_job(job_id)
        if not job:
            return False, f"job not found: {job_id}"

        # P0: Supabase JSON columns can be string
        input_json = _ensure_dict(job.get("input_json") or job.get("input_data") or {})
        survey_data = _ensure_dict(input_json.get("survey_data") or input_json.get("survey") or {})

        # saju_data
        saju_data = self._prepare_saju_data(input_json)
        self._assert_required_saju(saju_data)

        # enrich saju_summary (P0)
        if get_saju_summary is not None and not saju_data.get("saju_summary"):
            try:
                saju_summary = get_saju_summary(saju_data)  # type: ignore
                saju_data["saju_summary"] = saju_summary
                saju_data["ten_gods_present"] = saju_summary.get("ten_gods_present", [])
                saju_data["has_wealth_star"] = saju_summary.get("has_wealth_star", False)
            except Exception as e:
                # don't fail job for summary; just log-friendly string
                print(f"[Worker] saju_summary ÏÉùÏÑ± Ïã§Ìå®: {e}")

        target_year = int(input_json.get("target_year") or survey_data.get("target_year") or time.gmtime().tm_year)

        # sections to generate (use PREMIUM_SECTIONS order)
        section_ids = list(PREMIUM_SECTIONS.keys())

        all_used_card_ids: List[str] = []
        existing_contents: List[str] = []
        failed_sections: List[Dict[str, Any]] = []

        # all cards from rulestore or scorer store
        all_cards = rulestore.cards if rulestore and hasattr(rulestore, "cards") else None
        if all_cards is None:
            all_cards = await self.scorer.get_all_cards()  # type: ignore

        used_ids: set = set()

        for idx, section_id in enumerate(section_ids, start=1):
            spec = PREMIUM_SECTIONS.get(section_id)
            min_chars = spec.min_chars if spec else 800

            # Select rulecards for section (with physical filtering)
            rulecards = self._select_rulecards_for_section(
                all_cards=all_cards,
                section_id=section_id,
                survey_data=survey_data,
                saju_data=saju_data,
                used_ids=used_ids,
                k=100,
            )
            for c in rulecards:
                cid = c.get("id")
                if cid:
                    used_ids.add(cid)

            MAX_RETRIES = 2
            last_result: Optional[Dict[str, Any]] = None
            guardrail_errors: List[str] = []
            quality_warning = False

            for attempt in range(MAX_RETRIES):
                result = await premium_report_builder.regenerate_single_section(
                    section_id,
                    saju_data,
                    rulecards,
                    survey_data,
                    target_year,
                    user_question=input_json.get("user_question") or "",
                    existing_contents=existing_contents[-3:],
                    job_id=job_id,
                )
                body = _normalize_text(result.get("body_markdown", ""))

                issues = self._check_llm_quality(body, target_year, saju_data, min_chars=min_chars)
                if issues:
                    guardrail_errors = issues
                    if attempt < MAX_RETRIES - 1:
                        print(f"[Worker] ÏÑπÏÖò {section_id} ÌíàÏßà Ïù¥Ïäà: {issues} -> Ïû¨ÏãúÎèÑ")
                        continue
                    # last attempt: store but mark warning
                    quality_warning = True

                result["body_markdown"] = body
                result["guardrail_violations"] = issues
                last_result = result
                break

            if not last_result:
                failed_sections.append({"section_id": section_id, "error": "LLM_GENERATION_FAILED"})
                continue

            # save section
            await self.supabase.save_section(job_id, section_id, last_result)
            existing_contents.append(last_result.get("body_markdown", "")[:1200])

            # collect ids
            all_used_card_ids.extend(last_result.get("used_rulecard_ids", []) or [])

            if quality_warning:
                print(f"[Worker] ÏÑπÏÖò {section_id} ÌíàÏßà Í≤ΩÍ≥†: {guardrail_errors}")

            # progress update
            await self.supabase.update_progress(job_id, idx, len(section_ids))

        # finalize job
        if failed_sections:
            await self.supabase.fail_job(job_id, f"FAILED_SECTIONS: {failed_sections}")
            return False, f"failed sections: {[x['section_id'] for x in failed_sections]}"

        # saju_json creation (P0: daeun_direction bug fix)
        saju_json = {
            "year_pillar": saju_data.get("year_pillar", ""),
            "month_pillar": saju_data.get("month_pillar", ""),
            "day_pillar": saju_data.get("day_pillar", ""),
            "hour_pillar": saju_data.get("hour_pillar", ""),
            "day_master": saju_data.get("day_master", ""),
            "day_master_element": saju_data.get("day_master_element", ""),
            "daeun_direction": saju_data.get("daeun_direction"),
            "current_daeun": saju_data.get("current_daeun"),
            "feature_tags": input_json.get("feature_tags") or [],
            "rulecards_used": all_used_card_ids[:20],
            "survey_data": survey_data,
            "calculated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        }

        await self.supabase.complete_job(job_id, saju_json=saju_json)
        return True, "ok"

    # -------------------------
    # Saju handling
    # -------------------------

    def _prepare_saju_data(self, input_json: Dict[str, Any]) -> Dict[str, Any]:
        """ÏÇ¨Ï£º Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ - Îã§ÏñëÌïú Í≤ΩÎ°úÏóêÏÑú pillar Ï∂îÏ∂ú"""
        # saju_result can be nested JSON string
        saju_result = _ensure_dict(input_json.get("saju_result") or input_json.get("saju") or {})
        
        # üî• P0: nested saju Íµ¨Ï°∞ ÏßÄÏõê (calculate API ÏùëÎãµ Íµ¨Ï°∞)
        nested_saju = _ensure_dict(saju_result.get("saju") or {})
        
        def _extract_ganji(pillar_data) -> str:
            """pillarÍ∞Ä dictÎ©¥ ganji Ï∂îÏ∂ú, ÏïÑÎãàÎ©¥ Í∑∏ÎåÄÎ°ú Î∞òÌôò"""
            if not pillar_data:
                return ""
            if isinstance(pillar_data, dict):
                return pillar_data.get("ganji", "") or pillar_data.get("value", "") or ""
            return str(pillar_data) if pillar_data else ""
        
        # üî• P0: 3Îã®Í≥Ñ fallback Ï≤¥Ïù∏
        # 1) saju_result.saju.year_pillar (calculate API Íµ¨Ï°∞)
        # 2) saju_result.year_pillar (ÏßÅÏ†ë Ï†ëÍ∑º)
        # 3) input_json.year_pillar (top-level)
        year_pillar = _extract_ganji(nested_saju.get("year_pillar")) or _extract_ganji(saju_result.get("year_pillar")) or _extract_ganji(input_json.get("year_pillar"))
        month_pillar = _extract_ganji(nested_saju.get("month_pillar")) or _extract_ganji(saju_result.get("month_pillar")) or _extract_ganji(input_json.get("month_pillar"))
        day_pillar = _extract_ganji(nested_saju.get("day_pillar")) or _extract_ganji(saju_result.get("day_pillar")) or _extract_ganji(input_json.get("day_pillar"))
        hour_pillar = _extract_ganji(nested_saju.get("hour_pillar")) or _extract_ganji(saju_result.get("hour_pillar")) or _extract_ganji(input_json.get("hour_pillar"))
        
        # day_masterÎèÑ Îã§ÏñëÌïú Í≤ΩÎ°ú ÏßÄÏõê
        day_master = saju_result.get("day_master") or input_json.get("day_master") or (day_pillar[0] if day_pillar else "")
        
        logger.info(f"[Worker] üîç Ï∂îÏ∂úÎêú 4Ï£º: ÎÖÑ={year_pillar} Ïõî={month_pillar} Ïùº={day_pillar} Ïãú={hour_pillar}")
        
        saju_data = {
            "year_pillar": year_pillar,
            "month_pillar": month_pillar,
            "day_pillar": day_pillar,
            "hour_pillar": hour_pillar,
            "day_master": day_master,
            "day_master_element": saju_result.get("day_master_element") or input_json.get("day_master_element"),
            "daeun_direction": saju_result.get("daeun_direction") or input_json.get("daeun_direction"),
            "current_daeun": saju_result.get("current_daeun") or input_json.get("current_daeun"),
            "primary_structure": saju_result.get("primary_structure") or input_json.get("primary_structure"),
            "month_tengod": saju_result.get("month_tengod") or input_json.get("month_tengod"),
            "saju_summary": saju_result.get("saju_summary") or input_json.get("saju_summary"),
        }
        # include summary passthrough fields
        saju_data["ten_gods_present"] = saju_result.get("ten_gods_present") or input_json.get("ten_gods_present") or []
        saju_data["has_wealth_star"] = saju_result.get("has_wealth_star") or input_json.get("has_wealth_star") or False
        return saju_data

    def _assert_required_saju(self, saju_data: Dict[str, Any]) -> None:
        missing = [k for k in ("year_pillar", "month_pillar", "day_pillar") if not saju_data.get(k)]
        if missing:
            raise ValueError(f"ÏÇ¨Ï£º Îç∞Ïù¥ÌÑ∞ ÎàÑÎùΩ: {missing}.")

    # -------------------------
    # RuleCard selection + filtering
    # -------------------------

    def _select_rulecards_for_section(
        self,
        *,
        all_cards: List[Dict[str, Any]],
        section_id: str,
        survey_data: Dict[str, Any],
        saju_data: Dict[str, Any],
        used_ids: set,
        k: int = 100,
    ) -> List[Dict[str, Any]]:
        # P0: physical filter to remove hallucination-prone cards
        forbidden = forbidden_words_for_rulecards()

        filtered: List[Dict[str, Any]] = []
        for c in all_cards:
            cid = c.get("id")
            if cid and cid in used_ids:
                continue
            blob = f"{c.get('trigger_json','')} {c.get('mechanism','')} {c.get('interpretation','')} {c.get('action','')} {c.get('tags_json','')} {c.get('cautions_json','')}"
            if any(w in blob for w in forbidden):
                continue
            filtered.append(c)

        # score
        scored = self.scorer.score_cards_for_section(filtered, section_id, survey_data, saju_data, k=k)
        return scored

    # -------------------------
    # LLM quality guardrail
    # -------------------------

    def _check_llm_quality(
        self,
        body_markdown: str,
        target_year: int,
        saju_data: Dict[str, Any],
        *,
        min_chars: int = 800,
    ) -> List[str]:
        issues: List[str] = []
        s = body_markdown or ""

        # meta refusal
        refusal_patterns = ["Ï£ÑÏÜ°ÌïòÏßÄÎßå", "Î∂ÑÏÑùÌï† Ïàò ÏóÜ", "Ï∂îÍ∞Ä Ï†ïÎ≥¥Í∞Ä ÌïÑÏöî", "Ï†úÍ≥µÌï¥ Ï£ºÏãúÎ©¥", "cannot", "I can't"]
        for p in refusal_patterns:
            if p in s:
                issues.append(f"Í±∞Ï†àÎ¨∏Íµ¨:{p}")
                break

        # year sanity: don't drift heavily to previous year
        if str(target_year) in s:
            pass
        else:
            # allow missing but if mentions target_year-1 a lot, flag
            prev = str(target_year - 1)
            if prev in s and s.count(prev) >= 3:
                issues.append(f"Ïó∞ÎèÑÏò§Î•ò:{prev} Ïñ∏Í∏âÍ≥ºÎã§")

        # length
        if len(s) < int(min_chars):
            issues.append(f"Í∏∏Ïù¥Î∂ÄÏ°±:{len(s)}<{min_chars}")

        # hallucinated ten-gods check (simple keyword scan)
        summary = saju_data.get("saju_summary") or {}
        present = set(summary.get("ten_gods_present") or [])
        if present:
            all_tengods = ["ÎπÑÍ≤¨","Í≤ÅÏû¨","ÏãùÏã†","ÏÉÅÍ¥Ä","Ï†ïÏû¨","Ìé∏Ïû¨","Ï†ïÍ¥Ä","Ìé∏Í¥Ä","Ï†ïÏù∏","Ìé∏Ïù∏"]
            mentioned = {tg for tg in all_tengods if tg in s}
            halluc = sorted(list(mentioned - present))
            if halluc:
                issues.append(f"ÌôòÍ∞ÅÏã≠ÏÑ±:{halluc}")

        return issues


report_worker = ReportWorker()

__all__ = ["ReportWorker", "report_worker"]
