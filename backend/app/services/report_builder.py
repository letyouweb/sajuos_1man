"""
SajuOS Premium Report Builder v12 - P0 ë¹ˆ ì„¹ì…˜ ì ˆëŒ€ ê¸ˆì§€
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¥ P0-1: ì¹´ë“œ 0ê°œ â†’ LLM í˜¸ì¶œ X, í´ë°± í…ìŠ¤íŠ¸ ì¦‰ì‹œ ë°˜í™˜
ğŸ”¥ P0-2: ì„¹ì…˜ ID ì •í•©ì„± (exec,money,business,team,health,calendar,sprint)
ğŸ”¥ P0-3: í† í° "ì¹˜í™˜" (ì‚­ì œ X) - {industry}â†’"í•´ë‹¹ ì—…ì¢…"
ğŸ”¥ P0-4: ìƒì„± ì‹¤íŒ¨ ì›ì¸ ë¡œê·¸ 4ê°œ í•„ìˆ˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
import asyncio
import logging
import re
from typing import Dict, Any, List
from dataclasses import dataclass, field

from openai import AsyncOpenAI
import httpx

from app.config import get_settings
from app.services.openai_key import get_openai_api_key
from app.services.terminology_mapper import sanitize_for_business
from app.services.job_store import job_store
from app.templates.master_samples import load_master_samples, get_master_body_markdown

logger = logging.getLogger(__name__)

MASTER_SAMPLES = load_master_samples("v1")

DEBUG_TEMPLATE_LEAKS = False


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# P0-3: í† í° ì¹˜í™˜ (ì‚­ì œ X)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

TOKEN_REPLACEMENTS = {
    "{industry}": "í•´ë‹¹ ì—…ì¢…",
    "{painPoint}": "í˜„ì¬ ë³‘ëª©",
    "{engine_headline}": "í•µì‹¬ ê²°ë¡ ",
    "{goal}": "ëª©í‘œ",
    "{revenue}": "ë§¤ì¶œ",
    "{day_master}": "ì¼ê°„",
    "{time}": "ì‹œì ",
    "[ENGINE_HEADLINE]": "",
    "[/ENGINE_HEADLINE]": "",
}


def replace_template_tokens(text: str) -> str:
    """ğŸ”¥ P0-3: í† í° ì¹˜í™˜ (ì‚­ì œê°€ ì•„ë‹Œ ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´)"""
    if not text:
        return ""
    if DEBUG_TEMPLATE_LEAKS:
        return text.strip()
    for token, replacement in TOKEN_REPLACEMENTS.items():
        text = text.replace(token, replacement)
    text = re.sub(r"\{[a-zA-Z_]+\}", "í•´ë‹¹ í•­ëª©", text)
    return text.strip()


def check_template_leaks(text: str, context: str = "") -> List[str]:
    if not text:
        return []
    leaked = []
    for token in TOKEN_REPLACEMENTS.keys():
        if token in text:
            leaked.append(token)
    if re.search(r"\{[a-zA-Z_]+\}", text):
        leaked.append("{other}")
    if leaked:
        logger.warning(f"[TemplateLeak] {context} | leaked: {leaked}")
    return leaked


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# P0-2: ì„¹ì…˜ ID ì •í•©ì„± (ê¸°ì¡´ ID ìœ ì§€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class SectionSpec:
    id: str
    title: str
    max_cards: int
    min_chars: int
    fallback_headline: str
    topic_filter: List[str] = field(default_factory=list)


# ğŸ”¥ P0-2: í•©ì˜ëœ section_id ê³ ì • (exec, money, business, team, health, calendar, sprint)
PREMIUM_SECTIONS = {
    "exec": SectionSpec(
        "exec", "2026 ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ê¸°ìƒë„", 20, 1500,
        "í˜„ì¬ ì‚¬ì£¼ êµ¬ì¡°ìƒ 2026ë…„ ë¹„ì¦ˆë‹ˆìŠ¤ í™˜ê²½ì€ ë³€í™”ì˜ ê¸°ìš´ì´ ê°ì§€ë©ë‹ˆë‹¤",
        topic_filter=["ì „ì²´ìš´", "ì¢…í•©", "ì¼ê°„", "ì„±í–¥", "ê¸°ìš´", "ìš´ì„¸"]
    ),
    "money": SectionSpec(
        "money", "ìë³¸ ìœ ë™ì„± ë° í˜„ê¸ˆíë¦„ ìµœì í™”", 20, 2500,
        "í˜„ì¬ êµ¬ì¡°ìƒ í˜„ê¸ˆíë¦„ì˜ ë³€ë™ì„±ì´ ì˜ˆìƒë©ë‹ˆë‹¤",
        topic_filter=["ì¬ë¬¼", "ì¬ì„±", "ì •ì¬", "í¸ì¬", "í˜„ê¸ˆ", "ë§¤ì¶œ", "íˆ¬ì"]
    ),
    "business": SectionSpec(
        "business", "ì‹œì¥ í¬ì§€ì…”ë‹ ë° ìƒí’ˆ í™•ì¥ ì „ëµ", 20, 2500,
        "í˜„ì¬ êµ¬ì¡°ìƒ ì‹œì¥ í¬ì§€ì…”ë‹ ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤",
        topic_filter=["ì‚¬ì—…", "ì°½ì—…", "ê²½ì˜", "ê´€ì„±", "ì •ê´€", "í¸ê´€", "ì‹œì¥"]
    ),
    "team": SectionSpec(
        "team", "ì¡°ì§ í™•ì¥ ë° íŒŒíŠ¸ë„ˆì‹­ ê°€ì´ë“œ", 20, 2000,
        "í˜„ì¬ êµ¬ì¡°ìƒ íŒŒíŠ¸ë„ˆì‹­ ê´€ë¦¬ê°€ í•µì‹¬ ê³¼ì œì…ë‹ˆë‹¤",
        topic_filter=["ë¹„ê²", "ë¹„ê²¬", "ê²ì¬", "ë™ì—…", "íŒŒíŠ¸ë„ˆ", "í˜‘ë ¥", "ì¸ë§¥"]
    ),
    "health": SectionSpec(
        "health", "ì£¼ìš” ì¥ì• ë¬¼ ë° ë¦¬ìŠ¤í¬ (2026)", 15, 1500,
        "í˜„ì¬ êµ¬ì¡°ìƒ í•´ë‹¹ ë¦¬ìŠ¤í¬ëŠ” ë‚®ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤",
        topic_filter=["ë¦¬ìŠ¤í¬", "ìœ„í—˜", "ì¶©", "í˜•", "íŒŒ", "ì†í•´", "ì¥ì• ", "ë²ˆì•„ì›ƒ"]
    ),
    "calendar": SectionSpec(
        "calendar", "12ê°œì›” ë¹„ì¦ˆë‹ˆìŠ¤ ìŠ¤í”„ë¦°íŠ¸ ìº˜ë¦°ë”", 15, 2500,
        "í˜„ì¬ êµ¬ì¡°ìƒ ì›”ë³„ ë¦¬ë“¬ì— ë§ì¶˜ ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤",
        topic_filter=["ì›”ìš´", "ì‹œê¸°", "ê³„ì ˆ", "íƒ€ì´ë°", "ê¸¸ì¼", "í‰ì¼", "ëŒ€ìš´"]
    ),
    "sprint": SectionSpec(
        "sprint", "í–¥í›„ 90ì¼ ë§¤ì¶œ ê·¹ëŒ€í™” ì•¡ì…˜í”Œëœ", 15, 2000,
        "í˜„ì¬ êµ¬ì¡°ìƒ 90ì¼ ì§‘ì¤‘ ì‹¤í–‰ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤",
        topic_filter=["ì‹¤í–‰", "ì•¡ì…˜", "ê³„íš", "ëª©í‘œ", "ì‹ì‹ ", "ìƒê´€", "ì‹ìƒ"]
    ),
}


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# P0-1: í´ë°± í…ìŠ¤íŠ¸ (ë¹ˆ ì„¹ì…˜ ë°©ì§€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def generate_fallback_body(section_id: str, engine_headline: str, survey_data: Dict = None) -> str:
    """ğŸ”¥ P0-1: ì¹´ë“œ 0ê°œ ë˜ëŠ” LLM ì‹¤íŒ¨ ì‹œ í´ë°± í…ìŠ¤íŠ¸"""
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        spec = SectionSpec(section_id, "ì„¹ì…˜", 10, 500, "ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤")
    
    headline = engine_headline if engine_headline else spec.fallback_headline
    industry = (survey_data or {}).get("industry", "í•´ë‹¹ ì—…ì¢…")
    painPoint = (survey_data or {}).get("painPoint", "í˜„ì¬ ë³‘ëª©")
    
    return f"""{headline}

## í˜„ì¬ ìƒí™© ë¶„ì„

ì›ì¸(ì‚¬ì£¼/ë£°ì¹´ë“œ) ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ìƒì„¸ ë¶„ì„ì´ ì œí•œë©ë‹ˆë‹¤.
ì„¤ë¬¸ìœ¼ë¡œë§Œ ì–µì§€ ì¶”ë¡ í•˜ëŠ” ê²ƒì€ Root Cause Rule ìœ„ë°˜ì´ë¯€ë¡œ ìƒëµí•©ë‹ˆë‹¤.

### ë‹¤ìŒ í–‰ë™ ê¶Œì¥ì‚¬í•­

1. **D+14**: {industry} ì—…ì¢… í˜„í™© ì ê²€ ë° ë°ì´í„° ìˆ˜ì§‘
2. **D+30**: {painPoint} ê´€ë ¨ í•µì‹¬ ì§€í‘œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
3. **D+60**: ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ ì „ëµ ì¬ìˆ˜ë¦½

### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] í˜„ì¬ ìƒí™© ê°ê´€ì  ì§„ë‹¨
- [ ] í•µì‹¬ ì§€í‘œ ì •ì˜
- [ ] ë°ì´í„° ìˆ˜ì§‘ ì²´ê³„ êµ¬ì¶•
- [ ] ì£¼ê°„ ë¦¬ë·° ì¼ì • í™•ì •
- [ ] ì „ë¬¸ê°€ ìƒë‹´ ê²€í† 

---
*ì¶”ê°€ ì‚¬ì£¼ ì •ë³´ë‚˜ ë£°ì¹´ë“œ ë§¤ì¹­ì´ í™•ë³´ë˜ë©´ ë” ì •ë°€í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.*
"""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë°ì´í„° êµ¬ì¡°
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class SectionRuleCardAllocation:
    section_id: str
    allocated_count: int
    allocated_card_ids: List[str]
    context_text: str
    cards: List[Dict[str, Any]] = field(default_factory=list)


def score_card_for_section(card: Dict, section_id: str, survey_data: Dict = None) -> float:
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        return 1.0
    score = 1.0
    topic = (card.get("topic") or "").lower()
    mechanism = (card.get("mechanism") or "").lower()
    tags = " ".join(card.get("tags") or []).lower()
    card_text = f"{topic} {mechanism} {tags}"
    for tf in spec.topic_filter:
        if tf.lower() in card_text:
            score += 3.0
    if survey_data:
        pain = (survey_data.get("painPoint") or "").lower()
        pain_tags = {"lead": ["ì¸ë§¥", "ê·€ì¸"], "retention": ["ë¹„ê²", "ë¹„ê²¬"], "conversion": ["ì¬ì„±", "ì •ì¬"], "funding": ["ì¬ì„±", "íˆ¬ì"]}
        for tag in pain_tags.get(pain, []):
            if tag.lower() in card_text:
                score += 2.0
    return score


def allocate_rulecards_to_section(all_cards: List[Dict], section_id: str, max_cards: int, used_ids: set, survey_data: Dict = None) -> SectionRuleCardAllocation:
    scored = []
    for card in all_cards:
        cid = card.get("id", card.get("_id", ""))
        if cid in used_ids:
            continue
        score = score_card_for_section(card, section_id, survey_data)
        scored.append((score, card))
    scored.sort(key=lambda x: x[0], reverse=True)
    
    filtered = [(s, c) for s, c in scored if s > 1.0]
    if not filtered:
        logger.warning(f"[CardAlloc] section={section_id} topic_filter hit=0 â†’ fallback")
        if scored:
            filtered = scored[:max_cards]
        elif all_cards:
            fallback = [c for c in all_cards if c.get("id", c.get("_id", "")) not in used_ids][:max_cards]
            filtered = [(1.0, c) for c in fallback]
    
    allocated = [card for _, card in filtered[:max_cards]]
    ids, lines = [], []
    for card in allocated:
        cid = card.get("id", card.get("_id", ""))
        ids.append(cid)
        interp = sanitize_for_business((card.get("interpretation") or "")[:200])
        lines.append(f"[{cid}] {card.get('topic', '')} | {interp}")
    
    logger.info(f"[CardAlloc] section={section_id} | scored={len(scored)} | filtered={len(filtered)} | allocated={len(ids)}")
    return SectionRuleCardAllocation(section_id, len(ids), ids, "\n".join(lines), allocated)


def extract_engine_headline(cards: List[Dict]) -> str:
    if not cards:
        return ""
    top_card = cards[0]
    interp = top_card.get("interpretation") or top_card.get("content", {}).get("interpretation", "") or top_card.get("mechanism") or ""
    interp = sanitize_for_business(interp)
    sentences = re.split(r"[.ã€‚!?]", interp)
    first = sentences[0].strip() if sentences else interp[:100]
    first = re.sub(r"\{[a-zA-Z_]+\}", "", first)
    return first if first else interp[:100]


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í”„ë¡¬í”„íŠ¸
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ROOT_CAUSE_RULE = """## ğŸ§  Root Cause Rule (ì ˆëŒ€ê·œì¹™)
- ì‚¬ì£¼/ë£°ì¹´ë“œ(=ì›ì¸)ê°€ ê²°ë¡ ì´ë‹¤. ì„¤ë¬¸(=ì¦ìƒ)ì€ ê²°ë¡ ì´ ì•„ë‹ˆë‹¤.
- ì„¹ì…˜ì˜ ì²« ë¬¸ì¥ì€ ë°˜ë“œì‹œ ì—”ì§„ì´ í™•ì •í•œ ê²°ë¡ ìœ¼ë¡œ ì‹œì‘í•œë‹¤.
- ê¸ˆì§€: "ê³ ê°ë‹˜ì´ ì„¤ë¬¸ì—ì„œ ~ë¼ê³  í•˜ì…¨ìœ¼ë‹ˆ" ê°™ì€ ì„œìˆ .
"""




TENGOD_ORDER = ["ë¹„ê²¬","ê²ì¬","ì‹ì‹ ","ìƒê´€","í¸ì¬","ì •ì¬","í¸ê´€","ì •ê´€","í¸ì¸","ì •ì¸"]


def build_fact_check_context(saju_data: Dict[str, Any]) -> str:
    yp = saju_data.get("year_pillar","")
    mp = saju_data.get("month_pillar","")
    dp = saju_data.get("day_pillar","")
    hp = saju_data.get("hour_pillar","")
    dm = saju_data.get("day_master","")
    gender = saju_data.get("gender","")
    age = saju_data.get("age",0)
    cur = saju_data.get("current_daeun","")
    direction = saju_data.get("daeun_direction","")
    tg = saju_data.get("ten_gods_present") or []
    dtg = saju_data.get("daeun_ten_gods") or []
    elems = saju_data.get("elements_present") or []
    has_wealth = bool(saju_data.get("has_wealth_star"))

    def _fmt(xs, order=None):
        if not xs:
            return "(ì—†ìŒ)"
        if order:
            xs = [x for x in order if x in set(xs)] + [x for x in xs if x not in set(order)]
        return ", ".join(xs)

    return (
        "## ğŸš¨ ì›êµ­ íŒ©íŠ¸ì²´í¬ (ì ˆëŒ€ ì¤€ìˆ˜)\n"
        f"- ì›êµ­(4ì£¼): {yp} {mp} {dp} {hp}\n"
        f"- ì¼ê°„: {dm}\n"
        f"- ì„±ë³„/ë§Œë‚˜ì´: {gender} / {age}\n"
        f"- í˜„ì¬ ëŒ€ìš´: {cur} (ë°©í–¥={direction})\n"
        f"- ì›êµ­ ì‹­ì„±(ì²œê°„+ì§€ì¥ê°„): {_fmt(tg, TENGOD_ORDER)}\n"
        f"- í˜„ì¬ëŒ€ìš´ ì‹­ì„±: {_fmt(dtg, TENGOD_ORDER)}\n"
        f"- ì˜¤í–‰: {_fmt(elems)}\n"
        f"- ì¬ì„±(ì •ì¬/í¸ì¬) ì›êµ­ ì¡´ì¬: {'ìˆìŒ' if has_wealth else 'ì—†ìŒ'}\n\n"
        "### ê¸ˆì§€ ê·œì¹™\n"
        "1) ìœ„ 'ì›êµ­ ì‹­ì„±'ì— ì—†ëŠ” ì‹­ì„±ì„ 'ìˆë‹¤'ê³  ë‹¨ì •í•˜ì§€ ë§ˆë¼.\n"
        "2) ì¬ì„±ì´ ì›êµ­ì— ì—†ìœ¼ë©´ 'ì •ì¬/í¸ì¬ê°€ ìˆë‹¤'ë¼ê³  ë§í•˜ì§€ ë§ˆë¼.\n"
        "3) ëŒ€ìš´ ë³€í™”ëŠ” ë°˜ë“œì‹œ 'ëŒ€ìš´ì—ì„œ ë“¤ì–´ì˜¨ë‹¤'ë¡œ ì›êµ­ê³¼ êµ¬ë¶„í•´ì„œ ë§í•´ë¼.\n"
    )
def build_system_prompt(section_id: str, engine_headline: str, survey_data: Dict = None, saju_data: Dict = None, existing_contents: List[str] = None, cards_summary: str = "") -> str:
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        logger.error(f"[Builder] Invalid section_id: {section_id}")
        return ""
    title = spec.title
    min_chars = spec.min_chars
    master_body = get_master_body_markdown(section_id)
    industry = (survey_data or {}).get("industry", "") or "ë¯¸ì…ë ¥"
    painPoint = (survey_data or {}).get("painPoint", "") or "ë¯¸ì…ë ¥"
    businessGoal = (survey_data or {}).get("businessGoal", "") or "ë¯¸ì…ë ¥"
    survey_context = f"\n## ì„¤ë¬¸ (ì¦ìƒ)\n- ì—…ì¢…: {industry}\n- ê³ ë¯¼: {painPoint}\n- ëª©í‘œ: {businessGoal}\n"
    existing_block = ""
    if existing_contents:
        existing_block = f"\n## ì´ì „ ì„¹ì…˜ (ë°˜ë³µ ê¸ˆì§€)\n{chr(10).join(existing_contents[-2:])}\n"
    
    # ğŸ”¥ P0: ì›êµ­ íŒ©íŠ¸ ì²´í¬ ë¸”ë¡ ì¶”ê°€
    fact_ctx = build_fact_check_context(saju_data or {})
    
    return f"""ë„ˆëŠ” [{title}] ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ë‹¤.

{ROOT_CAUSE_RULE}
{fact_ctx}

## ì²« ë¬¸ì¥ (ìˆ˜ì • ê¸ˆì§€)
"{engine_headline}"

## ë§ˆìŠ¤í„° ìƒ˜í”Œ
{master_body if master_body else '(ììœ  ì‘ì„±)'}

## ë£°ì¹´ë“œ
{cards_summary if cards_summary else '(ì—†ìŒ)'}
{survey_context}
{existing_block}

## ê·œì¹™
1) ì²« ë¬¸ì¥: ìœ„ ì—”ì§„ ê²°ë¡ ìœ¼ë¡œ ì‹œì‘
2) ë¦¬ìŠ¤í¬ 2ê°œ, ì•¡ì…˜ 3ê°œ, ì²´í¬ë¦¬ìŠ¤íŠ¸ 7ê°œ
3) ìµœì†Œ {min_chars}ì, í•œêµ­ì–´ë¡œë§Œ
"""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë¹Œë” í´ë˜ìŠ¤
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class PremiumReportBuilder:
    def __init__(self):
        self._client = None
        self._semaphore = None
    
    def _get_client(self) -> AsyncOpenAI:
        api_key = get_openai_api_key()
        return AsyncOpenAI(api_key=api_key, timeout=httpx.Timeout(120.0, connect=15.0), max_retries=2)
    
    async def build_premium_report(self, saju_data: Dict, rulecards: List[Dict], feature_tags: List[str] = None, target_year: int = 2026, user_question: str = "", name: str = "ê³ ê°", job_id: str = None, survey_data: Dict = None, mode: str = "premium"):
        self._semaphore = asyncio.Semaphore(2)
        self._client = self._get_client()
        if job_id:
            await job_store.start_job(job_id)
        
        used_card_ids = set()
        results = []
        existing_contents = []
        
        for sid in PREMIUM_SECTIONS.keys():
            spec = PREMIUM_SECTIONS[sid]
            alloc = allocate_rulecards_to_section(rulecards, sid, spec.max_cards, used_card_ids, survey_data)
            used_card_ids.update(alloc.allocated_card_ids)
            engine_headline = extract_engine_headline(alloc.cards)
            
            # ğŸ”¥ P0-4: ìƒì„± ì‹¤íŒ¨ ì›ì¸ ë¡œê·¸ 4ê°œ í•„ìˆ˜
            headline_len = len(engine_headline) if engine_headline else 0
            logger.info(f"[Builder] ğŸ“Š section={sid} | 1.allocated_count={alloc.allocated_count} | 2.headline_len={headline_len}")
            
            try:
                result = await self._generate_section_safe(
                    section_id=sid,
                    saju_data=saju_data,
                    allocation=alloc,
                    target_year=target_year,
                    survey_data=survey_data,
                    engine_headline=engine_headline,
                    existing_contents=existing_contents,
                    job_id=job_id
                )
                
                body = result.get("body_markdown", "")
                body_len = len(body)
                
                # ğŸ”¥ P0-4: LLM ì‘ë‹µ ê¸¸ì´ + ìµœì¢… ì €ì¥ ê¸¸ì´ ë¡œê·¸
                logger.info(f"[Builder] ğŸ“Š section={sid} | 3.llm_response_len={result.get('llm_response_len', 0)} | 4.final_body_len={body_len}")
                
                if body_len == 0:
                    logger.error(f"[Builder] âŒ section={sid} | generated_len=0 â†’ EMPTY SECTION")
                elif body_len < 200:
                    logger.warning(f"[Builder] âš ï¸ section={sid} | generated_len={body_len} < 200 â†’ TOO SHORT")
                else:
                    logger.info(f"[Builder] âœ… section={sid} | generated_len={body_len}")
                
                if body:
                    existing_contents.append(body[:300])
                results.append(result)
                
                if job_id:
                    await job_store.section_done(job_id, sid, body_len)
                    
            except Exception as e:
                logger.exception(f"[Builder] âŒ ì„¹ì…˜ ìƒì„± ì‹¤íŒ¨: {sid} | {e}")
                # ğŸ”¥ P0-1: ì˜ˆì™¸ ì‹œì—ë„ í´ë°±ìœ¼ë¡œ ë¹ˆ ì„¹ì…˜ ë°©ì§€
                fallback_body = generate_fallback_body(sid, engine_headline, survey_data)
                result = {
                    "section_id": sid,
                    "title": spec.title,
                    "body_markdown": fallback_body,
                    "engine_headline": engine_headline or spec.fallback_headline,
                    "rulecard_ids": [],
                    "char_count": len(fallback_body),
                    "is_fallback": True,
                    "error": str(e)[:200]
                }
                results.append(result)
                logger.warning(f"[Builder] ğŸ”„ section={sid} | fallback_len={len(fallback_body)}")
        
        if job_id:
            await job_store.complete_job(job_id, {"sections": len(results)})
        return {"status": "success", "sections": results}
    
    async def _generate_section_safe(self, section_id: str, saju_data: Dict, allocation: SectionRuleCardAllocation, target_year: int, survey_data: Dict, engine_headline: str, existing_contents: List[str], job_id: str = None) -> Dict[str, Any]:
        """ğŸ”¥ P0-1: ë¹ˆ ì„¹ì…˜ ì ˆëŒ€ ê¸ˆì§€ - ì¹´ë“œ 0ê°œë©´ í´ë°±"""
        spec = PREMIUM_SECTIONS.get(section_id)
        if not spec:
            logger.error(f"[Builder] Invalid section_id: {section_id}")
            raise ValueError(f"Invalid section_id: {section_id}")
        
        # ğŸ”¥ P0-1(A): ì¹´ë“œ 0ê°œë©´ LLM í˜¸ì¶œ X, ì¦‰ì‹œ í´ë°±
        if allocation.allocated_count == 0:
            logger.warning(f"[Builder] section={section_id} | cards=0 â†’ skip LLM, use fallback")
            fallback_body = generate_fallback_body(section_id, engine_headline, survey_data)
            return {
                "section_id": section_id,
                "title": spec.title,
                "body_markdown": fallback_body,
                "engine_headline": engine_headline or spec.fallback_headline,
                "rulecard_ids": [],
                "char_count": len(fallback_body),
                "llm_response_len": 0,
                "is_fallback": True
            }
        
        cards_summary = self._build_cards_summary(allocation.cards[:5])
        system_prompt = build_system_prompt(
            section_id=section_id,
            engine_headline=engine_headline or spec.fallback_headline,
            survey_data=survey_data,
            saju_data=saju_data,  # ğŸ”¥ P0: íŒ©íŠ¸ì²´í¬ìš©
            existing_contents=existing_contents,
            cards_summary=cards_summary
        )
        user_prompt = self._build_user_prompt(saju_data, allocation, target_year)
        
        llm_response_len = 0
        body_markdown = ""
        
        async with self._semaphore:
            try:
                response = await self._client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=4000
                )
                body_markdown = response.choices[0].message.content or ""
                llm_response_len = len(body_markdown)
            except Exception as e:
                logger.error(f"[Builder] GPT í˜¸ì¶œ ì‹¤íŒ¨: {section_id} | {e}")
                # ğŸ”¥ P0-1(B): ì˜ˆì™¸ ì‹œ í´ë°±
                body_markdown = generate_fallback_body(section_id, engine_headline, survey_data)
                llm_response_len = 0
        
        # LLM ì‘ë‹µì´ ë„ˆë¬´ ì§§ìœ¼ë©´ í´ë°±
        if len(body_markdown) < 200:
            logger.warning(f"[Builder] section={section_id} | llm_response too short ({len(body_markdown)}) â†’ fallback")
            body_markdown = generate_fallback_body(section_id, engine_headline, survey_data)
        
        body_markdown = self._enforce_engine_headline(body_markdown, engine_headline or spec.fallback_headline)
        
        # ğŸ”¥ P0-3: leak ì²´í¬ í›„ ì¹˜í™˜
        leaked = check_template_leaks(body_markdown, f"section={section_id}")
        body_markdown = replace_template_tokens(body_markdown)
        
        return {
            "section_id": section_id,
            "title": spec.title,
            "body_markdown": body_markdown,
            "engine_headline": engine_headline or spec.fallback_headline,
            "rulecard_ids": allocation.allocated_card_ids,
            "char_count": len(body_markdown),
            "llm_response_len": llm_response_len,
            "leaked_tokens": leaked
        }
    
    def _build_cards_summary(self, cards: List[Dict]) -> str:
        lines = []
        for i, c in enumerate(cards[:5], 1):
            interp = (c.get("interpretation") or "")[:80]
            lines.append(f"{i}. [{c.get('topic', '')}] {interp}")
        return "\n".join(lines) if lines else "(ì—†ìŒ)"
    
    def _build_user_prompt(self, saju_data: Dict, allocation: SectionRuleCardAllocation, target_year: int) -> str:
        year_pillar = saju_data.get("year_pillar", "-")
        month_pillar = saju_data.get("month_pillar", "-")
        day_pillar = saju_data.get("day_pillar", "-")
        hour_pillar = saju_data.get("hour_pillar", "-") or "ë¯¸ì…ë ¥"
        day_master = saju_data.get("day_master", "")
        card_lines = []
        for c in allocation.cards[:10]:
            interp = (c.get("interpretation") or "")[:100]
            card_lines.append(f"- [{c.get('id', '')}] {c.get('topic', '')} | {interp}")
        return f"""## ì‚¬ì£¼ ì›êµ­
| ë…„ì£¼ | ì›”ì£¼ | ì¼ì£¼ | ì‹œì£¼ |
|------|------|------|------|
| {year_pillar} | {month_pillar} | {day_pillar} | {hour_pillar} |

- ì¼ê°„: {day_master}
- ë¶„ì„ë…„ë„: {target_year}ë…„

## ë£°ì¹´ë“œ
{chr(10).join(card_lines) if card_lines else '(ì—†ìŒ)'}

ìœ„ ì •ë³´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
    
    def _enforce_engine_headline(self, body_markdown: str, engine_headline: str) -> str:
        if not engine_headline:
            return body_markdown
        headline = engine_headline.strip()
        body_stripped = body_markdown.lstrip()
        if body_stripped.startswith(headline):
            return body_markdown
        if len(body_stripped) > 50 and headline[:30] in body_stripped[:100]:
            return body_markdown
        logger.warning(f"[Builder] engine_headline ê°•ì œ ì‚½ì…")
        return f"{headline}\n\n{body_stripped}"
    
    async def regenerate_single_section(self, section_id: str, saju_data: Dict, rulecards: List[Dict], feature_tags: List[str] = None, target_year: int = 2026, user_question: str = "", survey_data: Dict = None):
        self._client = self._get_client()
        self._semaphore = asyncio.Semaphore(1)
        spec = PREMIUM_SECTIONS.get(section_id)
        if not spec:
            logger.error(f"[Builder] Invalid section_id: {section_id}")
            raise ValueError(f"Invalid section_id: {section_id}")
        alloc = allocate_rulecards_to_section(rulecards, section_id, spec.max_cards, set(), survey_data)
        engine_headline = extract_engine_headline(alloc.cards)
        result = await self._generate_section_safe(
            section_id=section_id,
            saju_data=saju_data,
            allocation=alloc,
            target_year=target_year,
            survey_data=survey_data,
            engine_headline=engine_headline,
            existing_contents=[]
        )
        return {"success": True, "section": result}


premium_report_builder = PremiumReportBuilder()
report_builder = premium_report_builder
