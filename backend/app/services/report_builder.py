"""
SajuOS Premium Report Builder v7
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¥ v7 í•µì‹¬ ê°œì„ :
1) í’ˆì§ˆ ê²Œì´íŠ¸ 3ì¤‘ í•„í„° (ê¸ˆì§€ì–´/êµ¬ì²´ì„±/ì¤‘ë³µ)
2) 7ë¬¸í•­ ì„¤ë¬¸ ê¸°ë°˜ ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ì£¼ì…
3) ë£°ì¹´ë“œ ìŠ¤ì½”ì–´ë§ ì—”ì§„ (ì‚¬ì—…ê°€í˜• 50íƒœê·¸ ê¸°ë°˜)
4) ê²€ì¦ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ìƒì„± + í’ˆì§ˆ í”¼ë“œë°±
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
import asyncio
import logging
import time
import json
import random
import re
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass

from openai import AsyncOpenAI, APIError, RateLimitError, APIConnectionError, APITimeoutError
import httpx

from app.config import get_settings
from app.services.openai_key import get_openai_api_key
from app.services.terminology_mapper import (
    sanitize_for_business,
    get_business_prompt_rules,
)
from app.services.job_store import job_store, JobStore

# ğŸ”¥ v7: í’ˆì§ˆ ê²Œì´íŠ¸ + ì„¤ë¬¸ + ìŠ¤ì½”ì–´ë§ ëª¨ë“ˆ
from app.services.quality_gate import (
    quality_gate, 
    QualityReport, 
    get_quality_improvement_prompt,
    clean_banned_phrases
)
from app.services.survey_intake import (
    SurveyResponse, 
    survey_to_prompt_context
)
from app.services.rulecard_scorer import (
    rulecard_scorer, 
    SectionCards
)

logger = logging.getLogger(__name__)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 1. ê°€ë“œë ˆì¼: í•œêµ­ì–´ ê³ ì • + ë¹„ì¦ˆë‹ˆìŠ¤ ê¸ˆì¹™ì–´
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ê¸ˆì¹™ì–´ (ì·¨ì—…/ì»¤ë¦¬ì–´ í…œí”Œë¦¿)
BANNED_CAREER_TERMS = [
    "ìê²©ì¦", "ì·¨ì—…", "ì´ë ¥ì„œ", "ì±„ìš©", "ë©´ì ‘", "í¬íŠ¸í´ë¦¬ì˜¤", "í•©ê²©",
    "job application", "resume", "certification", "interview prep",
    "career change", "job search", "job hunting", "linkedin",
    "ì·¨ì—… ì¤€ë¹„", "ìê²© ì‹œí—˜", "ì…ì‚¬", "í‡´ì‚¬", "êµ¬ì§", "ì¸í„´"
]

# ë¹„ì¦ˆë‹ˆìŠ¤ í•„ìˆ˜ ìš©ì–´ (ìµœì†Œ 3ê°œ ì´ìƒ í¬í•¨ í•„ìš”)
REQUIRED_BUSINESS_TERMS = [
    "ë§¤ì¶œ", "ìˆ˜ìµ", "í˜„ê¸ˆ", "íˆ¬ì", "ROI", "KPI", "ì „í™˜", "ë¦¬ë“œ",
    "ê³ ê°", "ì‹œì¥", "ì „ëµ", "ì‹¤í–‰", "ëª©í‘œ", "ì„±ê³¼", "ë¶„ê¸°", "ì›”ë³„"
]

# ğŸ”¥ P0-3: ì˜ì–´ Allowlist (ë¹„ì¦ˆë‹ˆìŠ¤ ì•½ì–´ - en_ratio ê³„ì‚°ì—ì„œ ì œì™¸)
ENGLISH_ALLOWLIST = {
    "ai", "okr", "kpi", "pdf", "sns", "url", "api", "db", "sql",
    "roi", "b2b", "b2c", "saas", "crm", "erp", "hr", "ceo", "cto", "cfo",
    "mvp", "poc", "qa", "ui", "ux", "seo", "sem", "ppc", "cpa", "cpc",
    "ltv", "cac", "mrr", "arr", "gmv", "aov", "dau", "mau", "wau",
    "pm", "pd", "pr", "ir", "ipo", "m&a", "nda", "mou", "rnd",
    "it", "iot", "ml", "gpt", "llm", "devops", "ci", "cd",
}


def english_ratio(text: str) -> float:
    """ì˜ë¬¸ì ë¹„ìœ¨ ê³„ì‚° (Allowlist ì œì™¸)"""
    if not text:
        return 0.0
    
    # 1) ì˜ì–´ ë‹¨ì–´ ì¶”ì¶œ
    en_words = re.findall(r"[A-Za-z]+", text)
    
    # 2) Allowlist ì œì™¸í•œ ì˜ì–´ ê¸€ì ìˆ˜ ê³„ì‚°
    en_chars = 0
    for word in en_words:
        if word.lower() not in ENGLISH_ALLOWLIST:
            en_chars += len(word)
    
    # 3) ê³µë°± ì œì™¸í•œ ì „ì²´ ê¸¸ì´
    total_chars = len(re.sub(r"\s", "", text))
    
    return en_chars / max(total_chars, 1)


def validate_language_and_topic(text: str, section_id: str) -> Tuple[bool, List[str]]:
    """
    ê°€ë“œë ˆì¼ ê²€ì¦: í•œêµ­ì–´ ê³ ì • + ë¹„ì¦ˆë‹ˆìŠ¤ ê¸ˆì¹™ì–´
    Returns: (is_valid, error_codes)
    """
    errors = []
    
    if not text or len(text) < 100:
        errors.append("CONTENT_TOO_SHORT")
        return False, errors
    
    # 1) í•œêµ­ì–´ ê³ ì • (ì˜ë¬¸ ë¹„ìœ¨ 5% ì´ˆê³¼ ì‹œ ì‹¤íŒ¨)
    en_ratio = english_ratio(text)
    if en_ratio > 0.05:
        errors.append(f"LANGUAGE_NOT_KOREAN (en_ratio={en_ratio:.1%})")
        logger.warning(f"[Guardrail] {section_id}: ì˜ì–´ ë¹„ìœ¨ {en_ratio:.1%} > 5%")
    
    # 2) ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œì—ì„œ ì»¤ë¦¬ì–´ í…œí”Œë¦¿ ê¸ˆì§€
    text_lower = text.lower()
    for banned in BANNED_CAREER_TERMS:
        if banned.lower() in text_lower:
            errors.append(f"BANNED_CAREER_TEMPLATE ({banned})")
            logger.warning(f"[Guardrail] {section_id}: ê¸ˆì¹™ì–´ ë°œê²¬ '{banned}'")
            break  # í•˜ë‚˜ë§Œ ì°¾ìœ¼ë©´ ì¶©ë¶„
    
    # 3) ë¹„ì¦ˆë‹ˆìŠ¤ í•„ìˆ˜ ìš©ì–´ ìµœì†Œ 3ê°œ í¬í•¨ í™•ì¸
    found_business_terms = sum(1 for term in REQUIRED_BUSINESS_TERMS if term in text)
    if found_business_terms < 3:
        errors.append(f"MISSING_BUSINESS_CONTEXT (found={found_business_terms})")
        logger.warning(f"[Guardrail] {section_id}: ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ ë¶€ì¡± ({found_business_terms}/3)")
    
    is_valid = len(errors) == 0
    return is_valid, errors


def validate_rulecard_usage(rulecard_ids: List[str], section_id: str, min_required: int = 8) -> Tuple[bool, str]:
    """RuleCard ìµœì†Œ ì‚¬ìš©ëŸ‰ ê²€ì¦"""
    count = len(rulecard_ids) if rulecard_ids else 0
    if count < min_required:
        return False, f"RULECARD_INSUFFICIENT ({count}/{min_required})"
    return True, ""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 2. ì‚¬ì—…ê°€í˜• í•µì‹¬ íƒœê·¸ 50ê°œ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

BUSINESS_OWNER_CORE_TAGS = [
    "ì •ì¬", "í¸ì¬", "ì¬ì„±", "ì¬ë¬¼", "ë¶€", "í˜„ê¸ˆ", "ë§¤ì¶œ", "ìˆ˜ìµ", "íˆ¬ì", 
    "ìì‚°", "ìœ ë™ì„±", "ì†ì‹¤", "íŒŒì‚°", "íš¡ì¬", "ë„ë‘‘",
    "ì •ê´€", "í¸ê´€", "ê´€ì„±", "ì§ì¥", "ì‚¬ì—…", "ì°½ì—…", "ê²½ì˜", "ë¦¬ë”ì‹­", 
    "ìŠ¹ì§„", "ì´ì§", "ë…ë¦½", "í”„ë¦¬ëœì„œ", "ê³„ì•½", "ê±°ë˜", "íŒŒíŠ¸ë„ˆ",
    "ì‹ì‹ ", "ìƒê´€", "ì‹ìƒ", "ì‹¤í–‰", "ìƒì‚°", "ì°½ì‘", "ë§ˆì¼€íŒ…", "í˜ì‹ ", 
    "ì¶œë ¥", "ì„±ê³¼",
    "ë¹„ê²", "ë¹„ê²¬", "ê²ì¬", "ë™ì—…", "ê²½ìŸ",
    "ì¸ì„±", "ì •ì¸", "í¸ì¸", "í•™ìŠµ", "ë¸Œëœë“œ"
]

SECTION_WEIGHT_TAGS: Dict[str, List[str]] = {
    "exec": ["ì „ì²´ìš´", "ì¢…í•©", "í•µì‹¬", "ìš”ì•½", "ì¼ê°„", "ì„±í–¥"],
    "money": ["ì •ì¬", "í¸ì¬", "ì¬ì„±", "ì¬ë¬¼", "í˜„ê¸ˆ", "ë§¤ì¶œ", "íˆ¬ì", "ì†ì‹¤"],
    "business": ["ì •ê´€", "í¸ê´€", "ì‚¬ì—…", "ì°½ì—…", "ê²½ì˜", "ë¦¬ë”ì‹­", "ê³„ì•½", "ê±°ë˜"],
    "team": ["ë¹„ê²", "ë¹„ê²¬", "ê²ì¬", "ë™ì—…", "íŒŒíŠ¸ë„ˆ", "ì§ì›", "ê´€ê³„", "í˜‘ë ¥"],
    "health": ["ê±´ê°•", "ì—ë„ˆì§€", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë²ˆì•„ì›ƒ", "ì²´ë ¥", "ì§ˆë³‘", "íœ´ì‹"],
    "calendar": ["ì›”ìš´", "ì‹œê¸°", "ê³„ì ˆ", "íƒ€ì´ë°", "ê¸¸ì¼", "í‰ì¼", "ì ˆê¸°"],
    "sprint": ["ì‹¤í–‰", "ì•¡ì…˜", "ê³„íš", "ëª©í‘œ", "KPI", "ë§ˆì¼ìŠ¤í†¤", "ì£¼ê°„"]
}


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 3. ì„¹ì…˜ ì •ì˜
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class SectionSpec:
    id: str
    title: str
    pages: int
    max_cards: int
    min_cards: int  # ìµœì†Œ RuleCard ìˆ˜
    min_chars: int
    validation_type: str = "standard"


PREMIUM_SECTIONS: Dict[str, SectionSpec] = {
    "exec": SectionSpec(id="exec", title="2026ë…„, ë‚´ ì¥ì‚¬ ì„¤ê³„ë„", pages=2, max_cards=15, min_cards=8, min_chars=1500, validation_type="standard"),
    "money": SectionSpec(id="money", title="í˜„ê¸ˆíë¦„ & ìˆ˜ìµêµ¬ì¡°", pages=5, max_cards=18, min_cards=10, min_chars=2500, validation_type="standard"),
    "business": SectionSpec(id="business", title="ì‚¬ì—… ì „ëµ & í™•ì¥ íƒ€ì´ë°", pages=5, max_cards=18, min_cards=10, min_chars=2500, validation_type="standard"),
    "team": SectionSpec(id="team", title="í˜‘ë ¥ì & íŒŒíŠ¸ë„ˆ ë¦¬ìŠ¤í¬", pages=4, max_cards=15, min_cards=8, min_chars=2000, validation_type="standard"),
    "health": SectionSpec(id="health", title="ì²´ë ¥ & ë²ˆì•„ì›ƒ ê´€ë¦¬", pages=3, max_cards=12, min_cards=6, min_chars=1500, validation_type="standard"),
    "calendar": SectionSpec(id="calendar", title="12ê°œì›” ìº˜ë¦°ë”", pages=6, max_cards=12, min_cards=8, min_chars=2500, validation_type="calendar"),
    "sprint": SectionSpec(id="sprint", title="90ì¼ ìŠ¤í”„ë¦°íŠ¸ í”Œëœ", pages=5, max_cards=10, min_cards=6, min_chars=2000, validation_type="sprint")
}


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 4. JSON Schema (Structured Outputs)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

STANDARD_SECTION_SCHEMA = {
    "type": "json_schema",
    "json_schema": {
        "name": "standard_section",
        "strict": True,
        "schema": {
            "type": "object",
            "properties": {
                "title": {"type": "string"},
                "diagnosis": {
                    "type": "object",
                    "properties": {
                        "current_state": {"type": "string"},
                        "key_issues": {"type": "array", "items": {"type": "string"}}
                    },
                    "required": ["current_state", "key_issues"],
                    "additionalProperties": False
                },
                "hypotheses": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string"},
                            "statement": {"type": "string"},
                            "confidence": {"type": "string"},
                            "evidence": {"type": "string"}
                        },
                        "required": ["id", "statement", "confidence", "evidence"],
                        "additionalProperties": False
                    }
                },
                "strategy_options": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string"},
                            "name": {"type": "string"},
                            "description": {"type": "string"},
                            "pros": {"type": "array", "items": {"type": "string"}},
                            "cons": {"type": "array", "items": {"type": "string"}}
                        },
                        "required": ["id", "name", "description", "pros", "cons"],
                        "additionalProperties": False
                    }
                },
                "recommended_strategy": {
                    "type": "object",
                    "properties": {
                        "selected_option": {"type": "string"},
                        "rationale": {"type": "string"},
                        "execution_plan": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "week": {"type": "integer"},
                                    "focus": {"type": "string"},
                                    "actions": {"type": "array", "items": {"type": "string"}}
                                },
                                "required": ["week", "focus", "actions"],
                                "additionalProperties": False
                            }
                        }
                    },
                    "required": ["selected_option", "rationale", "execution_plan"],
                    "additionalProperties": False
                },
                "kpis": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "metric": {"type": "string"},
                            "target": {"type": "string"},
                            "current": {"type": "string"},
                            "measurement": {"type": "string"}
                        },
                        "required": ["metric", "target", "current", "measurement"],
                        "additionalProperties": False
                    }
                },
                "risks": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "risk": {"type": "string"},
                            "probability": {"type": "string"},
                            "impact": {"type": "string"},
                            "mitigation": {"type": "string"}
                        },
                        "required": ["risk", "probability", "impact", "mitigation"],
                        "additionalProperties": False
                    }
                },
                "body_markdown": {"type": "string"},
                "confidence": {"type": "string"}
            },
            "required": ["title", "diagnosis", "hypotheses", "strategy_options", 
                        "recommended_strategy", "kpis", "risks", "body_markdown", "confidence"],
            "additionalProperties": False
        }
    }
}

# ğŸ”¥ Sprint ì„¹ì…˜: ë¹„ì¦ˆë‹ˆìŠ¤ ì „ìš© (ë¦¬ë“œâ†’ì „í™˜â†’LTVâ†’ìë™í™”)
SPRINT_SECTION_SCHEMA = {
    "type": "json_schema",
    "json_schema": {
        "name": "sprint_section",
        "strict": True,
        "schema": {
            "type": "object",
            "properties": {
                "title": {"type": "string"},
                "mission_statement": {"type": "string"},
                "phase_1_offer": {
                    "type": "object",
                    "properties": {
                        "weeks": {"type": "string"},
                        "theme": {"type": "string"},
                        "goals": {"type": "array", "items": {"type": "string"}},
                        "deliverables": {"type": "array", "items": {"type": "string"}},
                        "kpis": {"type": "array", "items": {"type": "string"}}
                    },
                    "required": ["weeks", "theme", "goals", "deliverables", "kpis"],
                    "additionalProperties": False
                },
                "phase_2_funnel": {
                    "type": "object",
                    "properties": {
                        "weeks": {"type": "string"},
                        "theme": {"type": "string"},
                        "goals": {"type": "array", "items": {"type": "string"}},
                        "deliverables": {"type": "array", "items": {"type": "string"}},
                        "kpis": {"type": "array", "items": {"type": "string"}}
                    },
                    "required": ["weeks", "theme", "goals", "deliverables", "kpis"],
                    "additionalProperties": False
                },
                "phase_3_content": {
                    "type": "object",
                    "properties": {
                        "weeks": {"type": "string"},
                        "theme": {"type": "string"},
                        "goals": {"type": "array", "items": {"type": "string"}},
                        "deliverables": {"type": "array", "items": {"type": "string"}},
                        "kpis": {"type": "array", "items": {"type": "string"}}
                    },
                    "required": ["weeks", "theme", "goals", "deliverables", "kpis"],
                    "additionalProperties": False
                },
                "phase_4_automation": {
                    "type": "object",
                    "properties": {
                        "weeks": {"type": "string"},
                        "theme": {"type": "string"},
                        "goals": {"type": "array", "items": {"type": "string"}},
                        "deliverables": {"type": "array", "items": {"type": "string"}},
                        "kpis": {"type": "array", "items": {"type": "string"}}
                    },
                    "required": ["weeks", "theme", "goals", "deliverables", "kpis"],
                    "additionalProperties": False
                },
                "milestones": {
                    "type": "object",
                    "properties": {
                        "day_30": {
                            "type": "object",
                            "properties": {
                                "goal": {"type": "string"},
                                "success_criteria": {"type": "string"},
                                "revenue_target": {"type": "string"}
                            },
                            "required": ["goal", "success_criteria", "revenue_target"],
                            "additionalProperties": False
                        },
                        "day_60": {
                            "type": "object",
                            "properties": {
                                "goal": {"type": "string"},
                                "success_criteria": {"type": "string"},
                                "revenue_target": {"type": "string"}
                            },
                            "required": ["goal", "success_criteria", "revenue_target"],
                            "additionalProperties": False
                        },
                        "day_90": {
                            "type": "object",
                            "properties": {
                                "goal": {"type": "string"},
                                "success_criteria": {"type": "string"},
                                "revenue_target": {"type": "string"}
                            },
                            "required": ["goal", "success_criteria", "revenue_target"],
                            "additionalProperties": False
                        }
                    },
                    "required": ["day_30", "day_60", "day_90"],
                    "additionalProperties": False
                },
                "risk_scenarios": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "scenario": {"type": "string"},
                            "trigger": {"type": "string"},
                            "pivot_plan": {"type": "string"}
                        },
                        "required": ["scenario", "trigger", "pivot_plan"],
                        "additionalProperties": False
                    }
                },
                "body_markdown": {"type": "string"},
                "confidence": {"type": "string"}
            },
            "required": ["title", "mission_statement", "phase_1_offer", "phase_2_funnel",
                        "phase_3_content", "phase_4_automation", "milestones", 
                        "risk_scenarios", "body_markdown", "confidence"],
            "additionalProperties": False
        }
    }
}

# Calendar ì„¹ì…˜: ì›”ë³„ í˜„ê¸ˆíë¦„ í¬í•¨
CALENDAR_SECTION_SCHEMA = {
    "type": "json_schema",
    "json_schema": {
        "name": "calendar_section",
        "strict": True,
        "schema": {
            "type": "object",
            "properties": {
                "title": {"type": "string"},
                "annual_theme": {"type": "string"},
                "annual_revenue_projection": {"type": "string"},
                "monthly_plans": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "month": {"type": "integer"},
                            "month_name": {"type": "string"},
                            "theme": {"type": "string"},
                            "energy_level": {"type": "string"},
                            "revenue_index": {"type": "integer"},
                            "key_focus": {"type": "string"},
                            "recommended_actions": {"type": "array", "items": {"type": "string"}},
                            "cautions": {"type": "array", "items": {"type": "string"}}
                        },
                        "required": ["month", "month_name", "theme", "energy_level", 
                                    "revenue_index", "key_focus", "recommended_actions", "cautions"],
                        "additionalProperties": False
                    }
                },
                "quarterly_milestones": {
                    "type": "object",
                    "properties": {
                        "Q1": {"type": "object", "properties": {"theme": {"type": "string"}, "milestone": {"type": "string"}, "revenue_target": {"type": "string"}}, "required": ["theme", "milestone", "revenue_target"], "additionalProperties": False},
                        "Q2": {"type": "object", "properties": {"theme": {"type": "string"}, "milestone": {"type": "string"}, "revenue_target": {"type": "string"}}, "required": ["theme", "milestone", "revenue_target"], "additionalProperties": False},
                        "Q3": {"type": "object", "properties": {"theme": {"type": "string"}, "milestone": {"type": "string"}, "revenue_target": {"type": "string"}}, "required": ["theme", "milestone", "revenue_target"], "additionalProperties": False},
                        "Q4": {"type": "object", "properties": {"theme": {"type": "string"}, "milestone": {"type": "string"}, "revenue_target": {"type": "string"}}, "required": ["theme", "milestone", "revenue_target"], "additionalProperties": False}
                    },
                    "required": ["Q1", "Q2", "Q3", "Q4"],
                    "additionalProperties": False
                },
                "peak_months": {"type": "array", "items": {"type": "string"}},
                "risk_months": {"type": "array", "items": {"type": "string"}},
                "body_markdown": {"type": "string"},
                "confidence": {"type": "string"}
            },
            "required": ["title", "annual_theme", "annual_revenue_projection", "monthly_plans", 
                        "quarterly_milestones", "peak_months", "risk_months", "body_markdown", "confidence"],
            "additionalProperties": False
        }
    }
}


def get_section_schema(section_id: str) -> dict:
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        return STANDARD_SECTION_SCHEMA
    if spec.validation_type == "sprint":
        return SPRINT_SECTION_SCHEMA
    elif spec.validation_type == "calendar":
        return CALENDAR_SECTION_SCHEMA
    return STANDARD_SECTION_SCHEMA


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 5. ì „ì—­ Top-100 RuleCard ì„ ë³„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class GlobalRuleCardSelection:
    original_pool_count: int
    top100_count: int
    top100_cards: List[Dict[str, Any]]
    top100_card_ids: List[str]


def score_rulecard_global(card: Dict[str, Any], feature_tags: List[str]) -> float:
    score = 0.0
    card_text = f"{card.get('topic', '')} {' '.join(card.get('tags', []))} {card.get('mechanism', '')} {card.get('action', '')}"
    card_text_lower = card_text.lower()
    
    for ft in feature_tags:
        if ft.lower() in card_text_lower:
            score += 3.0
    
    for core_tag in BUSINESS_OWNER_CORE_TAGS:
        if core_tag.lower() in card_text_lower:
            score += 1.0
    
    return score


def select_global_top100(all_cards: List[Dict[str, Any]], feature_tags: List[str], top_limit: int = 100) -> GlobalRuleCardSelection:
    original_pool = len(all_cards)
    if original_pool == 0:
        return GlobalRuleCardSelection(0, 0, [], [])
    
    scored = [(score_rulecard_global(card, feature_tags), card) for card in all_cards]
    scored.sort(key=lambda x: x[0], reverse=True)
    top100 = [card for _, card in scored[:top_limit]]
    top100_ids = [card.get("id", card.get("_id", f"card_{i}")) for i, card in enumerate(top100)]
    
    logger.info(f"[GlobalTop100] Pool={original_pool} â†’ Top100={len(top100)}")
    return GlobalRuleCardSelection(original_pool, len(top100), top100, top100_ids)


@dataclass
class SectionRuleCardAllocation:
    section_id: str
    allocated_count: int
    allocated_card_ids: List[str]
    context_text: str


def allocate_rulecards_to_section(
    top100_cards: List[Dict[str, Any]],
    section_id: str,
    max_cards: int,
    already_used_ids: set
) -> SectionRuleCardAllocation:
    section_tags = SECTION_WEIGHT_TAGS.get(section_id, [])
    
    scored = []
    for card in top100_cards:
        cid = card.get("id", card.get("_id", ""))
        if cid in already_used_ids:
            continue
        
        card_text = f"{card.get('topic', '')} {card.get('mechanism', '')} {card.get('action', '')}".lower()
        section_score = sum(2.0 for st in section_tags if st.lower() in card_text)
        scored.append((section_score, card))
    
    scored.sort(key=lambda x: x[0], reverse=True)
    allocated = [card for _, card in scored[:max_cards]]
    
    lines = []
    ids = []
    for card in allocated:
        cid = card.get("id", card.get("_id", f"card_{len(ids)}"))
        ids.append(cid)
        topic = card.get("topic", "")
        # ğŸ”¥ğŸ”¥ğŸ”¥ P0-2: interpretationì„ "ê²°ë¡ "ìœ¼ë¡œ ì¶”ê°€ (trigger fallback)
        interp = sanitize_for_business((card.get("interpretation") or card.get("trigger") or "")[:220])
        mechanism = sanitize_for_business((card.get("mechanism") or "")[:100])
        action = sanitize_for_business((card.get("action") or "")[:100])
        line = f"[{cid}] {topic}"
        if interp:
            line += f" | ê²°ë¡ : {interp}"
        if mechanism:
            line += f" | ê·¼ê±°: {mechanism}"
        if action:
            line += f" | ì•¡ì…˜: {action}"
        lines.append(line)
    
    context = "\n".join(lines) if lines else "ë¶„ì„ ë°ì´í„° ì—†ìŒ"
    return SectionRuleCardAllocation(section_id, len(ids), ids, context)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 6. í”„ë¡¬í”„íŠ¸ ìƒì„± (ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ë“œë ˆì¼ ê°•í™”)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


def _extract_engine_headline_from_rulecards(rulecards: List[Dict[str, Any]]) -> str:
    """Top1 ë£°ì¹´ë“œì˜ interpretation(ì—†ìœ¼ë©´ trigger/mechanism)ë¥¼ í—¤ë“œë¼ì¸ìœ¼ë¡œ ë½‘ì•„ëƒ„.
    - ê°€ëŠ¥í•œ í•œ 'í•œ ë¬¸ì¥'ìœ¼ë¡œ ìœ ì§€
    - sanitize_for_business ì ìš©
    """
    if not rulecards:
        return ""

    def _first_sentence(text: str, max_len: int = 160) -> str:
        t = (text or "").strip()
        if not t:
            return ""
        # 1) ì²« ì¤„
        t = re.split(r"[\r\n]+", t)[0].strip()
        if len(t) <= max_len:
            return t
        # 2) ë¬¸ì¥ë¶€í˜¸ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ê¸°
        cut = t[:max_len]
        m = re.search(r"(.+?[\.\!\?â€¦ã€‚])", cut)
        if m:
            return m.group(1).strip()
        return cut.strip()

    for card in rulecards:
        raw = (
            card.get("interpretation")
            or card.get("trigger")
            or card.get("mechanism")
            or card.get("action")
            or ""
        )
        try:
            cleaned = sanitize_for_business(str(raw))
        except Exception:
            cleaned = str(raw)
        headline = _first_sentence(cleaned)
        if headline:
            return headline

    return ""


def get_section_system_prompt(section_id: str, target_year: int, survey_context: str = "", engine_headline: str = "") -> str:
    """ğŸ”¥ P0 Pivot: ONE-MAN BUSINESS ê³µí†µ í”„ë¡¬í”„íŠ¸ (RC-#### ë‚´ë¶€ ë©”ëª¨ ê¸ˆì§€)"""
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        spec = PREMIUM_SECTIONS["exec"]
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ P0 í•µì‹¬: ì‚¬ì£¼ ìš©ì–´ ê°•ì œ í¬í•¨ í”„ë¡¬í”„íŠ¸
    saju_interpretation_rule = """
## ğŸ”® ì‚¬ì£¼ ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„ ê·œì¹™ (í•„ìˆ˜)

âš ï¸ **ë¦¬í¬íŠ¸ ì‹œì‘ ì‹œ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•˜ë¼:**

```
ã€ë‹¹ì‹ ì˜ ì‚¬ì—… DNA ë¶„ì„ã€‘

ğŸ“Œ ì¼ê°„(Day Master): [ex: ì…ìˆ˜(å£¬æ°´)] = ë¹„ì¦ˆë‹ˆìŠ¤ ìŠ¤íƒ€ì¼ í•µì‹¬
   â†’ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„: [ex: "ìœ ì—°í•œ ì ì‘ë ¥, ë„¤íŠ¸ì›Œí‚¹ ê°•ì , í˜„ê¸ˆíë¦„ ê´€ë¦¬ ëŠ¥ë ¥"]

ğŸ“Œ 4ì£¼ êµ¬ì¡° ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„:
   - ë…„ì£¼(Year): [ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°ë°˜/ë°°ê²½]
   - ì›”ì£¼(Month): [ì‚¬ì—… ì‹¤í–‰ ìŠ¤íƒ€ì¼]
   - ì¼ì£¼(Day): [ë³¸ì§ˆì  ê²½ì˜ ì„±í–¥]
   - ì‹œì£¼(Hour): [ë¯¸ë˜ ì„±ì¥ ë°©í–¥]

ğŸ¯ 2026ë…„ í•µì‹¬ ì „ëµ í¬ì¸íŠ¸:
   [ex: "ì¬ì„±(è²¡æ˜Ÿ)ì´ ê°•í•œ í•´ â†’ ë§¤ì¶œ í™•ì¥ì— ì§‘ì¤‘", "ì¸ì„±(å°æ˜Ÿ) í™œì„±í™” â†’ ë¸Œëœë“œ/ì½˜í…ì¸  ê°•í™”"]
```

**ì‚¬ì£¼ ìš©ì–´ â†’ ë¹„ì¦ˆë‹ˆìŠ¤ ì–¸ì–´ ë³€í™˜ ê·œì¹™:**
- ì¬ì„±(è²¡æ˜Ÿ) â†’ ë§¤ì¶œ/ìˆ˜ìµ/í˜„ê¸ˆíë¦„
- ê´€ì„±(å®˜æ˜Ÿ) â†’ ì¡°ì§ë ¥/ì‹œìŠ¤í…œ/ê·œëª¨ í™•ì¥
- ì¸ì„±(å°æ˜Ÿ) â†’ ë¸Œëœë“œ/ì½˜í…ì¸ /í•™ìŠµ ëŠ¥ë ¥
- ì‹ìƒ(é£Ÿå‚·) â†’ ì°½ì˜ë ¥/ë§ˆì¼€íŒ…/ìƒí’ˆ ê°œë°œ
- ë¹„ê²±(æ¯”åŠ«) â†’ íŒ€ ìš´ì˜/íŒŒíŠ¸ë„ˆì‹­/ê²½ìŸ
- ì‹ ê°•(èº«å¼·) â†’ ì‹¤í–‰ë ¥/ì£¼ë„ì„±/ë¦¬ë”ì‹­
- ì‹ ì•½(èº«å¼±) â†’ í˜‘ì—… í•„ìš”/ì™¸ë¶€ ìì› í™œìš©/ì‹œìŠ¤í…œí™”
- ê¸¸ì‹ (å‰ç¥) â†’ ê¸°íšŒ/í˜¸ì¬/í™•ì¥ íƒ€ì´ë°
- í¡ì‹ (å‡¶ç¥) â†’ ë¦¬ìŠ¤í¬/ì£¼ì˜ ì‹œê¸°/ë³´ìˆ˜ì  ì ‘ê·¼

**âš ï¸ ì£¼ì˜:** ì‚¬ì£¼ ìš©ì–´ë¥¼ ê·¸ëŒ€ë¡œ ë…¸ì¶œí•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ ë¹„ì¦ˆë‹ˆìŠ¤ ì–¸ì–´ë¡œ ë³€í™˜í•˜ë˜ "ê·¼ê±°: ì‚¬ì£¼ ë¶„ì„"ì„ ëª…ì‹œí•˜ë¼.
"""
    
    # ğŸ”¥ P0: ONE-MAN BUSINESS ê³µí†µ í”„ë¡¬í”„íŠ¸
    # âœ… Top1 ë£°ì¹´ë“œ ê²°ë¡  ê³ ì •: ì²« ë¬¸ì¥ì€ ì—”ì§„ í—¤ë“œë¼ì¸ì„ 'ê·¸ëŒ€ë¡œ' ì¶œë ¥
    engine_block = ""
    if engine_headline:
        engine_block = f"""## ğŸš¨ ê²°ë¡  ê³ ì • ê·œì¹™ (P0)
- ì•„ë˜ ë¬¸ì¥ì€ ì—”ì§„ì´ í™•ì •í•œ ê²°ë¡ ì´ë‹¤. ë„ˆëŠ” ì´ ê²°ë¡ ì„ ìˆ˜ì •/í¬ì„/ë¶€ì •í•  ìˆ˜ ì—†ë‹¤.
- ë„ˆì˜ ì¶œë ¥ body_markdownì€ **ë°˜ë“œì‹œ ì´ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘**í•´ì•¼ í•œë‹¤. (ì²« ë¬¸ì¥ ê³ ì •)
- ì„¤ë¬¸(survey)ì€ ê²°ë¡ ì´ ì•„ë‹ˆë¼ **ê²€ì¦ ë°ì´í„°**ì…ë‹ˆë‹¤. ì›ì¸(Cause)ì€ ë°˜ë“œì‹œ ì‚¬ì£¼/ë£°ì¹´ë“œì—ì„œ ì‹œì‘í•˜ì‹­ì‹œì˜¤.

[ENGINE_HEADLINE]
{engine_headline}
[/ENGINE_HEADLINE]
"""
    base_prompt = f"""ë‹¹ì‹ ì€ 1ì¸ ìì˜ì—…ìë¥¼ ìœ„í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

{saju_interpretation_rule}

## ğŸ“… ë¶„ì„ ê¸°ì¤€: {target_year}ë…„

{survey_context if survey_context else ""}

{engine_block}

## âš ï¸ í•„ìˆ˜ ì¤€ìˆ˜ì‚¬í•­ (ìœ„ë°˜ ì‹œ ì¬ìƒì„±)

1. **RC-#### ì ˆëŒ€ ë…¸ì¶œ ê¸ˆì§€**: RC-1234 ê°™ì€ ë‚´ë¶€ ë©”ëª¨ëŠ” raw_jsonì—ë§Œ. ìµœì¢… ë§ˆí¬ë‹¤ìš´/í”„ë¡ íŠ¸ í‘œì‹œì— ì ˆëŒ€ í¬í•¨ ê¸ˆì§€.

2. **ì¶”ìƒì–´ ê¸ˆì§€**: "ë…¸ë ¥í•˜ì„¸ìš”", "ì„±ì¥ì˜ ì‹œê¸°", "ê· í˜•ì„ ìœ ì§€", "ì¢‹ì€ ìš´" ê°™ì€ ì¼ë°˜ë¡  ê¸ˆì§€.
   - ëŒ€ì‹  êµ¬ì²´ì  ìˆ˜ì¹˜/ê¸°ê°„/ì•¡ì…˜ë§Œ ì‘ì„±.
   - ì˜ˆ: "3ì›”ê¹Œì§€ ì›”ë§¤ì¶œ 500ë§Œì› ë‹¬ì„±" (O), "ì„±ì¥ì˜ ì‹œê¸°" (X)

3. **ì¶œë ¥ í¬ë§· ê°•ì œ**:
   ```markdown
   ## ê²°ë¡  (3ì¤„)
   - í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1ì¤„
   - í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2ì¤„
   - í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ì¤„

   ## ì•¡ì…˜í”Œëœ (3ê°œ, ê¸°ê°„/ìˆ˜ì¹˜/íš¨ê³¼ ëª…ì‹œ)
   ### ì•¡ì…˜ 1: [ì œëª©]
   - ê¸°ê°„: D+7 ~ D+30
   - ëª©í‘œ ìˆ˜ì¹˜: ì›”ë§¤ì¶œ 300ë§Œì›
   - ì˜ˆìƒ íš¨ê³¼: ê³ ê° í™•ë³´ 20ëª…

   ### ì•¡ì…˜ 2: [ì œëª©]
   - ê¸°ê°„: ...

   ### ì•¡ì…˜ 3: [ì œëª©]
   - ê¸°ê°„: ...

   ## ë¦¬ìŠ¤í¬ (2ê°œ)
   1. [ë¦¬ìŠ¤í¬ 1]
   2. [ë¦¬ìŠ¤í¬ 2]

   ## ì²´í¬ë¦¬ìŠ¤íŠ¸
   - [ ] D+1: ...
   - [ ] D+7: ...
   - [ ] D+30: ...
   ```

4. **í•œêµ­ì–´ ì „ìš©**: ì˜ì–´ ì‚¬ìš© ê¸ˆì§€ (KPI, ROI, MVP ê°™ì€ ì•½ì–´ëŠ” OK).

5. **ì·¨ì—…/ì»¤ë¦¬ì–´ ìš©ì–´ ê¸ˆì§€**: ì´ë ¥ì„œ, ë©´ì ‘, ìê²©ì¦, ì±„ìš©, í¬íŠ¸í´ë¦¬ì˜¤ ë“± ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€.

6. **ë¹„ì¦ˆë‹ˆìŠ¤ í•„ìˆ˜ ìš©ì–´**: ë§¤ì¶œ, ìˆ˜ìµ, í˜„ê¸ˆ, íˆ¬ì, ê³ ê°, ì „í™˜, ë¦¬ë“œ ì¤‘ ìµœì†Œ 5ê°œ í¬í•¨.
"""

    # Sprint ì„¹ì…˜ íŠ¹í™”
    if section_id == "sprint":
        return base_prompt + f"""

## ğŸ¯ 90ì¼ ìŠ¤í”„ë¦°íŠ¸ í•„ìˆ˜ êµ¬ì¡°

**Phase 1 (Week 1-3): ì˜¤í¼ í™•ì •**
- í•µì‹¬ ìƒí’ˆ 1ê°œ í™•ì •
- ê°€ê²© ê²°ì •
- íƒ€ê²Ÿ ê³ ê° ì •ì˜

**Phase 2 (Week 4-6): ìœ ì… ì±„ë„**
- ì±„ë„ 1ê°œ ì„ íƒ (SNS/ë¸”ë¡œê·¸/ê´‘ê³ )
- ëœë”©í˜ì´ì§€ ì œì‘
- ì²« ë¦¬ë“œ 10ëª… í™•ë³´

**Phase 3 (Week 7-9): ì½˜í…ì¸  ì‹œìŠ¤í…œ**
- ì£¼ 3íšŒ ì½˜í…ì¸  ë°œí–‰
- ì´ë©”ì¼ ì‹œí€€ìŠ¤ êµ¬ì¶•
- ë¦¬íƒ€ê²ŸíŒ… ì„¸íŒ…

**Phase 4 (Week 10-12): ìë™í™”**
- CRM ì„¸íŒ…
- ê²°ì œ ìë™í™”
- KPI ëŒ€ì‹œë³´ë“œ

JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì •í™•íˆ ì‘ë‹µí•˜ì„¸ìš”.
"""

    # ì¼ë°˜ ì„¹ì…˜
    return base_prompt + f"""

## ì´ ì„¹ì…˜: {spec.title}

ìµœì†Œ {spec.min_chars}ì ì´ìƒ ì‘ì„±í•˜ë˜, ìœ„ ì¶œë ¥ í¬ë§·ì„ ì¤€ìˆ˜í•˜ì„¸ìš”.

JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì •í™•íˆ ì‘ë‹µí•˜ì„¸ìš”.
"""


def get_section_user_prompt(
    section_id: str,
    saju_data: Dict[str, Any],
    allocation: SectionRuleCardAllocation,
    target_year: int,
    user_question: str = ""
) -> str:
    """
    ğŸ”¥ğŸ”¥ğŸ”¥ P0 í•µì‹¬: ì‚¬ì£¼ 4ì£¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨!
    ì´ë ‡ê²Œ í•´ì•¼ ì„œë¡œ ë‹¤ë¥¸ ìƒë…„ì›”ì¼ì´ ì„œë¡œ ë‹¤ë¥¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•¨.
    """
    spec = PREMIUM_SECTIONS.get(section_id)
    
    # ğŸ”¥ ì‚¬ì£¼ 4ì£¼ ì¶”ì¶œ (ì´ê²Œ í•µì‹¬!)
    year_pillar = saju_data.get("year_pillar", "-")
    month_pillar = saju_data.get("month_pillar", "-")
    day_pillar = saju_data.get("day_pillar", "-")
    hour_pillar = saju_data.get("hour_pillar", "-") or "ë¯¸ì…ë ¥"
    day_master = saju_data.get("day_master", "")
    day_master_element = saju_data.get("day_master_element", "")
    day_master_description = saju_data.get("day_master_description", "")
    birth_info = saju_data.get("birth_info", "")
    
    # ğŸ”¥ ì‚¬ì£¼ 4ì£¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê²½ê³  ë¡œê·¸
    if not year_pillar or year_pillar == "-":
        logger.warning(f"[Prompt:{section_id}] âš ï¸ ì‚¬ì£¼ ë°ì´í„° ëˆ„ë½! year_pillar={year_pillar}")
    
    return f"""## ğŸ”® í´ë¼ì´ì–¸íŠ¸ ì‚¬ì£¼ ì›êµ­ (í•„ìˆ˜ ì°¸ì¡°)

**ì´ ë¶„ì„ì€ ì•„ë˜ ì‚¬ì£¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ì´ 4ì£¼ë¥¼ í•´ì„ì— ë°˜ì˜í•˜ì„¸ìš”.**

| êµ¬ë¶„ | ê°„ì§€ |
|------|------|
| ë…„ì£¼(å¹´æŸ±) | {year_pillar} |
| ì›”ì£¼(æœˆæŸ±) | {month_pillar} |
| ì¼ì£¼(æ—¥æŸ±) | {day_pillar} |
| ì‹œì£¼(æ™‚æŸ±) | {hour_pillar} |

- **ì¼ê°„(æ—¥å¹²)**: {day_master} ({day_master_element}) - {day_master_description}
- **ìƒë…„ì›”ì¼ì‹œ**: {birth_info if birth_info else 'ë¯¸ì…ë ¥'}
- **ë¶„ì„ ê¸°ì¤€ë…„ë„**: {target_year}ë…„

## ğŸ’¼ í´ë¼ì´ì–¸íŠ¸ ì§ˆë¬¸
{user_question or "ì¢…í•©ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ìˆ˜ë¦½"}

## ğŸ“Š ë¶„ì„ ê·¼ê±° RuleCards ({allocation.allocated_count}ì¥)
{allocation.context_text}

---
ìœ„ ì‚¬ì£¼ ì›êµ­ê³¼ RuleCardsë¥¼ ê¸°ë°˜ìœ¼ë¡œ **{spec.title if spec else section_id}** ì„¹ì…˜ì„ ì‘ì„±í•˜ì„¸ìš”.

âš ï¸ í•µì‹¬ ê·œì¹™:
1. ìœ„ ì‚¬ì£¼ 4ì£¼(ë…„/ì›”/ì¼/ì‹œ)ë¥¼ ë°˜ë“œì‹œ í•´ì„ì— ë°˜ì˜
2. ì¼ê°„ {day_master}({day_master_element})ì˜ íŠ¹ì„±ì„ ëª¨ë“  ì „ëµì— ì—°ê²°
3. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
4. ì·¨ì—…/ìê²©ì¦/ì´ë ¥ì„œ/ë©´ì ‘ ê´€ë ¨ ë‚´ìš© ì ˆëŒ€ ê¸ˆì§€
5. ë§¤ì¶œ, ìˆ˜ìµ, í˜„ê¸ˆíë¦„, ROI, KPI ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±
6. ìµœì†Œ {spec.min_chars if spec else 2000}ì ì´ìƒ
7. JSON ìŠ¤í‚¤ë§ˆì— ì •í™•íˆ ë§ì¶° ì‘ë‹µ"""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 7. ë©”ì¸ ë¹Œë” (ê°€ë“œë ˆì¼ + ìë™ ì¬ìƒì„±)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class PremiumReportBuilder:
    """99,000ì› í”„ë¦¬ë¯¸ì—„ ë¦¬í¬íŠ¸ ë¹Œë” v6"""
    
    def __init__(self):
        self._client = None
        self._semaphore = None
    
    def _get_client(self) -> AsyncOpenAI:
        settings = get_settings()
        api_key = get_openai_api_key()
        return AsyncOpenAI(
            api_key=api_key,
            timeout=httpx.Timeout(90.0, connect=15.0),
            max_retries=0
        )
    
    async def _call_with_retry(
        self,
        messages: List[Dict[str, str]],
        section_id: str,
        response_format: dict,
        max_retries: int = 3,
        base_delay: float = 2.0,
        job_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """JSON Schema + Retry + Exponential Backoff"""
        settings = get_settings()
        last_error = None
        
        for attempt in range(max_retries):
            try:
                logger.info(f"[Section:{section_id}] OpenAI í˜¸ì¶œ {attempt + 1}/{max_retries}")
                
                # ğŸ”¥ Progress: OpenAI ìš”ì²­ ì‹œì‘
                if job_id:
                    await job_store.section_stage(job_id, section_id, "openai_request")
                
                response = await self._client.chat.completions.create(
                    model=settings.openai_model,
                    messages=messages,
                    max_tokens=4000,
                    temperature=0.3,
                    response_format=response_format
                )
                
                # ğŸ”¥ Progress: ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ
                if job_id:
                    await job_store.section_stage(job_id, section_id, "validating")
                
                content_str = response.choices[0].message.content
                if not content_str:
                    raise ValueError("ë¹ˆ ì‘ë‹µ")
                
                content = json.loads(content_str)
                logger.info(f"[Section:{section_id}] ì„±ê³µ | ì‘ë‹µ: {len(content_str)}ì")
                return content
                
            except RateLimitError as e:
                last_error = e
                delay = base_delay * (2 ** attempt) + random.uniform(0.5, 1.5)
                logger.warning(f"[Section:{section_id}] 429 Rate Limit | Wait {delay:.1f}s")
                # ğŸ”¥ Progress: 429 ì¬ì‹œë„
                if job_id:
                    await job_store.section_retry(job_id, section_id, "rate_limit_429", delay)
                if attempt < max_retries - 1:
                    await asyncio.sleep(delay)
                    
            except (APIError, APIConnectionError, APITimeoutError) as e:
                last_error = e
                delay = base_delay * (2 ** attempt) + random.uniform(0.5, 1.5)
                logger.warning(f"[Section:{section_id}] API Error | Wait {delay:.1f}s")
                # ğŸ”¥ Progress: API ì—ëŸ¬ ì¬ì‹œë„
                if job_id:
                    await job_store.section_retry(job_id, section_id, "api_error", delay)
                if attempt < max_retries - 1:
                    await asyncio.sleep(delay)
                    
            except json.JSONDecodeError as e:
                last_error = e
                delay = base_delay * (2 ** attempt) + random.uniform(0.5, 1.5)
                logger.warning(f"[Section:{section_id}] JSON Parse Error | Wait {delay:.1f}s")
                # ğŸ”¥ Progress: JSON íŒŒì‹± ì—ëŸ¬ ì¬ì‹œë„
                if job_id:
                    await job_store.section_retry(job_id, section_id, "json_parse_error", delay)
                if attempt < max_retries - 1:
                    await asyncio.sleep(delay)
                    
            except Exception as e:
                last_error = e
                logger.error(f"[Section:{section_id}] ì—ëŸ¬: {type(e).__name__}: {str(e)[:200]}")
                raise
        
        raise last_error or Exception("Unknown error")
    
    async def _generate_section_with_guardrail(
        self,
        section_id: str,
        saju_data: Dict[str, Any],
        allocation: SectionRuleCardAllocation,
        target_year: int,
        user_question: str,
        max_regeneration: int = 2,
        job_id: Optional[str] = None,
        survey_context: str = "",  # ğŸ”¥ v7: ì„¤ë¬¸ ì»¨í…ìŠ¤íŠ¸
        engine_headline: str = ""  # âœ… Top1 ë£°ì¹´ë“œ ê²°ë¡  ê³ ì •
    ) -> Dict[str, Any]:
        """ì„¹ì…˜ ìƒì„± + ê°€ë“œë ˆì¼ ê²€ì¦ + í’ˆì§ˆ ê²Œì´íŠ¸ + ìë™ ì¬ìƒì„±"""
        
        async with self._semaphore:
            start_time = time.time()
            spec = PREMIUM_SECTIONS.get(section_id)
            
            # ğŸ”¥ Progress: ì„¹ì…˜ ì‹œì‘
            if job_id:
                await job_store.section_start(job_id, section_id)
            
            system_prompt = get_section_system_prompt(section_id, target_year, survey_context, engine_headline=engine_headline)
            user_prompt = get_section_user_prompt(section_id, saju_data, allocation, target_year, user_question)
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            response_format = get_section_schema(section_id)
            
            logger.info(f"[Section:{section_id}] ì‹œì‘ | RuleCards={allocation.allocated_count}ì¥")
            
            for regen_attempt in range(max_regeneration + 1):
                content = await self._call_with_retry(
                    messages=messages,
                    section_id=section_id,
                    response_format=response_format,
                    max_retries=3,
                    base_delay=2.0,
                    job_id=job_id
                )
                
                # ğŸ”¥ Progress: ê°€ë“œë ˆì¼ ê²€ì¦
                if job_id:
                    await job_store.section_stage(job_id, section_id, "guardrail_check")
                
                # ğŸ”¥ ê°€ë“œë ˆì¼ ê²€ì¦
                
                # âœ… ì—”ì§„ í—¤ë“œë¼ì¸ ê°•ì œ: ì²« ë¬¸ì¥ì€ Top1 ë£°ì¹´ë“œ interpretationì„ ê·¸ëŒ€ë¡œ
                if engine_headline:
                    try:
                        head = engine_headline.strip()
                        body_now = (content.get("body_markdown") or "")
                        if body_now:
                            body_stripped = body_now.lstrip()
                            if not body_stripped.startswith(head):
                                content["body_markdown"] = f"{head}\n\n{body_stripped}"
                        else:
                            content["body_markdown"] = head
                    except Exception as _e:
                        pass

                body_text = content.get("body_markdown", "")
                is_valid, errors = validate_language_and_topic(body_text, section_id)
                
                # ğŸ”¥ v7: í’ˆì§ˆ ê²Œì´íŠ¸ ê²€ì¦ (ê¸ˆì§€ì–´/êµ¬ì²´ì„±/ì¤‘ë³µ)
                quality_report = quality_gate.check_section(
                    section_id=section_id,
                    content=body_text,
                    existing_contents=[]  # TODO: ì´ì „ ì„¹ì…˜ ë‚´ìš© ì „ë‹¬
                )
                
                if not quality_report.passed:
                    is_valid = False
                    # ğŸ”¥ P0-4: banned_phraseì— ìƒì„¸ ì •ë³´ ì¶”ê°€
                    for issue in quality_report.issues[:3]:
                        if issue.type == "banned_phrase":
                            errors.append(f"QUALITY_GATE:banned_phrase({issue.content})")
                        else:
                            errors.append(f"QUALITY_GATE:{issue.type}")
                    logger.warning(f"[Section:{section_id}] í’ˆì§ˆ ê²Œì´íŠ¸ ì ìˆ˜: {quality_report.score}/100")
                
                if is_valid:
                    logger.info(f"[Section:{section_id}] âœ… ê°€ë“œë ˆì¼ í†µê³¼")
                    break
                else:
                    if regen_attempt < max_regeneration:
                        logger.warning(
                            f"[Section:{section_id}] âš ï¸ ê°€ë“œë ˆì¼ ì‹¤íŒ¨ ({regen_attempt + 1}/{max_regeneration}) | "
                            f"Errors: {errors} â†’ ì¬ìƒì„± ì¤‘..."
                        )
                        # ì¬ìƒì„± ì‹œ ë” ê°•í•œ ê²½ê³  ì¶”ê°€
                        messages[1]["content"] += f"\n\nâš ï¸ ì´ì „ ì‘ë‹µì´ ê°€ë“œë ˆì¼ì„ ìœ„ë°˜í–ˆìŠµë‹ˆë‹¤: {errors}. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ, ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
                    else:
                        logger.error(f"[Section:{section_id}] âŒ ê°€ë“œë ˆì¼ ìµœì¢… ì‹¤íŒ¨ | Errors: {errors}")
            
            latency_ms = int((time.time() - start_time) * 1000)
            
            # ğŸ”¥ P0-2: ok í•„ë“œ ëª…í™•íˆ ë°˜í™˜ (is_valid ê¸°ë°˜)
            return {
                "ok": is_valid,  # ğŸ”¥ í•µì‹¬: ê°€ë“œë ˆì¼ í†µê³¼ ì—¬ë¶€
                "content": content, 
                "latency_ms": latency_ms, 
                "guardrail_errors": errors if not is_valid else []
            }
    
    async def build_premium_report(
        self,
        saju_data: Dict[str, Any],
        rulecards: List[Dict[str, Any]],
        feature_tags: List[str] = None,
        target_year: int = 2026,
        user_question: str = "",
        name: str = "ê³ ê°",
        mode: str = "premium",
        job_id: Optional[str] = None,
        survey_data: Optional[Dict[str, Any]] = None  # ğŸ”¥ v7: 7ë¬¸í•­ ì„¤ë¬¸ ë°ì´í„°
    ) -> Dict[str, Any]:
        """7ê°œ ì„¹ì…˜ ìˆœì°¨ ìƒì„± (Progress ì§€ì› + í’ˆì§ˆ ê²Œì´íŠ¸)"""
        settings = get_settings()
        start_time = time.time()
        
        self._semaphore = asyncio.Semaphore(1)
        self._client = self._get_client()
        
        if not feature_tags:
            feature_tags = []
        
        # ğŸ”¥ v7: ì„¤ë¬¸ ë°ì´í„° â†’ í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë³€í™˜
        survey_context = ""
        if survey_data:
            try:
                survey = SurveyResponse.from_dict(survey_data)
                survey_context = survey_to_prompt_context(survey)
                logger.info(f"[PremiumReport] ì„¤ë¬¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {len(survey_context)}ì")
            except Exception as e:
                logger.warning(f"[PremiumReport] ì„¤ë¬¸ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
        
        # ğŸ”¥ Progress: Job ì‹œì‘
        if job_id:
            await job_store.start_job(job_id)
        
        # ì „ì—­ Top-100 ì„ ë³„
        global_engine_headline = _extract_engine_headline_from_rulecards(rulecards)
        global_selection = select_global_top100(rulecards, feature_tags, top_limit=100)
        
        logger.info(
            f"[PremiumReport] ========== ì‹œì‘ ==========\n"
            f"  Year={target_year} | Pool={global_selection.original_pool_count} | "
            f"Top100={global_selection.top100_count}"
        )
        
        # ì„¹ì…˜ë³„ RuleCard ë¶„ë°°
        section_ids = list(PREMIUM_SECTIONS.keys())
        allocations: Dict[str, SectionRuleCardAllocation] = {}
        used_card_ids = set()
        
        for sid in section_ids:
            spec = PREMIUM_SECTIONS[sid]
            alloc = allocate_rulecards_to_section(
                top100_cards=global_selection.top100_cards,
                section_id=sid,
                max_cards=spec.max_cards,
                already_used_ids=used_card_ids
            )
            allocations[sid] = alloc
            used_card_ids.update(alloc.allocated_card_ids)
        
        # ì„¹ì…˜ ìƒì„± (ê°€ë“œë ˆì¼ + í’ˆì§ˆ ê²Œì´íŠ¸ í¬í•¨) - ğŸ”¥ ìˆœì°¨ ì²˜ë¦¬ë¡œ ë³€ê²½ (Progress ì§€ì›)
        results = []
        section_headlines = {}  # ğŸ”¥ P0: ì„¹ì…˜ë³„ engine_headline ì €ì¥
        for sid in section_ids:
            try:
                # ğŸ”¥ğŸ”¥ğŸ”¥ P0: ì„¹ì…˜ë³„ Top1 ì¹´ë“œì—ì„œ engine_headline ì¶”ì¶œ
                alloc = allocations[sid]
                section_cards = [c for c in global_selection.top100_cards if c.get("id", c.get("_id", "")) in alloc.allocated_card_ids]
                section_engine_headline = _extract_engine_headline_from_rulecards(section_cards)
                section_headlines[sid] = section_engine_headline
                
                result = await self._generate_section_with_guardrail(
                    section_id=sid,
                    saju_data=saju_data,
                    allocation=alloc,
                    target_year=target_year,
                    user_question=user_question,
                    max_regeneration=2,
                    job_id=job_id,
                    survey_context=survey_context,  # ğŸ”¥ v7: ì„¤ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                    engine_headline=section_engine_headline  # âœ… ì„¹ì…˜ë³„ Top1 ë£°ì¹´ë“œ ê²°ë¡  ê³ ì •
                )
                results.append(result)
                
                # ğŸ”¥ Progress: ì„¹ì…˜ ì™„ë£Œ
                if job_id:
                    char_count = len(result.get("content", {}).get("body_markdown", ""))
                    await job_store.section_done(job_id, sid, char_count)
                    
            except Exception as e:
                results.append(e)
                # ğŸ”¥ Progress: ì„¹ì…˜ ì—ëŸ¬
                if job_id:
                    await job_store.section_error(job_id, sid, str(e)[:200])
        
        # ê²°ê³¼ ìˆ˜ì§‘
        sections = []
        errors = []
        rulecard_meta = {}
        all_used_card_ids = set()
        
        for sid, result in zip(section_ids, results):
            alloc = allocations[sid]
            
            if isinstance(result, Exception):
                errors.append({"section": sid, "error_type": type(result).__name__, "error_message": str(result)[:500]})
                logger.error(f"[PremiumReport] âŒ ì„¹ì…˜ ì‹¤íŒ¨: {sid}")
                sections.append(self._create_error_section(sid, target_year, str(result)[:200]))
            else:
                content = result["content"]
                polished = self._polish_section(content, sid)
                spec = PREMIUM_SECTIONS.get(sid)
                
                section_data = {
                    "id": sid,
                    "title": spec.title if spec else sid,
                    "confidence": polished.get("confidence", "MEDIUM"),
                    "rulecard_ids": alloc.allocated_card_ids,
                    "rulecard_selected": alloc.allocated_count,
                    "body_markdown": polished.get("body_markdown", ""),
                    "char_count": len(polished.get("body_markdown", "")),
                    "latency_ms": result.get("latency_ms", 0),
                    "guardrail_passed": len(result.get("guardrail_errors", [])) == 0,
                    # ğŸ”¥ğŸ”¥ğŸ”¥ P0: engine_headline + top_card_id ì €ì¥
                    "engine_headline": section_headlines.get(sid, ""),
                    "top_card_id": alloc.allocated_card_ids[0] if alloc.allocated_card_ids else ""
                }
                
                # íƒ€ì…ë³„ í•„ë“œ
                if spec.validation_type == "sprint":
                    section_data.update({
                        "mission_statement": polished.get("mission_statement", ""),
                        "phase_1_offer": polished.get("phase_1_offer", {}),
                        "phase_2_funnel": polished.get("phase_2_funnel", {}),
                        "phase_3_content": polished.get("phase_3_content", {}),
                        "phase_4_automation": polished.get("phase_4_automation", {}),
                        "milestones": polished.get("milestones", {}),
                        "risk_scenarios": polished.get("risk_scenarios", []),
                    })
                elif spec.validation_type == "calendar":
                    section_data.update({
                        "annual_theme": polished.get("annual_theme", ""),
                        "annual_revenue_projection": polished.get("annual_revenue_projection", ""),
                        "monthly_plans": polished.get("monthly_plans", []),
                        "quarterly_milestones": polished.get("quarterly_milestones", {}),
                        "peak_months": polished.get("peak_months", []),
                        "risk_months": polished.get("risk_months", []),
                    })
                else:
                    section_data.update({
                        "diagnosis": polished.get("diagnosis", {}),
                        "hypotheses": polished.get("hypotheses", []),
                        "strategy_options": polished.get("strategy_options", []),
                        "recommended_strategy": polished.get("recommended_strategy", {}),
                        "kpis": polished.get("kpis", []),
                        "risks": polished.get("risks", []),
                    })
                
                sections.append(section_data)
                all_used_card_ids.update(alloc.allocated_card_ids)
                logger.info(f"[PremiumReport] âœ… ì„¹ì…˜ ì„±ê³µ: {sid} | Chars={section_data['char_count']}")
            
            rulecard_meta[sid] = {
                "selected_count": alloc.allocated_count,
                "selected_card_ids": alloc.allocated_card_ids
            }
        
        total_latency = int((time.time() - start_time) * 1000)
        total_chars = sum(s.get("char_count", 0) for s in sections)
        unique_cards_used = len(all_used_card_ids)
        
        report = {
            "target_year": target_year,
            "sections": sections,
            "meta": {
                "total_chars": total_chars,
                "mode": "premium_business_30p",
                "generated_at": datetime.now().isoformat(),
                "llm_model": settings.openai_model,
                "section_count": len(sections),
                "success_count": len(sections) - len(errors),
                "error_count": len(errors),
                "latency_ms": total_latency,
                # ğŸ”¥ í•µì‹¬: ìœ ë‹ˆí¬ RuleCard í•©ì‚°
                "rulecards_pool_total": global_selection.original_pool_count,
                "rulecards_top100_selected": global_selection.top100_count,
                "rulecards_unique_used": unique_cards_used,
                "rulecards_by_section": rulecard_meta,
                "feature_tags_count": len(feature_tags),
                "errors": errors if errors else None
            },
            "legacy": self._create_legacy_compat(sections, target_year, name)
        }
        
        logger.info(
            f"[PremiumReport] ========== ì™„ë£Œ ==========\n"
            f"  Sections={len(sections)} | Success={len(sections) - len(errors)}\n"
            f"  ğŸ”¥ RuleCards={unique_cards_used}/{global_selection.original_pool_count}\n"
            f"  Chars={total_chars} | Latency={total_latency}ms"
        )
        
        # ğŸ”¥ Progress: Job ì™„ë£Œ
        if job_id:
            await job_store.complete_job(job_id, report)
        
        # ğŸ”¥ v7: Supabaseì— ìµœì¢… ë¦¬í¬íŠ¸ ì˜êµ¬ ì €ì¥
        try:
            from app.services.supabase_service import supabase_service
            
            # 1) ê° ì„¹ì…˜ì„ report_sections í…Œì´ë¸”ì— ì €ì¥
            for section in sections:
                await supabase_service.save_section(
                    job_id=job_id,
                    section_id=section["id"],
                    content_json=section
                )
            
            # 2) Job ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸ (result_json, saju_json í¬í•¨)
            await supabase_service.complete_job(
                job_id=job_id,
                result_json=report,
                saju_json=saju_data  # ğŸ”¥ ì‚¬ì£¼ ê³„ì‚° ê²°ê³¼ ì €ì¥
            )
            
            logger.info(f"âœ… [Supabase] ë¦¬í¬íŠ¸ ì˜êµ¬ ì €ì¥ ì™„ë£Œ (Job: {job_id}, ì„¹ì…˜: {len(sections)}ê°œ)")
        except Exception as e:
            logger.error(f"âŒ [Supabase] ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        
        return report
    
    async def regenerate_single_section(
        self,
        section_id: str,
        saju_data: Dict[str, Any],
        rulecards: List[Dict[str, Any]],
        feature_tags: List[str] = None,
        target_year: int = 2026,
        user_question: str = "",
        survey_data: Optional[Dict[str, Any]] = None  # ğŸ”¥ v7: ì„¤ë¬¸ ë°ì´í„°
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ì„¹ì…˜ ì¬ìƒì„±"""
        
        # ğŸ”¥ P0-2: RuleCards ì§„ë‹¨ ë¡œê·¸
        logger.info(f"[Section:{section_id}] ì‹œì‘ | RuleCards={len(rulecards)}ì¥, feature_tags={len(feature_tags or [])}ê°œ")
        
        if section_id not in PREMIUM_SECTIONS:
            raise ValueError(f"Invalid section_id: {section_id}")
        
        self._semaphore = asyncio.Semaphore(1)
        self._client = self._get_client()
        
        if not feature_tags:
            feature_tags = []
        
        # ğŸ”¥ v7: ì„¤ë¬¸ ë°ì´í„° â†’ í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë³€í™˜
        survey_context = ""
        if survey_data:
            try:
                survey = SurveyResponse.from_dict(survey_data)
                survey_context = survey_to_prompt_context(survey)
            except Exception as e:
                logger.warning(f"[SingleSection] ì„¤ë¬¸ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
        
        engine_headline = _extract_engine_headline_from_rulecards(rulecards)
        global_selection = select_global_top100(rulecards, feature_tags, top_limit=100)
        spec = PREMIUM_SECTIONS[section_id]
        allocation = allocate_rulecards_to_section(global_selection.top100_cards, section_id, spec.max_cards, set())
        
        try:
            result = await self._generate_section_with_guardrail(
                section_id=section_id,
                saju_data=saju_data,
                allocation=allocation,
                target_year=target_year,
                user_question=user_question,
                max_regeneration=2,
                survey_context=survey_context,  # ğŸ”¥ v7: ì„¤ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                engine_headline=engine_headline  # âœ… Top1 ë£°ì¹´ë“œ ê²°ë¡  ê³ ì •
            )
            
            content = result["content"]
            polished = self._polish_section(content, section_id)
            
            section_data = {
                "id": section_id,
                "title": spec.title,
                "confidence": polished.get("confidence", "MEDIUM"),
                "rulecard_ids": allocation.allocated_card_ids,
                "rulecard_selected": allocation.allocated_count,
                "body_markdown": polished.get("body_markdown", ""),
                "char_count": len(polished.get("body_markdown", "")),
                "latency_ms": result.get("latency_ms", 0),
                "regenerated": True,
                # ğŸ”¥ğŸ”¥ğŸ”¥ P0: engine_headline + top_card_id ì €ì¥
                "engine_headline": engine_headline,
                "top_card_id": allocation.allocated_card_ids[0] if allocation.allocated_card_ids else ""
            }
            
            return {"success": True, "section": section_data}
            
        except Exception as e:
            logger.error(f"[SingleSection] ì‹¤íŒ¨: {section_id} | {str(e)[:200]}")
            return {"success": False, "section_id": section_id, "error": str(e)[:500]}
    
    def _polish_section(self, content: Dict[str, Any], section_id: str) -> Dict[str, Any]:
        if "body_markdown" in content:
            content["body_markdown"] = sanitize_for_business(content["body_markdown"])
        if "diagnosis" in content and isinstance(content["diagnosis"], dict):
            if "current_state" in content["diagnosis"]:
                content["diagnosis"]["current_state"] = sanitize_for_business(content["diagnosis"]["current_state"])
        if "mission_statement" in content:
            content["mission_statement"] = sanitize_for_business(content["mission_statement"])
        if "annual_theme" in content:
            content["annual_theme"] = sanitize_for_business(content["annual_theme"])
        return content
    
    def _create_error_section(self, section_id: str, target_year: int, error_msg: str = "") -> Dict[str, Any]:
        spec = PREMIUM_SECTIONS.get(section_id)
        return {
            "id": section_id,
            "title": spec.title if spec else section_id,
            "confidence": "LOW",
            "rulecard_ids": [],
            "rulecard_selected": 0,
            "body_markdown": f"## {spec.title if spec else section_id}\n\në¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n_Error: {error_msg[:100]}_",
            "char_count": 0,
            "latency_ms": 0,
            "error": True,
            "error_message": error_msg[:200]
        }
    
    def _create_legacy_compat(self, sections: List[Dict[str, Any]], target_year: int, name: str) -> Dict[str, Any]:
        exec_section = next((s for s in sections if s["id"] == "exec"), {})
        strengths = [h.get("statement", "") for h in exec_section.get("hypotheses", []) if h.get("confidence") == "HIGH"][:5]
        risks = [r.get("risk", "") for r in exec_section.get("risks", [])[:3]]
        return {
            "success": True,
            "summary": f"{target_year}ë…„ í”„ë¦¬ë¯¸ì—„ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤íŒ… ë³´ê³ ì„œ",
            "strengths": strengths,
            "risks": risks,
            "blessing": f"{name}ë‹˜ì˜ {target_year}ë…„ ì„±ê³µì„ ì‘ì›í•©ë‹ˆë‹¤!",
            "disclaimer": "ë³¸ ë³´ê³ ì„œëŠ” ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì°¸ê³  ìë£Œì…ë‹ˆë‹¤."
        }


premium_report_builder = PremiumReportBuilder()
report_builder = premium_report_builder
