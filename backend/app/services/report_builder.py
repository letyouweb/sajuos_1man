"""
SajuOS Premium Report Builder v12 - P0 ë¹ˆ ì„¹ì…˜ ì ˆëŒ€ ê¸ˆì§€
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¥ P0-1: ì¹´ë“œ 0ê°œ â†’ LLM í˜¸ì¶œ X, í´ë°± í…ìŠ¤íŠ¸ ì¦‰ì‹œ ë°˜í™˜
ğŸ”¥ P0-2: ì„¹ì…˜ ID ì •í•©ì„± (exec,money,business,team,health,calendar,sprint)
ğŸ”¥ P0-3: í† í° "ì¹˜í™˜" (ì‚­ì œ X) - {industry}â†’"í•´ë‹¹ ì—…ì¢…"
ğŸ”¥ P0-4: ìƒì„± ì‹¤íŒ¨ ì›ì¸ ë¡œê·¸ 4ê°œ í•„ìˆ˜
ğŸ”¥ P0-5: ì§€ì¥ê°„ ì¶”ë¡  ê¸ˆì§€ ë° 'ë³´ì´ëŠ” ê¸€ì' ì¤‘ì‹¬ ê²€ì¦ ê°•í™” (Guardrails í†µí•©)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import asyncio
import json
import logging
import re
from typing import Dict, Any, List, Tuple
from dataclasses import dataclass, field

import httpx
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë§ˆìŠ¤í„° ìƒ˜í”Œ ë¡œë“œ (ì›ë³¸ ìœ ì§€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

try:
    from app.templates.master_samples import load_master_samples
    MASTER_SAMPLES = load_master_samples("v1")
except Exception:
    MASTER_SAMPLES = {}

DEBUG_TEMPLATE_LEAKS = False


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# P0-3: í† í° ì¹˜í™˜ (ì‚­ì œ X)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

TOKEN_REPLACEMENTS = {
    "{industry}": "í•´ë‹¹ ì—…ì¢…",
    "{painPoint}": "í˜„ì¬ ë³‘ëª©",
    "{engine_headline}": "í•µì‹¬ ê²°ë¡ ",
    "{goal}": "ëª©í‘œ",
    "{revenue}": "ë§¤ì¶œ",
    "{day_master}": "ì¼ê°„",
    "{time}": "ì‹œì ",
    "[ENGINE_HEADLINE]": "",
    "[/ENGINE_HEADLINE]": "",
}


def replace_template_tokens(text: str) -> str:
    """ğŸ”¥ P0-3: í† í° ì¹˜í™˜ (ì‚­ì œê°€ ì•„ë‹Œ ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´)"""
    if not text:
        return ""
    if DEBUG_TEMPLATE_LEAKS:
        return text.strip()
    for token, replacement in TOKEN_REPLACEMENTS.items():
        text = text.replace(token, replacement)
    text = re.sub(r"\{[a-zA-Z_]+\}", "í•´ë‹¹ í•­ëª©", text)
    return text.strip()


def normalize_year(text: str, target_year: int) -> str:
    """ì¶œë ¥ì— ì„ì¸ ì—°ë„(ì˜ˆ: 2025)ë¥¼ target_yearë¡œ ì •ê·œí™”.
    - target_year ìì²´ëŠ” ìœ ì§€
    - ë‹¤ë¥¸ 20xxëŠ” target_yearë¡œ ì¹˜í™˜
    """
    if not text:
        return ""
    def _repl(m: re.Match) -> str:
        y = int(m.group(0))
        return str(target_year) if y != target_year else m.group(0)
    return re.sub(r"\b20\d{2}\b", _repl, text)


def check_template_leaks(text: str, context: str = "") -> List[str]:
    if not text:
        return []
    leaked = []
    for token in TOKEN_REPLACEMENTS.keys():
        if token in text:
            leaked.append(token)
    if re.search(r"\{[a-zA-Z_]+\}", text):
        leaked.append("{other}")
    if leaked:
        logger.warning(f"[TemplateLeak] context={context} leaked={leaked}")
    return leaked


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í”„ë¦¬ë¯¸ì—„ ì„¹ì…˜ ì •ì˜ (ì›ë³¸ ìœ ì§€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class SectionSpec:
    id: str
    title: str
    icon: str
    order: int
    min_chars: int = 800


PREMIUM_SECTIONS: Dict[str, SectionSpec] = {
    "exec": SectionSpec(id="exec", title="ì „ëµê¸°ìƒë„", icon="ğŸŒ¦ï¸", order=1, min_chars=900),
    "money": SectionSpec(id="money", title="í˜„ê¸ˆíë¦„", icon="ğŸ’°", order=2, min_chars=900),
    "business": SectionSpec(id="business", title="ì‹œì¥ì „ëµ", icon="ğŸ“", order=3, min_chars=900),
    "team": SectionSpec(id="team", title="íŒŒíŠ¸ë„ˆì‹­", icon="ğŸ¤", order=4, min_chars=900),
    "health": SectionSpec(id="health", title="ë¦¬ìŠ¤í¬", icon="ğŸ§¯", order=5, min_chars=900),
    "calendar": SectionSpec(id="calendar", title="12ê°œì›”", icon="ğŸ—“ï¸", order=6, min_chars=900),
    "sprint": SectionSpec(id="sprint", title="90ì¼í”Œëœ", icon="ğŸš€", order=7, min_chars=900),
}


def get_master_body_markdown(section_id: str) -> str:
    if not MASTER_SAMPLES:
        return ""
    sample = MASTER_SAMPLES.get(section_id) or {}
    body = sample.get("body_markdown") or ""
    return body.strip()


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# P0 Guardrails (ì›ë³¸ ìœ ì§€ + ìµœì†Œ ì•ˆì „ì¥ì¹˜)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

PROHIBITED_INFER = [
    "ì§€ì¥ê°„", "ì¥ê°„", "ì¶”ë¡ ", "ì¶”ì¸¡", "ëª°ë˜", "ìˆ¨ê²¨ì§„",
]


def build_truth_anchor(saju_data: Dict[str, Any]) -> str:
    """'ë³´ì´ëŠ” ê¸€ì' ê¸°ë°˜ì˜ ì‚¬ì‹¤ ì•µì»¤"""
    if not saju_data:
        return "ì›êµ­ ë°ì´í„°ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    pillars = saju_data.get("pillars") or {}
    # ê°€ëŠ¥í•œ í•œ ì‚¬ìš©ìì—ê²Œ ë³´ì´ëŠ” ê°’ë§Œ ì‚¬ìš©
    parts = []
    for k in ["year", "month", "day", "hour"]:
        v = pillars.get(k)
        if isinstance(v, dict):
            parts.append(f"{k}:{v.get('stem','')}{v.get('branch','')}".strip())
        elif isinstance(v, str):
            parts.append(f"{k}:{v}")
    return " / ".join([p for p in parts if p]) or "ì›êµ­(ì—°ì›”ì¼ì‹œ) ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤."


def build_fact_check_context(saju_data: Dict[str, Any]) -> str:
    """ê²€ì¦ìš© ì»¨í…ìŠ¤íŠ¸(ìµœì†Œ)"""
    anchor = build_truth_anchor(saju_data)
    return f"[ì‚¬ì‹¤ ì•µì»¤]\n{anchor}\n"


def detect_guardrail_violations(text: str, saju_data: Dict[str, Any]) -> List[str]:
    if not text:
        return ["empty_output"]
    v = []
    # ì§€ì¥ê°„/ì¶”ë¡  ê¸ˆì§€
    for w in PROHIBITED_INFER:
        if w in text:
            v.append(f"prohibited:{w}")
    # í…œí”Œë¦¿ í† í° ìœ ì¶œ
    v += [f"template:{t}" for t in check_template_leaks(text, context="guardrail")]
    return v


def sanitize_output_last_resort(text: str, saju_data: Dict[str, Any]) -> str:
    """ìµœí›„ ìˆ˜ë‹¨: ìœ„í—˜ ë‹¨ì–´ ì œê±° + í…œí”Œë¦¿ í† í° ì¹˜í™˜"""
    if not text:
        return ""
    for w in PROHIBITED_INFER:
        text = text.replace(w, "í•´ì„")
    text = replace_template_tokens(text)
    return text.strip()


def build_system_prompt(
    section_id: str,
    engine_headline: str,
    survey_data: Dict[str, Any] = None,
    saju_data: Dict[str, Any] = None,
    existing_contents: List[str] = None,
    cards_summary: str = "",
) -> str:
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        return ""
    title = spec.title
    min_chars = spec.min_chars
    master_body = get_master_body_markdown(section_id)

    saju_summary = (saju_data or {}).get("saju_summary", {})
    summary_json = json.dumps(saju_summary, ensure_ascii=False, indent=2) if saju_summary else "{}"

    truth_anchor = build_truth_anchor(saju_data or {})
    fact_ctx = build_fact_check_context(saju_data or {})

    existing_text = ""
    if existing_contents:
        existing_text = "\n\n".join([c[:1200] for c in existing_contents if c])

    return f"""ë„ˆëŠ” [{title}] ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ë‹¤.

[ëª©í‘œ]
- ìµœì†Œ {min_chars}ì ì´ìƒìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ë¼.
- "ë³´ì´ëŠ” ê¸€ì" ê¸°ë°˜ ì‚¬ì‹¤ë§Œ ì‚¬ìš©í•˜ê³ , ì§€ì¥ê°„/ì¥ê°„ ë“± ì¶”ë¡  ê¸ˆì§€.
- í…œí”Œë¦¿ í† í°({{industry}} ë“±)ì„ ì ˆëŒ€ ë…¸ì¶œí•˜ì§€ ë§ˆë¼.

[ì—”ì§„ í—¤ë“œë¼ì¸]
{engine_headline or ""}

[ì‚¬ì‹¤ ì•µì»¤]
{truth_anchor}

[ê²€ì¦ ì»¨í…ìŠ¤íŠ¸]
{fact_ctx}

[ì‚¬ì£¼ ìš”ì•½ JSON]
{summary_json}

[ì„¤ë¬¸ ë°ì´í„°]
{json.dumps(survey_data or {{}}, ensure_ascii=False, indent=2)}

[ê¸°ì¡´ ì„¹ì…˜(ì¤‘ë³µ ë°©ì§€/ì—°ê²°)]
{existing_text}

[ë§ˆìŠ¤í„° ìƒ˜í”Œ(ì°¸ê³ )]
{master_body}

[ì‘ì„± ê·œì¹™]
- ë¬¸ì¥ìœ¼ë¡œ ëª…í™•íˆ, ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ í¬í•¨.
- ê³¼ë„í•œ ë‹¨ì • ê¸ˆì§€. ëŒ€ì‹  'ê°€ëŠ¥ì„±/ê²½í–¥' í‘œí˜„.
- ê¸ˆì§€ ë‹¨ì–´(ì§€ì¥ê°„/ì¶”ë¡  ë“±) ì‚¬ìš© ê¸ˆì§€.
"""


def generate_fallback_body(section_id: str, engine_headline: str, survey_data: Dict[str, Any]) -> str:
    """LLM ì‹¤íŒ¨/ë¶ˆì™„ì „ ì‹œì—ë„ ë¬´ì¡°ê±´ ë³¸ë¬¸ ìƒì„± (P0)"""
    spec = PREMIUM_SECTIONS.get(section_id)
    title = spec.title if spec else section_id
    industry = (survey_data or {}).get("industry") or "í•´ë‹¹ ì—…ì¢…"
    goal = (survey_data or {}).get("goal") or "ëª©í‘œ"
    pain = (survey_data or {}).get("painPoint") or "í˜„ì¬ ë³‘ëª©"

    return f"""# {spec.icon if spec else "ğŸ“Œ"} {title}

> í•µì‹¬ ê²°ë¡ : {engine_headline or "í•µì‹¬ ê²°ë¡ ì„ ì •ë¦¬ ì¤‘ì…ë‹ˆë‹¤. (ìë™ í´ë°±)"}

## í˜„ì¬ ìƒí™©(ìš”ì•½)
- ì—…ì¢…: {industry}
- ëª©í‘œ: {goal}
- ë³‘ëª©: {pain}

## ë°”ë¡œ ì ìš©í•  ì•¡ì…˜(ì˜¤ëŠ˜ ê°€ëŠ¥í•œ ê²ƒë§Œ)
1) **ë°ì´í„° 1ê°œë§Œ ì •ë¦¬**: ìµœê·¼ 30ì¼ ë§¤ì¶œ/ìœ ì…/ë¬¸ì˜/ì „í™˜ ì¤‘ 1ê°œë¥¼ ê³ ì • ì§€í‘œë¡œ ì„ íƒí•˜ê³  ë§¤ì¼ ê¸°ë¡í•©ë‹ˆë‹¤.
2) **ë³‘ëª© 1ê°œë§Œ ì œê±°**: "{pain}"ì„ ë°©í•´í•˜ëŠ” ê°€ì¥ í° ì›ì¸ì„ 1ê°œ ê³ ë¥´ê³ , ì˜¤ëŠ˜ 30ë¶„ ì•ˆì— ì¤„ì¼ ìˆ˜ ìˆëŠ” ì¡°ì¹˜ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
3) **ê²°ì • ë£¨í‹´ ê³ ì •**: ì˜¤ì „(ë˜ëŠ” ì—…ë¬´ ì‹œì‘ ì§í›„) 10ë¶„ ë™ì•ˆ 'ì˜¤ëŠ˜ì˜ 1ìˆœìœ„'ë¥¼ ëª…í™•íˆ ì ê³ , ê·¸ ì™¸ëŠ” ë³´ë¥˜í•©ë‹ˆë‹¤.

## ë¦¬ìŠ¤í¬ & ì£¼ì˜
- ë³¸ ì„¹ì…˜ì€ LLM ìƒì„±ì´ ì‹¤íŒ¨í•´ë„ ê²°ê³¼ê°€ ë¹„ì§€ ì•Šë„ë¡ ë§Œë“  ìë™ í´ë°±ì…ë‹ˆë‹¤.
- ì¶”ê°€ ì…ë ¥(ë§¤ì¶œ ê·œëª¨/ê³ ê°êµ°/ì±„ë„/ê°€ê²©/íŒ€ ìƒí™©)ì´ ìˆìœ¼ë©´ ë” ì •ë°€í•œ ì‹¤í–‰ í”Œëœìœ¼ë¡œ ê°•í™” ê°€ëŠ¥í•©ë‹ˆë‹¤.
"""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# OpenAI Key Provider (ì›ë³¸ ìœ ì§€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def get_openai_api_key() -> str:
    try:
        from app.config import settings
        return settings.OPENAI_API_KEY
    except Exception:
        return ""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Builder
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class PremiumReportBuilder:
    def __init__(self, max_concurrency: int = 3):
        self._semaphore = asyncio.Semaphore(max_concurrency)
        self._client = self._get_client()

    def _get_client(self) -> AsyncOpenAI:
        api_key = get_openai_api_key()
        return AsyncOpenAI(api_key=api_key, timeout=httpx.Timeout(120.0, connect=15.0), max_retries=2)

    async def _repair_output_once(
        self,
        section_id: str,
        system_prompt: str,
        draft_markdown: str,
        violations: List[str],
        min_chars: int,
    ) -> str:
        """ê·œì¹™ ìœ„ë°˜ ì‹œ 1íšŒ ë¦¬ë¼ì´íŠ¸ ìˆ˜ì •"""
        if not draft_markdown:
            return ""
        try:
            repair_user = f"""ë„ˆëŠ” ì•„ë˜ ì´ˆì•ˆì„ 'ê·œì¹™ ìœ„ë°˜ì„ ì œê±°'í•˜ì—¬ ë‹¤ì‹œ ì‘ì„±í•œë‹¤.
[ìœ„ë°˜ ëª©ë¡]
{chr(10).join(f"- {v}" for v in violations)}
[ì´ˆì•ˆ]
{draft_markdown}
"""
            response = await self._client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": repair_user},
                ],
                temperature=0.2,
                max_tokens=1800,
            )
            out = (response.choices[0].message.content or "").strip()
            if len(out) < min_chars:
                return draft_markdown
            return out
        except Exception as e:
            logger.error(f"[Builder] repair ì‹¤íŒ¨ section={section_id}: {e}")
            return draft_markdown

    async def build_premium_sections(
        self,
        saju_data: Dict[str, Any],
        survey_data: Dict[str, Any],
        engine_headline: str,
        target_year: int = 2026,
        job_id: str = None,
    ) -> List[Dict[str, Any]]:
        """7ê°œ ì„¹ì…˜ ëª¨ë‘ ìƒì„±. P0: ì ˆëŒ€ ë¹ˆ ì„¹ì…˜ ê¸ˆì§€"""
        sections = []
        existing_contents: List[str] = []

        for section_id in ["exec", "money", "business", "team", "health", "calendar", "sprint"]:
            try:
                s = await self._generate_section_safe(
                    section_id=section_id,
                    saju_data=saju_data,
                    survey_data=survey_data,
                    target_year=target_year,
                    engine_headline=engine_headline,
                    existing_contents=existing_contents,
                    job_id=job_id,
                )
            except Exception as e:
                logger.error(f"[Builder] ì„¹ì…˜ ìƒì„± ì‹¤íŒ¨ section={section_id} job_id={job_id}: {e}")
                s = {
                    "section_id": section_id,
                    "title": PREMIUM_SECTIONS.get(section_id).title if PREMIUM_SECTIONS.get(section_id) else section_id,
                    "body_markdown": generate_fallback_body(section_id, engine_headline, survey_data or {}),
                    "char_count": 0,
                    "llm_response_len": 0,
                    "guardrail_violations": ["exception_fallback"],
                    "repaired": False,
                }
            sections.append(s)
            existing_contents.append((s.get("body_markdown") or "")[:1500])

        # ì •ë ¬
        sections.sort(key=lambda x: PREMIUM_SECTIONS.get(x["section_id"]).order if PREMIUM_SECTIONS.get(x["section_id"]) else 999)
        return sections

    async def _generate_section_safe(
        self,
        section_id: str,
        saju_data: Dict[str, Any],
        survey_data: Dict[str, Any],
        target_year: int,
        engine_headline: str,
        existing_contents: List[str],
        job_id: str = None,
    ) -> Dict[str, Any]:
        spec = PREMIUM_SECTIONS.get(section_id)
        system_prompt = build_system_prompt(section_id, engine_headline, survey_data, saju_data, existing_contents)
        user_prompt = f"## ì‚¬ì£¼ ì›êµ­ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ì‘ì„± ë¶€íƒë“œë¦½ë‹ˆë‹¤. ({target_year}ë…„)"

        llm_response_len = 0
        body_markdown = ""
        try:
            async with self._semaphore:
                response = await self._client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    temperature=0.3,
                    max_tokens=1800,
                )
                body_markdown = (response.choices[0].message.content or "").strip()
                llm_response_len = len(body_markdown)
        except Exception as e:
            logger.error(f"[Builder] LLM í˜¸ì¶œ ì‹¤íŒ¨ section={section_id} job_id={job_id}: {e}")
            body_markdown = generate_fallback_body(section_id, engine_headline, survey_data or {}) or ""
            llm_response_len = 0

        # âœ… ê²°ê³¼ê°€ ë¹„ê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´(ë¶ˆì™„ì „) fallbackìœ¼ë¡œ êµì²´
        min_chars = spec.min_chars if spec else 800
        if (not body_markdown) or (len(body_markdown) < min_chars):
            body_markdown = generate_fallback_body(section_id, engine_headline, survey_data or {}) or body_markdown

        # â”€â”€ P0 Guardrail ê²€ì¦ ë° ìˆ˜ì • â”€â”€
        violations = detect_guardrail_violations(body_markdown, saju_data or {})
        repaired = False
        if violations:
            logger.warning(f"[Builder] Guardrail ìœ„ë°˜ íƒì§€: {violations}")
            repaired_text = await self._repair_output_once(section_id, system_prompt, body_markdown, violations, min_chars)
            if repaired_text != body_markdown:
                repaired = True
                body_markdown = repaired_text

            # 2ì°¨ ê²€ì¦ ì‹¤íŒ¨ ì‹œ ìµœí›„ ìˆ˜ë‹¨
            violations2 = detect_guardrail_violations(body_markdown, saju_data or {})
            if violations2:
                body_markdown = sanitize_output_last_resort(body_markdown, saju_data or {})

        body_markdown = replace_template_tokens(body_markdown)
        body_markdown = normalize_year(body_markdown, target_year)

        return {
            "section_id": section_id,
            "title": spec.title if spec else section_id,
            "body_markdown": body_markdown,
            "char_count": len(body_markdown),
            "llm_response_len": llm_response_len,
            "guardrail_violations": violations,
            "repaired": repaired,
        }

    # (ê¸°íƒ€ Helper í•¨ìˆ˜ë“¤ì€ ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
    async def regenerate_single_section(
        self,
        section_id: str,
        saju_data: Dict[str, Any],
        survey_data: Dict[str, Any],
        target_year: int,
        engine_headline: str,
        existing_contents: List[str],
        job_id: str = None,
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ì„¹ì…˜ ì¬ìƒì„±"""
        return await self._generate_section_safe(
            section_id=section_id,
            saju_data=saju_data,
            survey_data=survey_data,
            target_year=target_year,
            engine_headline=engine_headline,
            existing_contents=existing_contents or [],
            job_id=job_id,
        )
