"""
report_builder.py
Premium section generator:
- Uses master sample markdown per section
- Uses selected RuleCards
- Injects dynamic Truth Anchor to prevent hallucinations
- ðŸ”¥ P0: LLM ê±°ì ˆ ì‘ë‹µ ê°ì§€ ì‹œ 1íšŒ ìžë™ ìž¬ì‹œë„
"""

from __future__ import annotations

import json
import logging
import os
import re
import time
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import httpx

from app.services.truth_anchor import build_truth_anchor

logger = logging.getLogger(__name__)


# -----------------------------
# Section specs
# -----------------------------

@dataclass(frozen=True)
class SectionSpec:
    section_id: str
    title: str
    min_chars: int = 800


# Keep aligned with UI tabs / MasterSamples keys
PREMIUM_SECTIONS: Dict[str, SectionSpec] = {
    "business": SectionSpec("business", "ì‚¬ì—…/ì „ëžµ ê¸°ìƒë„", 900),
    "money": SectionSpec("money", "í˜„ê¸ˆíë¦„", 900),
    "team": SectionSpec("team", "íŒŒíŠ¸ë„ˆì‹­/íŒ€", 800),
    "health": SectionSpec("health", "ì˜¤ë„ˆ ë¦¬ìŠ¤í¬", 700),
    "calendar": SectionSpec("calendar", "12ê°œì›” ìº˜ë¦°ë”", 800),
    "sprint": SectionSpec("sprint", "12ê°œì›” ìŠ¤í”„ë¦°íŠ¸", 900),
    "exec": SectionSpec("exec", "90ì¼ ì‹¤í–‰ í”Œëžœ", 900),
}

# -----------------------------
# ðŸ”¥ P0: ê±°ì ˆ íŒ¨í„´ ê°ì§€
# -----------------------------

REJECTION_PATTERNS = [
    "ì£„ì†¡",
    "ì¶”ê°€ ì •ë³´",
    "ì¶”ê°€ì •ë³´",
    "ìž‘ì„±í•  ìˆ˜ ì—†",
    "ìž‘ì„±ì´ ì–´ë µ",
    "ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ",
    "ë¶„ì„í•  ìˆ˜ ì—†",
    "ë¶„ì„ì´ ì–´ë µ",
    "ì •ë³´ê°€ ë¶€ì¡±",
    "ë” ë§Žì€ ì •ë³´",
    "êµ¬ì²´ì ì¸ ì •ë³´",
]


def _detect_rejection(text: str) -> Tuple[bool, List[str]]:
    """LLM ì‘ë‹µì—ì„œ ê±°ì ˆ íŒ¨í„´ ê°ì§€"""
    if not text:
        return True, ["empty_response"]
    
    found = []
    for pattern in REJECTION_PATTERNS:
        if pattern in text:
            found.append(pattern)
    
    return len(found) > 0, found


# -----------------------------
# Prompt rules (P0) - ðŸ”¥ í†¤ ë³€ê²½: "ì‹¤íŒ¨" â†’ "ëŒ€ì²´ ì¶œë ¥"
# -----------------------------

ENGINE_HEADLINE = "ì²« ë¬¸ìž¥ = ENGINE_HEADLINE. ìˆ˜ì •/ë¶€ì •/í¬ì„ ê¸ˆì§€."

ROOT_CAUSE_RULE = """## ðŸ§  Root Cause Rule (í•µì‹¬ ì›ì¹™)
1) ê²°ë¡ (ì›ì¸)ì€ ë°˜ë“œì‹œ 'ì‚¬ì£¼/ë£°ì¹´ë“œ'ì—ì„œ ì‹œìž‘í•œë‹¤. ì„¤ë¬¸ì€ 'ì¦ìƒ'ì´ë‹¤.
2) ì„¤ë¬¸(industry/painPoint/goal/time)ì€ "í˜„ìž¥ì—ì„œ ì–´ë–»ê²Œ ë“œëŸ¬ë‚¬ëŠ”ì§€" ì„¤ëª…ì—ë§Œ ì‚¬ìš©í•œë‹¤.
3) ê¸ˆì§€: "ê³ ê°ë‹˜ì´ ì„¤ë¬¸ì—ì„œ ~ë¼ê³  í•˜ì…”ì„œ"ë¥¼ ì›ì¸ìœ¼ë¡œ í™•ì •í•˜ëŠ” ì„œìˆ .
4) ì •ë‹µ íŒ¨í„´: "ì›êµ­/ë£°ì¹´ë“œ êµ¬ì¡°(ì›ì¸) ë•Œë¬¸ì— {industry} í˜„ìž¥ì—ì„œ {painPoint}ë¡œ ë°œí˜„(ì¦ìƒ)"
5) ì²« ë¬¸ìž¥ = ENGINE_HEADLINE. ìˆ˜ì •/ë¶€ì •/í¬ì„ ê¸ˆì§€.
"""

# ðŸ”¥ P0 FIX: "ìœ„ë°˜ì‹œ ì‹¤íŒ¨" ì œê±°, "ëŒ€ì²´ ì¶œë ¥" ë°©ì‹ìœ¼ë¡œ ë³€ê²½
DATA_COMPLIANCE_RULE = """## ðŸ“‹ ë°ì´í„° ì¤€ìˆ˜ ê·œì¹™ (ì¶œë ¥ ì§€ì†)
1) saju_summaryì— ì—†ëŠ” ì˜¤í–‰/ì‹­ì„±ì„ "ìžˆë‹¤"ê³  ë‹¨ì •í•˜ì§€ ë§ˆë¼. â†’ ì—†ìœ¼ë©´ "(ë¯¸í™•ì¸)" í‘œê¸° í›„ ê³„ì† ìž‘ì„±.
2) is_missing_jaesung=trueë©´ ì •ìž¬/íŽ¸ìž¬ "ìžˆë‹¤" ê¸ˆì§€ â†’ "í˜„ê¸ˆíë¦„ ë³´ì™„ ì „ëžµ"ìœ¼ë¡œ ëŒ€ì²´ ì„œìˆ .
3) is_missing_shiksang=trueë©´ ì‹ì‹ /ìƒê´€ "ìžˆë‹¤" ê¸ˆì§€ â†’ "ë§ˆì¼€íŒ…/í‘œí˜„ë ¥ ê°•í™” ë°©ì•ˆ"ìœ¼ë¡œ ëŒ€ì²´ ì„œìˆ .
4) ëª¨ë¥´ëŠ” ê²©êµ­ì€ "(ê²©êµ­ ë¯¸í™•ì¸)" í‘œê¸° í›„ ì¼ë°˜ ì „ëžµìœ¼ë¡œ ê³„ì† ìž‘ì„±.
5) ì§€ìž¥ê°„/ìˆ¨ì€ ì‹­ì„± ì¶”ë¡  ê¸ˆì§€ â†’ í™•ì¸ëœ ë°ì´í„°ë§Œ ì‚¬ìš©.

âš ï¸ ì¤‘ìš”: ìž…ë ¥ì´ ë¹„ì–´ë„ ìž‘ì„±ì€ ë°˜ë“œì‹œ ì§„í–‰í•œë‹¤.
- ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ 'ê°€ì •' ë˜ëŠ” '(í™•ì¸ í•„ìš”)'ë¡œ í‘œê¸°
- 2~3ê°œ í™•ì¸ ì§ˆë¬¸ì€ ë³¸ë¬¸ ë§¨ ëì—ë§Œ ì¶”ê°€ (ì‚¬ê³¼/ê±°ì ˆ ê¸ˆì§€)
"""

# ðŸ”¥ P0: ìž¬ì‹œë„ìš© ê°•í™” í”„ë¡¬í”„íŠ¸ (ê±°ì ˆ ë°©ì§€)
NO_REJECTION_RULE = """## ðŸš« ì ˆëŒ€ ê¸ˆì§€ (ì‚¬ê³¼/ê±°ì ˆ ê¸ˆì§€)
- "ì£„ì†¡í•©ë‹ˆë‹¤", "ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤", "ìž‘ì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ë“± ê±°ì ˆ ë¬¸êµ¬ ì ˆëŒ€ ê¸ˆì§€.
- ì •ë³´ê°€ ë¶€ì¡±í•´ë„ ë°˜ë“œì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ í”Œëžœì„ ìž‘ì„±í•œë‹¤.
- ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ "[ê°€ì •]" ë˜ëŠ” "[í™•ì¸ í•„ìš”]"ë¡œ í‘œê¸°í•˜ê³  ê³„ì† ìž‘ì„±.
- ë³¸ë¬¸ì€ ìµœì†Œ 800ìž ì´ìƒ, ì‹¤í–‰ ì•¡ì…˜ 3~7ê°œ í¬í•¨ í•„ìˆ˜.
- ì§ˆë¬¸ì´ ìžˆìœ¼ë©´ ë³¸ë¬¸ ë§¨ ë "ðŸ’¡ í™•ì¸ ì‚¬í•­" ì„¹ì…˜ì—ë§Œ 2~3ê°œ ì¶”ê°€.
"""


class _SafeDict(dict):
    def __missing__(self, key):
        return "ë¯¸ìž…ë ¥"


def _safe_format(template: str, vars: Dict[str, Any]) -> str:
    if not template:
        return ""
    try:
        out = template.format_map(_SafeDict(vars))
    except Exception:
        out = template
    out = re.sub(r"\{[a-zA-Z0-9_]+\}", "ë¯¸ìž…ë ¥", out)
    return out


# -----------------------------
# Master sample loader (optional)
# -----------------------------

def get_master_body_markdown(section_id: str) -> str:
    """Optional: loads master sample markdown. If unavailable, returns empty."""
    try:
        from app.templates.master_samples.index import get_master_sample  # type: ignore
        sample = get_master_sample(section_id)
        return sample.get("body_markdown") or sample.get("markdown") or ""
    except Exception:
        return ""


# -----------------------------
# System prompt builder
# -----------------------------

def build_system_prompt(
    section_id: str,
    saju_data: Dict[str, Any],
    rulecards: List[Dict[str, Any]],
    survey_data: Dict[str, Any],
    target_year: int,
    user_question: str = "",
    existing_contents: Optional[List[str]] = None,
    truth_anchor_override: Optional[str] = None,
    is_retry: bool = False,  # ðŸ”¥ ìž¬ì‹œë„ ì—¬ë¶€
) -> str:
    spec = PREMIUM_SECTIONS.get(section_id) or SectionSpec(section_id, section_id, 800)
    title = spec.title
    min_chars = spec.min_chars
    master_body = get_master_body_markdown(section_id)

    # dynamic truth anchor
    if truth_anchor_override:
        truth_anchor = truth_anchor_override
    else:
        truth_anchor = build_truth_anchor(
            saju_data=saju_data,
            target_year=target_year,
            section_id=section_id,
        )

    # compact rulecards text (top 8)
    cards_text = []
    for i, c in enumerate(rulecards[:8]):
        cards_text.append(
            f"[{i+1}] topic={c.get('topic','')}\n"
            f"- interpretation: {c.get('interpretation','')}\n"
            f"- action: {c.get('action','')}\n"
        )
    cards_block = "\n".join(cards_text).strip()

    # survey facts (ë¹„ì–´ë„ OK)
    industry = survey_data.get("industry") or "(ë¯¸ìž…ë ¥ - ì¼ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ë¡œ ê°€ì •)"
    pain = user_question or survey_data.get("painPoint") or "(ë¯¸ìž…ë ¥ - ì„±ìž¥/ìˆ˜ìµ ê°œì„ ìœ¼ë¡œ ê°€ì •)"
    goal = survey_data.get("goal") or "(ë¯¸ìž…ë ¥ - ì•ˆì •ì  ì„±ìž¥ìœ¼ë¡œ ê°€ì •)"
    timeframe = survey_data.get("time") or "(ë¯¸ìž…ë ¥ - 12ê°œì›”ë¡œ ê°€ì •)"

    # ground truth summary json
    summary = saju_data.get("saju_summary") or {}
    summary_json = json.dumps(summary, ensure_ascii=False, indent=2)

    existing = "\n\n".join(existing_contents or [])
    if existing:
        existing = f"## ê¸°ì¡´ ìƒì„± ë‚´ìš©(ì¤‘ë³µ ê¸ˆì§€ ì°¸ê³ )\n{existing}\n"

    # ðŸ”¥ ìž¬ì‹œë„ ì‹œ ê°•í™” í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    retry_block = NO_REJECTION_RULE if is_retry else ""

    return f"""{truth_anchor}

{ROOT_CAUSE_RULE}

{DATA_COMPLIANCE_RULE}

{retry_block}

## Ground Truth saju_summary (ì •ë‹µì§€)
{summary_json}

## ì‚¬ìš©ìž ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´
- ì—…ì¢…: {industry}
- ê³ ë¯¼/ì§ˆë¬¸: {pain}
- ëª©í‘œ: {goal}
- ê¸°ê°„: {timeframe}

## ì—”ì§„ í™•ì • ë£°ì¹´ë“œ (ê·¼ê±°ë¡œë§Œ ì‚¬ìš©)
{cards_block}

## ë§ˆìŠ¤í„° ìƒ˜í”Œ ë¬¸ì²´ ì°¸ê³  (ìŠ¤íƒ€ì¼ë§Œ)
{master_body}

{existing}

## ìž‘ì„± ì§€ì‹œ
- ì„¹ì…˜: [{title}] (section_id={section_id})
- ë°˜ë“œì‹œ {min_chars}ìž ì´ìƒ
- ë£¨í”„: (ì›êµ­/ë£°ì¹´ë“œ êµ¬ì¡°) â†’ (í˜„ìž¥ ë°œí˜„) â†’ (ì‹¤í–‰ ì•¡ì…˜ 3~7ê°œ)
- ê¸ˆì§€: ì‚¬ê³¼, ê±°ì ˆ, 'ì¶”ê°€ ì •ë³´ í•„ìš”', 'ë¶„ì„í•  ìˆ˜ ì—†ìŒ'
- í—ˆìš©: ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ "[ê°€ì •]" í‘œê¸° í›„ ê³„ì† ìž‘ì„±
""".strip()


# -----------------------------
# Builder class
# -----------------------------

class PremiumReportBuilder:
    def __init__(
        self,
        *,
        model: Optional[str] = None,
        temperature: float = 0.3,
        max_tokens: int = 1600,
        timeout: float = 60.0,
    ):
        self.model = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        self.temperature = float(temperature)
        self.max_tokens = int(max_tokens)
        self.timeout = float(timeout)

    async def _call_openai(self, system_prompt: str, user_prompt: str) -> str:
        api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_KEY") or ""
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY is missing")

        payload = {
            "model": self.model,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        }
        headers = {"Authorization": f"Bearer {api_key}"}
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            r = await client.post("https://api.openai.com/v1/chat/completions", json=payload, headers=headers)
            r.raise_for_status()
            data = r.json()
            return (data["choices"][0]["message"]["content"] or "").strip()

    async def generate_single_section(
        self,
        section_id: str,
        saju_data: Dict[str, Any],
        rulecards: List[Dict[str, Any]],
        survey_data: Dict[str, Any],
        target_year: int,
        user_question: str = "",
        existing_contents: Optional[List[str]] = None,
        job_id: Optional[str] = None,
        truth_anchor: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        ì„¹ì…˜ ìƒì„± + ðŸ”¥ ê±°ì ˆ ì‘ë‹µ ê°ì§€ ì‹œ 1íšŒ ìžë™ ìž¬ì‹œë„
        """
        spec = PREMIUM_SECTIONS.get(section_id) or SectionSpec(section_id, section_id, 800)
        user_prompt = f"{ENGINE_HEADLINE}\nì„¹ì…˜ [{section_id}] ë‚´ìš©ì„ ìž‘ì„±í•˜ë¼."
        
        body = ""
        retried = False
        rejection_detected = False
        rejection_patterns = []
        
        # ðŸ”¥ ìµœëŒ€ 2íšŒ ì‹œë„ (ìµœì´ˆ 1íšŒ + ìž¬ì‹œë„ 1íšŒ)
        for attempt in range(2):
            is_retry = (attempt > 0)
            
            system_prompt = build_system_prompt(
                section_id=section_id,
                saju_data=saju_data,
                rulecards=rulecards,
                survey_data=survey_data,
                target_year=target_year,
                user_question=user_question,
                existing_contents=existing_contents,
                truth_anchor_override=truth_anchor,
                is_retry=is_retry,
            )
            
            try:
                body = await self._call_openai(system_prompt, user_prompt)
            except Exception as e:
                logger.error(f"[Builder] OpenAI í˜¸ì¶œ ì‹¤íŒ¨ (attempt={attempt+1}): {e}")
                body = f"[ì„¹ì…˜ ìƒì„± ì˜¤ë¥˜: {str(e)[:100]}]"
                break
            
            # ðŸ”¥ ê±°ì ˆ íŒ¨í„´ ê°ì§€
            is_rejection, patterns = _detect_rejection(body)
            
            if is_rejection and attempt == 0:
                # ì²« ë²ˆì§¸ ì‹œë„ì—ì„œ ê±°ì ˆ â†’ ìž¬ì‹œë„
                logger.warning(f"[Builder] ê±°ì ˆ ì‘ë‹µ ê°ì§€ (section={section_id}): {patterns} â†’ ìž¬ì‹œë„")
                retried = True
                rejection_detected = True
                rejection_patterns = patterns
                continue
            elif is_rejection and attempt == 1:
                # ìž¬ì‹œë„ì—ì„œë„ ê±°ì ˆ â†’ ê²½ê³ ë§Œ ë‚¨ê¸°ê³  ì‚¬ìš©
                logger.warning(f"[Builder] ìž¬ì‹œë„ í›„ì—ë„ ê±°ì ˆ ì‘ë‹µ (section={section_id}): {patterns}")
                rejection_detected = True
                rejection_patterns = patterns
                break
            else:
                # ì •ìƒ ì‘ë‹µ
                if is_retry:
                    logger.info(f"[Builder] ìž¬ì‹œë„ ì„±ê³µ (section={section_id})")
                break

        used_ids = [c.get("id") for c in rulecards if c.get("id")]

        return {
            "section_id": section_id,
            "title": spec.title,
            "body_markdown": body,
            "char_count": len(body),
            "llm_response_len": len(body),
            "guardrail_violations": rejection_patterns if rejection_detected else [],
            "repaired": retried,
            "rejection_detected": rejection_detected,
            "match_summary": {
                "selected_rulecards": len(rulecards),
                "model": self.model,
                "job_id": job_id,
                "retried": retried,
            },
            "used_rulecard_ids": used_ids[:50],
            "generated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        }

    async def regenerate_single_section(self, *args, **kwargs) -> Dict[str, Any]:
        """Alias for retry logic (ì™¸ë¶€ í˜¸ì¶œìš©)"""
        return await self.generate_single_section(*args, **kwargs)


# Public singleton used across routers/workers
premium_report_builder = PremiumReportBuilder()

__all__ = [
    "PREMIUM_SECTIONS",
    "SectionSpec",
    "PremiumReportBuilder",
    "premium_report_builder",
    "build_system_prompt",
]
