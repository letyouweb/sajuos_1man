"""
SajuOS Premium Report Builder v12 - P0 ë¹ˆ ì„¹ì…˜ ì ˆëŒ€ ê¸ˆì§€
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¥ P0-1: ì¹´ë“œ 0ê°œ â†’ LLM í˜¸ì¶œ X, í´ë°± í…ìŠ¤íŠ¸ ì¦‰ì‹œ ë°˜í™˜
ğŸ”¥ P0-2: ì„¹ì…˜ ID ì •í•©ì„± (exec,money,business,team,health,calendar,sprint)
ğŸ”¥ P0-3: í† í° "ì¹˜í™˜" (ì‚­ì œ X) - {industry}â†’"í•´ë‹¹ ì—…ì¢…"
ğŸ”¥ P0-4: ìƒì„± ì‹¤íŒ¨ ì›ì¸ ë¡œê·¸ 4ê°œ í•„ìˆ˜
ğŸ”¥ P0-5: ì§€ì¥ê°„ ì¶”ë¡  ê¸ˆì§€ ë° 'ë³´ì´ëŠ” ê¸€ì' ì¤‘ì‹¬ ê²€ì¦ ê°•í™”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
import asyncio
import json
import logging
import re
from typing import Dict, Any, List
from dataclasses import dataclass, field

from openai import AsyncOpenAI
import httpx

from app.config import get_settings
from app.services.openai_key import get_openai_api_key
from app.services.terminology_mapper import sanitize_for_business
from app.services.job_store import job_store
from app.templates.master_samples import load_master_samples, get_master_body_markdown

logger = logging.getLogger(__name__)

MASTER_SAMPLES = load_master_samples("v1")

DEBUG_TEMPLATE_LEAKS = False


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# P0-3: í† í° ì¹˜í™˜ (ì‚­ì œ X)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

TOKEN_REPLACEMENTS = {
    "{industry}": "í•´ë‹¹ ì—…ì¢…",
    "{painPoint}": "í˜„ì¬ ë³‘ëª©",
    "{engine_headline}": "í•µì‹¬ ê²°ë¡ ",
    "{goal}": "ëª©í‘œ",
    "{revenue}": "ë§¤ì¶œ",
    "{day_master}": "ì¼ê°„",
    "{time}": "ì‹œì ",
    "[ENGINE_HEADLINE]": "",
    "[/ENGINE_HEADLINE]": "",
}


def replace_template_tokens(text: str) -> str:
    """ğŸ”¥ P0-3: í† í° ì¹˜í™˜ (ì‚­ì œê°€ ì•„ë‹Œ ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´)"""
    if not text:
        return ""
    if DEBUG_TEMPLATE_LEAKS:
        return text.strip()
    for token, replacement in TOKEN_REPLACEMENTS.items():
        text = text.replace(token, replacement)
    text = re.sub(r"\{[a-zA-Z_]+\}", "í•´ë‹¹ í•­ëª©", text)
    return text.strip()


def check_template_leaks(text: str, context: str = "") -> List[str]:
    if not text:
        return []
    leaked = []
    for token in TOKEN_REPLACEMENTS.keys():
        if token in text:
            leaked.append(token)
    if re.search(r"\{[a-zA-Z_]+\}", text):
        leaked.append("{other}")
    if leaked:
        logger.warning(f"[TemplateLeak] {context} | leaked: {leaked}")
    return leaked


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# P0-2: ì„¹ì…˜ ID ì •í•©ì„± (ê¸°ì¡´ ID ìœ ì§€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class SectionSpec:
    id: str
    title: str
    max_cards: int
    min_chars: int
    fallback_headline: str
    topic_filter: List[str] = field(default_factory=list)


# ğŸ”¥ P0-2: í•©ì˜ëœ section_id ê³ ì • (exec, money, business, team, health, calendar, sprint)
PREMIUM_SECTIONS = {
    "exec": SectionSpec(
        "exec", "2026 ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ê¸°ìƒë„", 20, 1500,
        "í˜„ì¬ ì‚¬ì£¼ êµ¬ì¡°ìƒ 2026ë…„ ë¹„ì¦ˆë‹ˆìŠ¤ í™˜ê²½ì€ ë³€í™”ì˜ ê¸°ìš´ì´ ê°ì§€ë©ë‹ˆë‹¤",
        topic_filter=["ì „ì²´ìš´", "ì¢…í•©", "ì¼ê°„", "ì„±í–¥", "ê¸°ìš´", "ìš´ì„¸"]
    ),
    "money": SectionSpec(
        "money", "ìë³¸ ìœ ë™ì„± ë° í˜„ê¸ˆíë¦„ ìµœì í™”", 20, 2500,
        "í˜„ì¬ êµ¬ì¡°ìƒ í˜„ê¸ˆíë¦„ì˜ ë³€ë™ì„±ì´ ì˜ˆìƒë©ë‹ˆë‹¤",
        topic_filter=["ì¬ë¬¼", "ì¬ì„±", "ì •ì¬", "í¸ì¬", "í˜„ê¸ˆ", "ë§¤ì¶œ", "íˆ¬ì"]
    ),
    "business": SectionSpec(
        "business", "ì‹œì¥ í¬ì§€ì…”ë‹ ë° ìƒí’ˆ í™•ì¥ ì „ëµ", 20, 2500,
        "í˜„ì¬ êµ¬ì¡°ìƒ ì‹œì¥ í¬ì§€ì…”ë‹ ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤",
        topic_filter=["ì‚¬ì—…", "ì°½ì—…", "ê²½ì˜", "ê´€ì„±", "ì •ê´€", "í¸ê´€", "ì‹œì¥"]
    ),
    "team": SectionSpec(
        "team", "ì¡°ì§ í™•ì¥ ë° íŒŒíŠ¸ë„ˆì‹­ ê°€ì´ë“œ", 20, 2000,
        "í˜„ì¬ êµ¬ì¡°ìƒ íŒŒíŠ¸ë„ˆì‹­ ê´€ë¦¬ê°€ í•µì‹¬ ê³¼ì œì…ë‹ˆë‹¤",
        topic_filter=["ë¹„ê²", "ë¹„ê²¬", "ê²ì¬", "ë™ì—…", "íŒŒíŠ¸ë„ˆ", "í˜‘ë ¥", "ì¸ë§¥"]
    ),
    "health": SectionSpec(
        "health", "ì£¼ìš” ì¥ì• ë¬¼ ë° ë¦¬ìŠ¤í¬ (2026)", 15, 1500,
        "í˜„ì¬ êµ¬ì¡°ìƒ í•´ë‹¹ ë¦¬ìŠ¤í¬ëŠ” ë‚®ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤",
        topic_filter=["ë¦¬ìŠ¤í¬", "ìœ„í—˜", "ì¶©", "í˜•", "íŒŒ", "ì†í•´", "ì¥ì• ", "ë²ˆì•„ì›ƒ"]
    ),
    "calendar": SectionSpec(
        "calendar", "12ê°œì›” ë¹„ì¦ˆë‹ˆìŠ¤ ìŠ¤í”„ë¦°íŠ¸ ìº˜ë¦°ë”", 15, 2500,
        "í˜„ì¬ êµ¬ì¡°ìƒ ì›”ë³„ ë¦¬ë“¬ì— ë§ì¶˜ ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤",
        topic_filter=["ì›”ìš´", "ì‹œê¸°", "ê³„ì ˆ", "íƒ€ì´ë°", "ê¸¸ì¼", "í‰ì¼", "ëŒ€ìš´"]
    ),
    "sprint": SectionSpec(
        "sprint", "í–¥í›„ 90ì¼ ë§¤ì¶œ ê·¹ëŒ€í™” ì•¡ì…˜í”Œëœ", 15, 2000,
        "í˜„ì¬ êµ¬ì¡°ìƒ 90ì¼ ì§‘ì¤‘ ì‹¤í–‰ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤",
        topic_filter=["ì‹¤í–‰", "ì•¡ì…˜", "ê³„íš", "ëª©í‘œ", "ì‹ì‹ ", "ìƒê´€", "ì‹ìƒ"]
    ),
}


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# P0-1: í´ë°± í…ìŠ¤íŠ¸ (ë¹ˆ ì„¹ì…˜ ë°©ì§€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def generate_fallback_body(section_id: str, engine_headline: str, survey_data: Dict = None) -> str:
    """ğŸ”¥ P0-1: ì¹´ë“œ 0ê°œ ë˜ëŠ” LLM ì‹¤íŒ¨ ì‹œ í´ë°± í…ìŠ¤íŠ¸"""
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        spec = SectionSpec(section_id, "ì„¹ì…˜", 10, 500, "ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤")
    
    headline = engine_headline if engine_headline else spec.fallback_headline
    industry = (survey_data or {}).get("industry", "í•´ë‹¹ ì—…ì¢…")
    painPoint = (survey_data or {}).get("painPoint", "í˜„ì¬ ë³‘ëª©")
    
    return f"""{headline}

## í˜„ì¬ ìƒí™© ë¶„ì„

ì›ì¸(ì‚¬ì£¼/ë£°ì¹´ë“œ) ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ìƒì„¸ ë¶„ì„ì´ ì œí•œë©ë‹ˆë‹¤.
ì„¤ë¬¸ìœ¼ë¡œë§Œ ì–µì§€ ì¶”ë¡ í•˜ëŠ” ê²ƒì€ Root Cause Rule ìœ„ë°˜ì´ë¯€ë¡œ ìƒëµí•©ë‹ˆë‹¤.

### ë‹¤ìŒ í–‰ë™ ê¶Œì¥ì‚¬í•­

1. **D+14**: {industry} ì—…ì¢… í˜„í™© ì ê²€ ë° ë°ì´í„° ìˆ˜ì§‘
2. **D+30**: {painPoint} ê´€ë ¨ í•µì‹¬ ì§€í‘œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
3. **D+60**: ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ ì „ëµ ì¬ìˆ˜ë¦½

### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] í˜„ì¬ ìƒí™© ê°ê´€ì  ì§„ë‹¨
- [ ] í•µì‹¬ ì§€í‘œ ì •ì˜
- [ ] ë°ì´í„° ìˆ˜ì§‘ ì²´ê³„ êµ¬ì¶•
- [ ] ì£¼ê°„ ë¦¬ë·° ì¼ì • í™•ì •
- [ ] ì „ë¬¸ê°€ ìƒë‹´ ê²€í† 

---
*ì¶”ê°€ ì‚¬ì£¼ ì •ë³´ë‚˜ ë£°ì¹´ë“œ ë§¤ì¹­ì´ í™•ë³´ë˜ë©´ ë” ì •ë°€í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.*
"""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë°ì´í„° êµ¬ì¡° ë° í—¬í¼
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class SectionRuleCardAllocation:
    section_id: str
    allocated_count: int
    allocated_card_ids: List[str]
    context_text: str
    cards: List[Dict[str, Any]] = field(default_factory=list)


def score_card_for_section(card: Dict, section_id: str, survey_data: Dict = None) -> float:
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        return 1.0
    score = 1.0
    topic = (card.get("topic") or "").lower()
    mechanism = (card.get("mechanism") or "").lower()
    tags = " ".join(card.get("tags") or []).lower()
    card_text = f"{topic} {mechanism} {tags}"
    for tf in spec.topic_filter:
        if tf.lower() in card_text:
            score += 3.0
    if survey_data:
        pain = (survey_data.get("painPoint") or "").lower()
        pain_tags = {"lead": ["ì¸ë§¥", "ê·€ì¸"], "retention": ["ë¹„ê²", "ë¹„ê²¬"], "conversion": ["ì¬ì„±", "ì •ì¬"], "funding": ["ì¬ì„±", "íˆ¬ì"]}
        for tag in pain_tags.get(pain, []):
            if tag.lower() in card_text:
                score += 2.0
    return score


def allocate_rulecards_to_section(all_cards: List[Dict], section_id: str, max_cards: int, used_ids: set, survey_data: Dict = None) -> SectionRuleCardAllocation:
    scored = []
    for card in all_cards:
        cid = card.get("id", card.get("_id", ""))
        if cid in used_ids:
            continue
        score = score_card_for_section(card, section_id, survey_data)
        scored.append((score, card))
    scored.sort(key=lambda x: x[0], reverse=True)
    
    filtered = [(s, c) for s, c in scored if s > 1.0]
    if not filtered:
        logger.warning(f"[CardAlloc] section={section_id} topic_filter hit=0 â†’ fallback")
        if scored:
            filtered = scored[:max_cards]
        elif all_cards:
            fallback = [c for c in all_cards if c.get("id", c.get("_id", "")) not in used_ids][:max_cards]
            filtered = [(1.0, c) for c in fallback]
    
    allocated = [card for _, card in filtered[:max_cards]]
    ids, lines = [], []
    for card in allocated:
        cid = card.get("id", card.get("_id", ""))
        ids.append(cid)
        interp = sanitize_for_business((card.get("interpretation") or "")[:200])
        lines.append(f"[{cid}] {card.get('topic', '')} | {interp}")
    
    logger.info(f"[CardAlloc] section={section_id} | scored={len(scored)} | filtered={len(filtered)} | allocated={len(ids)}")
    return SectionRuleCardAllocation(section_id, len(ids), ids, "\n".join(lines), allocated)


def extract_engine_headline(cards: List[Dict]) -> str:
    if not cards:
        return ""
    top_card = cards[0]
    interp = top_card.get("interpretation") or top_card.get("content", {}).get("interpretation", "") or top_card.get("mechanism") or ""
    interp = sanitize_for_business(interp)
    sentences = re.split(r"[.ã€‚!?]", interp)
    first = sentences[0].strip() if sentences else interp[:100]
    first = re.sub(r"\{[a-zA-Z_]+\}", "", first)
    return first if first else interp[:100]


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í”„ë¡¬í”„íŠ¸ êµ¬ì„± ìœ í‹¸ë¦¬í‹°
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ROOT_CAUSE_RULE = """## ğŸ§  Root Cause Rule (ì ˆëŒ€ê·œì¹™)
- ì‚¬ì£¼/ë£°ì¹´ë“œ(=ì›ì¸)ê°€ ê²°ë¡ ì´ë‹¤. ì„¤ë¬¸(=ì¦ìƒ)ì€ ê²°ë¡ ì´ ì•„ë‹ˆë‹¤.
- ì„¹ì…˜ì˜ ì²« ë¬¸ì¥ì€ ë°˜ë“œì‹œ ì—”ì§„ì´ í™•ì •í•œ ê²°ë¡ ìœ¼ë¡œ ì‹œì‘í•œë‹¤.
- ê¸ˆì§€: "ê³ ê°ë‹˜ì´ ì„¤ë¬¸ì—ì„œ ~ë¼ê³  í•˜ì…¨ìœ¼ë‹ˆ" ê°™ì€ ì„œìˆ .
"""

TENGOD_ORDER = ["ë¹„ê²¬","ê²ì¬","ì‹ì‹ ","ìƒê´€","í¸ì¬","ì •ì¬","í¸ê´€","ì •ê´€","í¸ì¸","ì •ì¸"]


def build_fact_check_context(saju_data: Dict[str, Any]) -> str:
    """ğŸ”¥ P0: ì‚¬ì‹¤ ê²€ì¦ìš© ì»¨í…ìŠ¤íŠ¸ (ë³´ì´ëŠ” ê¸€ì ì¤‘ì‹¬ ë° ì§€ì¥ê°„ ì¶”ë¡  ê¸ˆì§€)"""
    summary = saju_data.get("saju_summary", {})
    yp = saju_data.get("year_pillar","")
    mp = saju_data.get("month_pillar","")
    dp = saju_data.get("day_pillar","")
    hp = saju_data.get("hour_pillar","")
    dm = saju_data.get("day_master","")
    gender = saju_data.get("gender","")
    age = saju_data.get("age",0)
    cur = saju_data.get("current_daeun","")
    direction = saju_data.get("daeun_direction","")
    
    # ì‹­ì„± ì •ë³´ (ì—”ì§„ ì •ë‹µì§€ ìš°ì„ )
    tg = summary.get("ten_gods_present", []) or saju_data.get("ten_gods_present", [])
    dtg = saju_data.get("daeun_ten_gods") or []
    elems = saju_data.get("elements_present") or []
    has_wealth = bool(saju_data.get("has_wealth_star"))

    def _fmt(xs, order=None):
        if not xs:
            return "(ì—†ìŒ)"
        if order:
            s = set(xs)
            xs = [x for x in order if x in s] + [x for x in xs if x not in s]
        return ", ".join(xs)

    # ğŸ”¥ P0: 'ë³´ì´ëŠ” ê¸€ì'ë§Œ í—ˆìš© (ì§€ì¥ê°„/ìˆ¨ì€ì²œê°„ ì¶”ë¡  ê¸ˆì§€)
    pillars = [yp, mp, dp, hp]
    stems = [p[0] for p in pillars if p and len(p) >= 2]
    branches = [p[1] for p in pillars if p and len(p) >= 2]

    STEM_ELEM = {
        "ê°‘": "ëª©", "ì„": "ëª©", "ë³‘": "í™”", "ì •": "í™”", "ë¬´": "í† ", 
        "ê¸°": "í† ", "ê²½": "ê¸ˆ", "ì‹ ": "ê¸ˆ", "ì„": "ìˆ˜", "ê³„": "ìˆ˜",
    }
    all_stem_elem = [f"{k}{v}" for k, v in STEM_ELEM.items()]
    allowed_stem_elem = [f"{s}{STEM_ELEM.get(s, '')}" for s in stems if s in STEM_ELEM]
    forbidden_stem_elem = [x for x in all_stem_elem if x not in set(allowed_stem_elem)]

    primary_structure = summary.get("primary_structure") or saju_data.get("primary_structure") or ""
    allowed_structures = summary.get("allowed_structure_names") or saju_data.get("allowed_structure_names") or []

    return (
        "## âœ… ì‚¬ì‹¤ ê²€ì¦ìš© ì»¨í…ìŠ¤íŠ¸ (P0)\n"
        f"- ì›êµ­(4ì£¼): {yp} {mp} {dp} {hp}\n"
        f"- í—ˆìš© ì²œê°„(ë³´ì´ëŠ” ê²ƒë§Œ): {', '.join(stems) if stems else '(ì—†ìŒ)'}\n"
        f"- í—ˆìš© ì§€ì§€(ë³´ì´ëŠ” ê²ƒë§Œ): {', '.join(branches) if branches else '(ì—†ìŒ)'}\n"
        f"- ê¸ˆì§€ ì²œê°„ì˜¤í–‰(ì›êµ­ì— ì—†ìŒ): {', '.join(forbidden_stem_elem[:6])}{'...' if len(forbidden_stem_elem) > 6 else ''}\n"
        f"- ì¼ê°„: {dm}\n"
        f"- ì„±ë³„/ë§Œë‚˜ì´: {gender} / {age}\n"
        f"- ê²©êµ­(ì—”ì§„ í™•ì •): {primary_structure or '(ë¯¸ì œê³µ)'}\n"
        f"- ì‚¬ìš© ê°€ëŠ¥í•œ ê²©êµ­ëª…: {', '.join(allowed_structures) if allowed_structures else '(ë¯¸ì œê³µ)'}\n"
        f"- ì›êµ­ ì‹­ì„±(ì—”ì§„ ìš”ì•½): {_fmt(tg, TENGOD_ORDER)}\n"
        f"- í˜„ì¬ ëŒ€ìš´: {cur} (ë°©í–¥={direction}, ì‹­ì„±={_fmt(dtg, TENGOD_ORDER)})\n"
        f"- ì¬ì„±(ì •ì¬/í¸ì¬) ì›êµ­ ì¡´ì¬: {'ìˆìŒ' if has_wealth else 'ì—†ìŒ'}\n\n"
        "### ğŸš« ê¸ˆì§€ ê·œì¹™\n"
        "1) ìœ„ 'í—ˆìš© ì²œê°„/ì§€ì§€'ì— ì—†ëŠ” ê¸€ì(ì˜ˆ: ì„, ë³‘ ë“±)ë¥¼ ì›êµ­ì— ìˆë‹¤ê³  ì“°ì§€ ë§ˆë¼.\n"
        "2) ìœ„ ì‹­ì„± ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ì‹­ì„±ì„ 'ìˆë‹¤'ê³  ì“°ì§€ ë§ˆë¼.\n"
        "3) ëŒ€ìš´ ë³€í™”ëŠ” ë°˜ë“œì‹œ 'ëŒ€ìš´ì—ì„œ ë“¤ì–´ì˜¨ë‹¤'ë¡œ ì›êµ­ê³¼ êµ¬ë¶„í•´ì„œ ë§í•´ë¼.\n"
        "4) ê¸ˆì§€: ì§€ì¥ê°„/ìˆ¨ì€ì²œê°„ì„ ê·¼ê±°ë¡œ 'ë³‘í™”/ì„ëª©ì´ ë§ë‹¤' ê°™ì€ ë¬¸ì¥ ì‘ì„± ê¸ˆì§€. (ë³´ì´ëŠ” ê¸€ìë§Œ)\n"
        "5) ê¸ˆì§€: 'ê±¸ë¡ê²©' í‘œê¸°. (ë°˜ë“œì‹œ 'ê±´ë¡ê²©'ìœ¼ë¡œ í‘œê¸°)\n"
        "6) ê¸ˆì§€: ì›”ì§€ì— íŠ¹ì • ì‹­ì„±ì´ 'ìœ„ì¹˜'í•œë‹¤ê³  ë‹¨ì •(ì˜ˆ: ì›”ì§€ ë¹„ê²¬ ë“±). í•„ìš”ì‹œ ë¶„í¬ë¡œë§Œ ì„¤ëª….\n"
    )

def build_system_prompt(section_id: str, engine_headline: str, survey_data: Dict = None, saju_data: Dict = None, existing_contents: List[str] = None, cards_summary: str = "") -> str:
    spec = PREMIUM_SECTIONS.get(section_id)
    if not spec:
        return ""
    title = spec.title
    min_chars = spec.min_chars
    master_body = get_master_body_markdown(section_id)
    industry = (survey_data or {}).get("industry", "ë¯¸ì…ë ¥")
    painPoint = (survey_data or {}).get("painPoint", "ë¯¸ì…ë ¥")
    businessGoal = (survey_data or {}).get("businessGoal", "ë¯¸ì…ë ¥")
    
    saju_summary = (saju_data or {}).get("saju_summary", {})
    summary_json = json.dumps(saju_summary, ensure_ascii=False, indent=2) if saju_summary else "{}"
    
    data_compliance_rule = f"""
## ğŸ”´ ë°ì´í„° ì¤€ìˆ˜ ì² ì¹™ (ìœ„ë°˜ì‹œ ì‹¤íŒ¨)
1. ì•„ë˜ ì›êµ­ í†µê³„(ì •ë‹µì§€)ì— ì—†ëŠ” ì‹­ì„±/ì˜¤í–‰ì„ "ìˆë‹¤"ê³  ì£¼ì¥í•˜ì§€ ë§ˆë¼.
2. ì›êµ­ì— ì¬ì„±(ì •ì¬/í¸ì¬)ì´ 0ê°œë©´, "ì¬ì„±ì´ ìˆë‹¤"ê³  ë§í•˜ì§€ ë§ˆë¼.
3. ì›êµ­ì— ì‹ìƒ(ì‹ì‹ /ìƒê´€)ì´ 0ê°œë©´, "ì‹ìƒì´ ìˆë‹¤"ê³  ë§í•˜ì§€ ë§ˆë¼.
4. ëŒ€ìš´ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ê¸°ìš´ì€ ë°˜ë“œì‹œ "ëŒ€ìš´ì—ì„œ ~ê°€ ë“¤ì–´ì˜¨ë‹¤"ë¡œ ëª…ì‹œí•˜ë¼.
5. Allowed_structure_names ì™¸ì˜ ê²©êµ­ ì´ë¦„ì„ ì‚¬ìš©í•˜ì§€ ë§ˆë¼.
"""
    
    fact_ctx = build_fact_check_context(saju_data or {})
    survey_context = f"\n## ì„¤ë¬¸ (ì¦ìƒ)\n- ì—…ì¢…: {industry}\n- ê³ ë¯¼: {painPoint}\n- ëª©í‘œ: {businessGoal}\n"
    
    existing_block = ""
    if existing_contents:
        existing_block = f"\n## ì´ì „ ì„¹ì…˜ (ë°˜ë³µ ê¸ˆì§€)\n{chr(10).join(existing_contents[-2:])}\n"
    
    return f"""ë„ˆëŠ” [{title}] ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ë‹¤.

{ROOT_CAUSE_RULE}
{data_compliance_rule}
{fact_ctx}

## ì •ë‹µì§€ (Ground Truth)
{summary_json}

## ì²« ë¬¸ì¥ (ìˆ˜ì • ê¸ˆì§€)
"{engine_headline}"

## ë§ˆìŠ¤í„° ìƒ˜í”Œ
{master_body if master_body else '(ììœ  ì‘ì„±)'}

## ë£°ì¹´ë“œ ìš”ì•½
{cards_summary if cards_summary else '(ì—†ìŒ)'}
{survey_context}
{existing_block}

## í•„ìˆ˜ ê·œì¹™
1) ì²« ë¬¸ì¥: ìœ„ ì—”ì§„ ê²°ë¡ ìœ¼ë¡œ ì‹œì‘
2) ë¦¬ìŠ¤í¬ 2ê°œ, ì•¡ì…˜ 3ê°œ, ì²´í¬ë¦¬ìŠ¤íŠ¸ 7ê°œ í¬í•¨
3) ìµœì†Œ {min_chars}ì ì´ìƒ, ì „ë¬¸ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ í†¤ ì¤€ìˆ˜
"""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë¹Œë” í´ë˜ìŠ¤
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class PremiumReportBuilder:
    def __init__(self):
        self._client = None
        self._semaphore = None
    
    def _get_client(self) -> AsyncOpenAI:
        api_key = get_openai_api_key()
        return AsyncOpenAI(api_key=api_key, timeout=httpx.Timeout(120.0, connect=15.0), max_retries=2)
    
    async def build_premium_report(self, saju_data: Dict, rulecards: List[Dict], feature_tags: List[str] = None, target_year: int = 2026, user_question: str = "", name: str = "ê³ ê°", job_id: str = None, survey_data: Dict = None, mode: str = "premium"):
        self._semaphore = asyncio.Semaphore(2)
        self._client = self._get_client()
        if job_id:
            await job_store.start_job(job_id)
        
        used_card_ids = set()
        results = []
        existing_contents = []
        
        for sid in PREMIUM_SECTIONS.keys():
            spec = PREMIUM_SECTIONS[sid]
            alloc = allocate_rulecards_to_section(rulecards, sid, spec.max_cards, used_card_ids, survey_data)
            used_card_ids.update(alloc.allocated_card_ids)
            engine_headline = extract_engine_headline(alloc.cards)
            
            # ğŸ”¥ P0-4: ìƒì„± ì‹¤íŒ¨ ì›ì¸ ë¡œê·¸ í•„ìˆ˜
            headline_len = len(engine_headline) if engine_headline else 0
            logger.info(f"[Builder] ğŸ“Š section={sid} | 1.allocated_count={alloc.allocated_count} | 2.headline_len={headline_len}")
            
            try:
                result = await self._generate_section_safe(
                    section_id=sid,
                    saju_data=saju_data,
                    allocation=alloc,
                    target_year=target_year,
                    survey_data=survey_data,
                    engine_headline=engine_headline,
                    existing_contents=existing_contents,
                    job_id=job_id
                )
                
                body = result.get("body_markdown", "")
                body_len = len(body)
                
                # ğŸ”¥ P0-4: LLM ì‘ë‹µ ë° ìµœì¢… ê¸¸ì´ ë¡œê·¸
                logger.info(f"[Builder] ğŸ“Š section={sid} | 3.llm_response_len={result.get('llm_response_len', 0)} | 4.final_body_len={body_len}")
                
                if body:
                    existing_contents.append(body[:300])
                results.append(result)
                
                if job_id:
                    await job_store.section_done(job_id, sid, body_len)
                    
            except Exception as e:
                logger.exception(f"[Builder] âŒ ì„¹ì…˜ ìƒì„± ì‹¤íŒ¨: {sid}")
                fallback_body = generate_fallback_body(sid, engine_headline, survey_data)
                results.append({
                    "section_id": sid, "title": spec.title, "body_markdown": fallback_body,
                    "engine_headline": engine_headline or spec.fallback_headline,
                    "rulecard_ids": [], "char_count": len(fallback_body), "is_fallback": True
                })
        
        if job_id:
            await job_store.complete_job(job_id, {"sections": len(results)})
        return {"status": "success", "sections": results}
    
    async def _generate_section_safe(self, section_id: str, saju_data: Dict, allocation: SectionRuleCardAllocation, target_year: int, survey_data: Dict, engine_headline: str, existing_contents: List[str], job_id: str = None) -> Dict[str, Any]:
        """ğŸ”¥ P0-1: ë¹ˆ ì„¹ì…˜ ì ˆëŒ€ ê¸ˆì§€ - ì¹´ë“œ 0ê°œë©´ í´ë°±"""
        spec = PREMIUM_SECTIONS.get(section_id)
        if not spec:
            raise ValueError(f"Invalid section_id: {section_id}")
        
        # ğŸ”¥ P0-1(A): ì¹´ë“œ 0ê°œë©´ ì¦‰ì‹œ í´ë°±
        if allocation.allocated_count == 0:
            logger.warning(f"[Builder] section={section_id} | cards=0 â†’ fallback")
            fallback_body = generate_fallback_body(section_id, engine_headline, survey_data)
            return {
                "section_id": section_id, "title": spec.title, "body_markdown": fallback_body,
                "engine_headline": engine_headline or spec.fallback_headline, "rulecard_ids": [],
                "char_count": len(fallback_body), "llm_response_len": 0, "is_fallback": True
            }
        
        cards_summary = self._build_cards_summary(allocation.cards[:5])
        system_prompt = build_system_prompt(
            section_id=section_id, engine_headline=engine_headline or spec.fallback_headline,
            survey_data=survey_data, saju_data=saju_data, existing_contents=existing_contents,
            cards_summary=cards_summary
        )
        user_prompt = self._build_user_prompt(saju_data, allocation, target_year)
        
        body_markdown = ""
        llm_response_len = 0
        
        async with self._semaphore:
            try:
                # ğŸ”¥ P0: temperature 0.3 ë° max_tokens 1800 ìµœì í™”
                response = await self._client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=1800
                )
                body_markdown = response.choices[0].message.content or ""
                llm_response_len = len(body_markdown)
            except Exception as e:
                logger.error(f"[Builder] GPT í˜¸ì¶œ ì‹¤íŒ¨: {section_id} | {e}")
                body_markdown = generate_fallback_body(section_id, engine_headline, survey_data)
        
        if len(body_markdown) < 200:
            body_markdown = generate_fallback_body(section_id, engine_headline, survey_data)
        
        body_markdown = self._enforce_engine_headline(body_markdown, engine_headline or spec.fallback_headline)
        leaked = check_template_leaks(body_markdown, f"section={section_id}")
        body_markdown = replace_template_tokens(body_markdown)
        
        return {
            "section_id": section_id, "title": spec.title, "body_markdown": body_markdown,
            "engine_headline": engine_headline or spec.fallback_headline,
            "rulecard_ids": allocation.allocated_card_ids, "char_count": len(body_markdown),
            "llm_response_len": llm_response_len, "leaked_tokens": leaked
        }
    
    def _build_cards_summary(self, cards: List[Dict]) -> str:
        lines = []
        for i, c in enumerate(cards[:5], 1):
            interp = (c.get("interpretation") or "")[:80]
            lines.append(f"{i}. [{c.get('topic', '')}] {interp}")
        return "\n".join(lines) if lines else "(ì—†ìŒ)"
    
    def _build_user_prompt(self, saju_data: Dict, allocation: SectionRuleCardAllocation, target_year: int) -> str:
        year_pillar = saju_data.get("year_pillar", "-")
        month_pillar = saju_data.get("month_pillar", "-")
        day_pillar = saju_data.get("day_pillar", "-")
        hour_pillar = saju_data.get("hour_pillar", "-") or "ë¯¸ì…ë ¥"
        day_master = saju_data.get("day_master", "")
        card_lines = [f"- [{c.get('id', '')}] {c.get('topic', '')} | {(c.get('interpretation') or '')[:100]}" for c in allocation.cards[:10]]
        return f"""## ì‚¬ì£¼ ì›êµ­
| ë…„ì£¼ | ì›”ì£¼ | ì¼ì£¼ | ì‹œì£¼ |
|------|------|------|------|
| {year_pillar} | {month_pillar} | {day_pillar} | {hour_pillar} |

- ì¼ê°„: {day_master}
- ë¶„ì„ë…„ë„: {target_year}ë…„

## ë°°ì •ëœ ë£°ì¹´ë“œ
{chr(10).join(card_lines) if card_lines else '(ì—†ìŒ)'}

ìœ„ ì›êµ­ íŒ©íŠ¸ì™€ ë£°ì¹´ë“œë¥¼ ê·¼ê±°ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
"""
    
    def _enforce_engine_headline(self, body_markdown: str, engine_headline: str) -> str:
        if not engine_headline: return body_markdown
        headline = engine_headline.strip()
        body_stripped = body_markdown.lstrip()
        if body_stripped.startswith(headline) or (len(body_stripped) > 50 and headline[:30] in body_stripped[:100]):
            return body_markdown
        return f"{headline}\n\n{body_stripped}"
    
    async def regenerate_single_section(self, section_id: str, saju_data: Dict, rulecards: List[Dict], feature_tags: List[str] = None, target_year: int = 2026, user_question: str = "", survey_data: Dict = None):
        self._client = self._get_client()
        self._semaphore = asyncio.Semaphore(1)
        spec = PREMIUM_SECTIONS.get(section_id)
        if not spec: raise ValueError(f"Invalid section_id: {section_id}")
        alloc = allocate_rulecards_to_section(rulecards, section_id, spec.max_cards, set(), survey_data)
        engine_headline = extract_engine_headline(alloc.cards)
        result = await self._generate_section_safe(section_id=section_id, saju_data=saju_data, allocation=alloc, target_year=target_year, survey_data=survey_data, engine_headline=engine_headline, existing_contents=[])
        return {"success": True, "section": result}

premium_report_builder = PremiumReportBuilder()
report_builder = premium_report_builder