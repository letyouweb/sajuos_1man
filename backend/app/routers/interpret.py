"""
/interpret endpoint - Premium Business Report Engine v4
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1) ë£°ì¹´ë“œ ì„ íƒ ì—”ì§„: featureTags + Top-100 RuleCards
2) JSON Schema ê°•ì œ: Responses API + json_schema(strict)
3) ì•ˆì •ì„±: Semaphore(2), exponential backoff, regenerate-section
4) ğŸ”¥ SSE ìŠ¤íŠ¸ë¦¬ë°: ì‹¤ì‹œê°„ ì§„í–‰ ìƒíƒœ + ì¬ì‹œë„ í‘œì‹œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
from fastapi import APIRouter, HTTPException, Request, Query, BackgroundTasks
from fastapi.responses import JSONResponse, StreamingResponse
from typing import Optional, List
import logging
import asyncio
import json

from app.models.schemas import (
    InterpretRequest,
    InterpretResponse,
    ErrorResponse,
    ConcernType
)
from app.services.gpt_interpreter import gpt_interpreter
from app.services.report_builder import premium_report_builder, PREMIUM_SECTIONS
from app.services.engine_v2 import SajuManager
from app.services.job_store import job_store, JobStatus

# RuleCard pipeline
from app.services.feature_tags_no_time import build_feature_tags_no_time_from_pillars
from app.services.preset_type2 import BUSINESS_OWNER_PRESET_V2
from app.services.focus_boost import boost_preset_focus
from app.services.rulecard_selector import select_cards_for_preset

logger = logging.getLogger(__name__)
router = APIRouter()


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Helper Functions
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def _get_pillar_ganji(pillar_data) -> str:
    """ì‚¬ì£¼ ê¸°ë‘¥ì—ì„œ ê°„ì§€ ë¬¸ìì—´ ì¶”ì¶œ"""
    if isinstance(pillar_data, dict):
        if pillar_data.get("ganji"):
            return pillar_data["ganji"]
        gan = pillar_data.get("gan", "")
        ji = pillar_data.get("ji", "")
        if gan and ji:
            return gan + ji
        return ""
    elif isinstance(pillar_data, str):
        return pillar_data
    return ""


def _extract_pillars_from_saju_data(saju_data: dict) -> tuple:
    """ì‚¬ì£¼ ë°ì´í„°ì—ì„œ ì—°/ì›”/ì¼ ê°„ì§€ ì¶”ì¶œ"""
    if "saju" in saju_data and isinstance(saju_data["saju"], dict):
        saju = saju_data["saju"]
        year_p = _get_pillar_ganji(saju.get("year_pillar", {}))
        month_p = _get_pillar_ganji(saju.get("month_pillar", {}))
        day_p = _get_pillar_ganji(saju.get("day_pillar", {}))
        return year_p, month_p, day_p
    
    year_p = _get_pillar_ganji(saju_data.get("year_pillar", saju_data.get("year", "")))
    month_p = _get_pillar_ganji(saju_data.get("month_pillar", saju_data.get("month", "")))
    day_p = _get_pillar_ganji(saju_data.get("day_pillar", saju_data.get("day", "")))
    
    return year_p, month_p, day_p


def _get_rulecards_and_feature_tags(
    saju_data: dict, 
    store, 
    target_year: int
) -> tuple:
    """
    ì‚¬ì£¼ ë°ì´í„°ì—ì„œ RuleCards + FeatureTags ë°˜í™˜
    Returns: (rulecards: List, feature_tags: List, pool_count: int)
    """
    year_p, month_p, day_p = _extract_pillars_from_saju_data(saju_data)
    
    logger.info(f"[RuleCards] ê¸°ë‘¥ ì¶”ì¶œ: ë…„={year_p}, ì›”={month_p}, ì¼={day_p}")
    
    if not (year_p and month_p and day_p):
        logger.warning("[RuleCards] ì‚¬ì£¼ ê¸°ë‘¥ ë°ì´í„° ë¶€ì¡±")
        return [], [], 0
    
    # FeatureTags ìƒì„±
    ft = build_feature_tags_no_time_from_pillars(year_p, month_p, day_p, overlay_year=target_year)
    feature_tags = ft.get("tags", [])
    
    logger.info(f"[RuleCards] FeatureTags ìƒì„±: {len(feature_tags)}ê°œ")
    
    # Preset ë¶€ìŠ¤íŠ¸ ë° ì¹´ë“œ ì„ íƒ
    boosted = boost_preset_focus(BUSINESS_OWNER_PRESET_V2, feature_tags)
    selection = select_cards_for_preset(store, boosted, feature_tags)
    
    # ëª¨ë“  ì¹´ë“œ ìˆ˜ì§‘
    all_cards = []
    for sec in selection.get("sections", []):
        all_cards.extend(sec.get("cards", []))
    
    pool_count = len(all_cards)
    logger.info(f"[RuleCards] âœ… Pool={pool_count}ì¥, FeatureTags={len(feature_tags)}ê°œ")
    
    return all_cards, feature_tags, pool_count


def inject_year_context(question: str, target_year: int) -> str:
    """ì—°ë„ ê°•ì œ ì»¨í…ìŠ¤íŠ¸ ì£¼ì…"""
    return f"""[ë¶„ì„ ê¸°ì¤€ ê³ ì •]
- ì´ ë¶„ì„ì€ ë°˜ë“œì‹œ {target_year}ë…„ 1ì›”~12ì›” ê¸°ì¤€ìœ¼ë¡œë§Œ ì‘ì„±í•©ë‹ˆë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}""".strip()


def _extract_saju_data_from_payload(payload: InterpretRequest) -> dict:
    """payloadì—ì„œ ì‚¬ì£¼ ë°ì´í„° ì¶”ì¶œ"""
    if payload.saju_result:
        return payload.saju_result.model_dump()
    
    if not all([payload.year_pillar, payload.month_pillar, payload.day_pillar]):
        raise HTTPException(
            status_code=400,
            detail={"error_code": "MISSING_SAJU_DATA", "message": "Saju data required"}
        )
    
    return {
        "year_pillar": payload.year_pillar,
        "month_pillar": payload.month_pillar,
        "day_pillar": payload.day_pillar,
        "hour_pillar": payload.hour_pillar,
        "day_master": payload.day_pillar[0] if payload.day_pillar else "",
        "day_master_element": ""
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# API Endpoints
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.post(
    "/interpret",
    response_model=InterpretResponse,
    responses={400: {"model": ErrorResponse}, 500: {"model": ErrorResponse}},
    summary="Saju Interpretation (Legacy)"
)
async def interpret_saju(
    payload: InterpretRequest,
    raw: Request,
    mode: str = Query("auto", description="auto | direct | premium")
):
    """ì‚¬ì£¼ í•´ì„ API (Legacy ë‹¨ì¼ í˜¸ì¶œ)"""
    if mode == "premium":
        return await generate_premium_report(payload, raw, mode)
    
    saju_data = _extract_saju_data_from_payload(payload)
    question = payload.question
    final_year = payload.target_year if payload.target_year else 2026
    
    store = getattr(raw.app.state, "rulestore", None)
    
    if store and mode != "direct":
        try:
            rulecards, feature_tags, pool_count = _get_rulecards_and_feature_tags(
                saju_data, store, final_year
            )
            # ë ˆê±°ì‹œ ëª¨ë“œëŠ” ì»¨í…ìŠ¤íŠ¸ë§Œ ì¶”ê°€
        except Exception as e:
            logger.warning(f"[RuleCards] ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    question_with_context = inject_year_context(question, final_year)
    logger.info(f"[INTERPRET] Year={final_year} | Mode={mode}")

    try:
        result = await gpt_interpreter.interpret(
            saju_data=saju_data,
            name=payload.name,
            gender=payload.gender.value if payload.gender else None,
            concern_type=payload.concern_type,
            question=question_with_context
        )
        return result
    except Exception as e:
        logger.error(f"[INTERPRET] Error: {type(e).__name__}")
        raise HTTPException(status_code=500, detail={"error_code": "INTERPRETATION_ERROR", "message": str(e)[:200]})


@router.post(
    "/generate-report",
    responses={400: {"model": ErrorResponse}, 500: {"model": ErrorResponse}},
    summary="99,000ì› í”„ë¦¬ë¯¸ì—„ 30í˜ì´ì§€ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤íŒ… ë³´ê³ ì„œ"
)
async def generate_premium_report(
    payload: InterpretRequest,
    raw: Request,
    mode: str = Query("premium", description="premium | legacy")
):
    """
    ğŸ¯ 99,000ì› í”„ë¦¬ë¯¸ì—„ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤íŒ… ë³´ê³ ì„œ v4
    
    **í•µì‹¬ ê°œì„ ì‚¬í•­:**
    1. ë£°ì¹´ë“œ ì„ íƒ ì—”ì§„: featureTags + ì‚¬ì—…ê°€í˜• íƒœê·¸ 50ê°œ â†’ Top-100 RuleCards
    2. JSON Schema ê°•ì œ: Responses API + json_schema(strict)
    3. ì•ˆì •ì„±: Semaphore(2), exponential backoff + jitter, 3íšŒ ì¬ì‹œë„
    
    **ì‘ë‹µ metaì— í¬í•¨:**
    - rulecards_pool_total: ì „ì²´ ë£°ì¹´ë“œ ìˆ˜
    - rulecards_selected_total: ì„ íƒëœ ë£°ì¹´ë“œ ìˆ˜
    - rulecards_by_section: ì„¹ì…˜ë³„ selected_count, pool_count, selected_card_ids
    - feature_tags_count: ì‚¬ìš©ëœ featureTags ìˆ˜
    """
    if mode == "legacy":
        return await interpret_saju(payload, raw, "auto")
    
    saju_data = _extract_saju_data_from_payload(payload)
    final_year = payload.target_year if payload.target_year else 2026
    
    # RuleStoreì—ì„œ RuleCards + FeatureTags ê°€ì ¸ì˜¤ê¸°
    store = getattr(raw.app.state, "rulestore", None)
    rulecards = []
    feature_tags = []
    pool_count = 0
    
    if store:
        try:
            rulecards, feature_tags, pool_count = _get_rulecards_and_feature_tags(
                saju_data, store, final_year
            )
        except Exception as e:
            logger.warning(f"[PremiumReport] RuleCards ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        logger.warning("[PremiumReport] âš ï¸ RuleStore ë¯¸ë¡œë“œ")
    
    logger.info(
        f"[PREMIUM-REPORT] Year={final_year} | "
        f"RuleCards Pool={pool_count} | FeatureTags={len(feature_tags)}"
    )
    
    try:
        report = await premium_report_builder.build_premium_report(
            saju_data=saju_data,
            rulecards=rulecards,
            feature_tags=feature_tags,  # â† featureTags ì „ë‹¬
            target_year=final_year,
            user_question=payload.question,
            name=payload.name,
            mode="premium_business_30p"
        )
        
        return JSONResponse(content=report)
        
    except Exception as e:
        logger.error(f"[PREMIUM-REPORT] Error: {type(e).__name__}: {str(e)[:200]}")
        
        return JSONResponse(
            status_code=500,
            content={
                "error": True,
                "error_code": "REPORT_GENERATION_ERROR",
                "message": str(e)[:200],
                "target_year": final_year,
                "sections": [],
                "meta": {
                    "mode": "premium_business_30p", 
                    "error": True,
                    "rulecards_pool_total": pool_count,
                    "feature_tags_count": len(feature_tags)
                }
            }
        )


@router.post(
    "/regenerate-section",
    responses={400: {"model": ErrorResponse}, 500: {"model": ErrorResponse}},
    summary="ë‹¨ì¼ ì„¹ì…˜ ì¬ìƒì„± (ì˜¤ë¥˜ ë³µêµ¬ìš©)"
)
async def regenerate_single_section(
    payload: InterpretRequest,
    raw: Request,
    section_id: str = Query(..., description="ì¬ìƒì„±í•  ì„¹ì…˜ ID (exec, money, business, team, health, calendar, sprint)")
):
    """
    ğŸ”„ ë‹¨ì¼ ì„¹ì…˜ ì¬ìƒì„± ì—”ë“œí¬ì¸íŠ¸
    
    ì „ì²´ ë¦¬í¬íŠ¸ ì¬ìƒì„± ì—†ì´ íŠ¹ì • ì„¹ì…˜ë§Œ ì¬ìƒì„±í•©ë‹ˆë‹¤.
    "ì´ ì„¹ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜" ë°œìƒ ì‹œ ë³µêµ¬ìš©ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    **ì‚¬ìš© ì˜ˆì‹œ:**
    ```
    POST /api/v1/regenerate-section?section_id=sprint
    ```
    
    **ì‘ë‹µ í˜•ì‹:**
    ```json
    {
      "success": true,
      "section": {
        "id": "sprint",
        "title": "90-Day Sprint Plan",
        "rulecard_selected": 10,
        "rulecard_pool": 480,
        "char_count": 2500,
        ...
      }
    }
    ```
    """
    # section_id ê²€ì¦
    valid_sections = list(PREMIUM_SECTIONS.keys())
    if section_id not in valid_sections:
        raise HTTPException(
            status_code=400,
            detail={
                "error_code": "INVALID_SECTION_ID",
                "message": f"Invalid section_id: {section_id}. Valid: {valid_sections}"
            }
        )
    
    saju_data = _extract_saju_data_from_payload(payload)
    final_year = payload.target_year if payload.target_year else 2026
    
    # RuleCards + FeatureTags
    store = getattr(raw.app.state, "rulestore", None)
    rulecards = []
    feature_tags = []
    
    if store:
        try:
            rulecards, feature_tags, pool_count = _get_rulecards_and_feature_tags(
                saju_data, store, final_year
            )
        except Exception as e:
            logger.warning(f"[RegenerateSection] RuleCards ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    logger.info(
        f"[REGENERATE-SECTION] Section={section_id} | Year={final_year} | "
        f"RuleCards={len(rulecards)} | FeatureTags={len(feature_tags)}"
    )
    
    try:
        result = await premium_report_builder.regenerate_single_section(
            section_id=section_id,
            saju_data=saju_data,
            rulecards=rulecards,
            feature_tags=feature_tags,
            target_year=final_year,
            user_question=payload.question
        )
        
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"[REGENERATE-SECTION] Error: {type(e).__name__}: {str(e)[:200]}")
        
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "section_id": section_id,
                "error": str(e)[:500],
                "error_type": type(e).__name__
            }
        )


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Utility Endpoints
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.get("/interpret/today", summary="Today Date (KST)")
async def get_today_context():
    today = SajuManager.get_today_kst()
    return {
        "today_kst": SajuManager.get_today_string(),
        "year": today.year,
        "month": today.month,
        "day": today.day
    }


@router.get("/interpret/cost-estimate", summary="Cost Estimate")
async def get_cost_estimate(input_tokens: int = 1500, output_tokens: int = 1000):
    return gpt_interpreter.estimate_cost(input_tokens, output_tokens)


@router.get("/interpret/concern-types", summary="Concern Types")
async def get_concern_types():
    return {
        "concern_types": [
            {"value": "love", "label": "Love/Marriage", "emoji": "ğŸ’•"},
            {"value": "wealth", "label": "Wealth/Finance", "emoji": "ğŸ’°"},
            {"value": "career", "label": "Career/Business", "emoji": "ğŸ’¼"},
            {"value": "health", "label": "Health", "emoji": "ğŸ¥"},
            {"value": "study", "label": "Study/Exam", "emoji": "ğŸ“š"},
            {"value": "general", "label": "General Fortune", "emoji": "ğŸ”®"}
        ]
    }


@router.get("/interpret/rulecards-status", summary="RuleCards Status")
async def get_rulecards_status(raw: Request):
    """RuleCards ë¡œë“œ ìƒíƒœ í™•ì¸"""
    store = getattr(raw.app.state, "rulestore", None)
    if store:
        return {
            "loaded": True,
            "total_cards": len(store.cards),
            "topics": list(store.by_topic.keys())[:20],
            "topics_count": len(store.by_topic)
        }
    return {"loaded": False, "total_cards": 0, "topics": [], "topics_count": 0}


@router.get("/interpret/premium-sections", summary="Premium Report Sections Info")
async def get_premium_sections():
    """í”„ë¦¬ë¯¸ì—„ ë¦¬í¬íŠ¸ ì„¹ì…˜ ì •ë³´"""
    return {
        "mode": "premium_business_30p",
        "price": "99,000ì›",
        "total_pages": sum(s.pages for s in PREMIUM_SECTIONS.values()),
        "sections": [
            {
                "id": spec.id,
                "title": spec.title,
                "pages": spec.pages,
                "max_cards": spec.max_cards,
                "min_chars": spec.min_chars,
                "validation_type": spec.validation_type
            }
            for spec in PREMIUM_SECTIONS.values()
        ]
    }


@router.get("/interpret/gpt-test", summary="GPT API Connection Test")
async def test_gpt_connection():
    """GPT API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    from app.config import get_settings
    from app.services.openai_key import get_openai_api_key, key_fingerprint, key_tail
    from openai import AsyncOpenAI
    import httpx
    
    settings = get_settings()
    
    try:
        api_key = get_openai_api_key()
        key_preview = f"fp={key_fingerprint(api_key)} tail={key_tail(api_key)}"
    except RuntimeError as e:
        return {"success": False, "error": str(e)}
    
    try:
        client = AsyncOpenAI(api_key=api_key, timeout=httpx.Timeout(30.0, connect=10.0))
        resp = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": "Say hello"}],
            max_tokens=20
        )
        return {
            "success": True,
            "api_key_preview": key_preview,
            "model": settings.openai_model,
            "response": resp.choices[0].message.content,
            "concurrency": settings.report_max_concurrency,
            "status": "READY_FOR_PRODUCTION"
        }
    except Exception as e:
        return {"success": False, "error_type": type(e).__name__, "error": str(e)[:200]}



# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”¥ SSE ìŠ¤íŠ¸ë¦¬ë° API (ì‹¤ì‹œê°„ ì§„í–‰ ìƒíƒœ)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

async def _run_report_generation(
    job_id: str,
    saju_data: dict,
    rulecards: list,
    feature_tags: list,
    target_year: int,
    user_question: str,
    name: str
):
    """ë°±ê·¸ë¼ìš´ë“œ ë¦¬í¬íŠ¸ ìƒì„± íƒœìŠ¤í¬"""
    try:
        await premium_report_builder.build_premium_report(
            saju_data=saju_data,
            rulecards=rulecards,
            feature_tags=feature_tags,
            target_year=target_year,
            user_question=user_question,
            name=name,
            mode="premium_business_30p",
            job_id=job_id
        )
    except Exception as e:
        logger.error(f"[AsyncReport] Job {job_id} ì‹¤íŒ¨: {e}")
        await job_store.fail_job(job_id, str(e)[:500])


@router.post(
    "/generate-report-async",
    responses={400: {"model": ErrorResponse}},
    summary="ğŸ”¥ ë¹„ë™ê¸° í”„ë¦¬ë¯¸ì—„ ë³´ê³ ì„œ ìƒì„± (SSEìš©)"
)
async def generate_report_async(
    payload: InterpretRequest,
    raw: Request,
    background_tasks: BackgroundTasks
):
    """
    ğŸ¯ ë¹„ë™ê¸° í”„ë¦¬ë¯¸ì—„ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘
    
    ì¦‰ì‹œ job_id ë°˜í™˜ â†’ SSEë¡œ ì§„í–‰ ìƒíƒœ ìŠ¤íŠ¸ë¦¬ë°
    
    **ì‘ë‹µ:**
    ```json
    {
      "job_id": "abc12345",
      "status": "queued",
      "stream_url": "/api/v1/report-progress/stream?job_id=abc12345",
      "result_url": "/api/v1/report-result?job_id=abc12345"
    }
    ```
    """
    saju_data = _extract_saju_data_from_payload(payload)
    final_year = payload.target_year if payload.target_year else 2026
    
    # RuleCards + FeatureTags ì¤€ë¹„
    store = getattr(raw.app.state, "rulestore", None)
    rulecards = []
    feature_tags = []
    
    if store:
        try:
            rulecards, feature_tags, _ = _get_rulecards_and_feature_tags(
                saju_data, store, final_year
            )
        except Exception as e:
            logger.warning(f"[AsyncReport] RuleCards ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # Job ìƒì„± (ì„¹ì…˜ ì •ë³´ í¬í•¨)
    section_specs = [(spec.id, spec.title) for spec in PREMIUM_SECTIONS.values()]
    job_id = await job_store.create_job(section_specs)
    
    logger.info(f"[AsyncReport] Job ìƒì„±: {job_id} | Year={final_year}")
    
    # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ë“±ë¡
    background_tasks.add_task(
        _run_report_generation,
        job_id=job_id,
        saju_data=saju_data,
        rulecards=rulecards,
        feature_tags=feature_tags,
        target_year=final_year,
        user_question=payload.question,
        name=payload.name
    )
    
    return JSONResponse(content={
        "job_id": job_id,
        "status": "queued",
        "stream_url": f"/api/v1/report-progress/stream?job_id={job_id}",
        "result_url": f"/api/v1/report-result?job_id={job_id}",
        "sections": [{"id": s.id, "title": s.title} for s in PREMIUM_SECTIONS.values()]
    })


@router.get(
    "/report-progress/stream",
    summary="ğŸ”¥ SSE ì§„í–‰ ìƒíƒœ ìŠ¤íŠ¸ë¦¬ë°"
)
async def stream_report_progress(
    job_id: str = Query(..., description="Job ID")
):
    """
    ğŸ¯ SSE(Server-Sent Events) ì‹¤ì‹œê°„ ì§„í–‰ ìƒíƒœ ìŠ¤íŠ¸ë¦¬ë°
    
    **ì´ë²¤íŠ¸ í˜•ì‹:**
    ```
    event: progress
    data: {"job_id":"abc","overall":{"total":7,"done":3,"percent":42},...}
    
    event: complete
    data: {"job_id":"abc"}
    ```
    
    **í”„ë¡ íŠ¸ì—”ë“œ ì‚¬ìš© ì˜ˆ:**
    ```javascript
    const evtSource = new EventSource('/api/v1/report-progress/stream?job_id=abc');
    evtSource.addEventListener('progress', (e) => {
      const data = JSON.parse(e.data);
      console.log('ì§„í–‰ë¥ :', data.overall.percent);
    });
    evtSource.addEventListener('complete', () => {
      evtSource.close();
      // ê²°ê³¼ fetch
    });
    ```
    """
    job = await job_store.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
    
    async def event_generator():
        queue = await job_store.subscribe(job_id)
        
        try:
            # ì´ˆê¸° ìƒíƒœ ì „ì†¡
            initial = (await job_store.get_job(job_id))
            if initial:
                yield f"event: progress\ndata: {json.dumps(initial.to_dict())}\n\n"
            
            while True:
                try:
                    # 5ì´ˆ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì´ë²¤íŠ¸ ëŒ€ê¸°
                    data = await asyncio.wait_for(queue.get(), timeout=5.0)
                    
                    # ì™„ë£Œ ì‹ í˜¸ í™•ì¸
                    if isinstance(data, dict) and data.get("type") == "complete":
                        yield f"event: complete\ndata: {json.dumps({'job_id': job_id})}\n\n"
                        break
                    
                    yield f"event: progress\ndata: {json.dumps(data)}\n\n"
                    
                except asyncio.TimeoutError:
                    # keepalive
                    yield f": keepalive\n\n"
                    
                    # Job ìƒíƒœ í™•ì¸
                    current_job = await job_store.get_job(job_id)
                    if not current_job:
                        break
                    if current_job.status in [JobStatus.COMPLETED, JobStatus.FAILED]:
                        yield f"event: complete\ndata: {json.dumps({'job_id': job_id, 'status': current_job.status.value})}\n\n"
                        break
                        
        except Exception as e:
            logger.error(f"[SSE] ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
            yield f"event: error\ndata: {json.dumps({'error': str(e)[:200]})}\n\n"
        finally:
            await job_store.unsubscribe(job_id, queue)
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
        }
    )


@router.get(
    "/report-result",
    summary="ì™„ë£Œëœ ë¦¬í¬íŠ¸ ê²°ê³¼ ì¡°íšŒ"
)
async def get_report_result(
    job_id: str = Query(..., description="Job ID")
):
    """
    ğŸ¯ ì™„ë£Œëœ ë¦¬í¬íŠ¸ ê²°ê³¼ ì¡°íšŒ
    
    Jobì´ ì™„ë£Œë˜ë©´ ìµœì¢… ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì§„í–‰ ì¤‘ì´ë©´ í˜„ì¬ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    job = await job_store.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
    
    if job.status == JobStatus.COMPLETED and job.final_result:
        return JSONResponse(content={
            "status": "completed",
            "job_id": job_id,
            "result": job.final_result
        })
    
    if job.status == JobStatus.FAILED:
        return JSONResponse(
            status_code=500,
            content={
                "status": "failed",
                "job_id": job_id,
                "error": job.error_message
            }
        )
    
    # ì•„ì§ ì§„í–‰ ì¤‘
    return JSONResponse(content={
        "status": job.status.value,
        "job_id": job_id,
        "progress": job.to_dict()
    })


@router.get(
    "/report-progress",
    summary="ì§„í–‰ ìƒíƒœ í´ë§ ì¡°íšŒ (SSE ëŒ€ì•ˆ)"
)
async def get_report_progress(
    job_id: str = Query(..., description="Job ID")
):
    """
    ğŸ¯ í´ë§ ë°©ì‹ ì§„í–‰ ìƒíƒœ ì¡°íšŒ
    
    SSEê°€ ë¶ˆì•ˆì •í•œ í™˜ê²½ì—ì„œ 1~2ì´ˆë§ˆë‹¤ í˜¸ì¶œí•˜ì—¬ ì§„í–‰ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    job = await job_store.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
    
    return JSONResponse(content=job.to_dict())
