"""
Reports API Router v11 - P0: íƒ­ ê°•ì œ ìƒì„± + ì„¹ì…˜ placeholder
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
P0 í•µì‹¬ ìˆ˜ì •:
1) ğŸ”¥ íƒ­ ê°•ì œ: DBì— ì„¹ì…˜ ì—†ì–´ë„ 7ê°œ íƒ­ ëª¨ë‘ ë°˜í™˜
2) full_markdown = ì„¹ì…˜ë³„ markdown ìˆœì„œëŒ€ë¡œ í•©ì¹¨
3) completedì¸ë° ì„¹ì…˜ ë¹„ë©´ â†’ ê²½ê³  ë¡œê·¸
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
from fastapi import APIRouter, HTTPException, Request, BackgroundTasks, Query
from pydantic import BaseModel, EmailStr
from typing import Optional, Dict, Any, List
import logging
import uuid

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/reports", tags=["reports"])


class ReportStartRequest(BaseModel):
    email: EmailStr
    name: str = "ê³ ê°"
    saju_result: Optional[Dict[str, Any]] = None
    year_pillar: Optional[str] = None
    month_pillar: Optional[str] = None
    day_pillar: Optional[str] = None
    hour_pillar: Optional[str] = None
    target_year: int = 2026
    question: str = ""
    concern_type: str = "career"
    survey_data: Optional[Dict[str, Any]] = None


def get_supabase():
    try:
        from app.services.supabase_service import supabase_service
        return supabase_service
    except Exception as e:
        logger.error(f"Supabase import ì‹¤íŒ¨: {e}")
        return None


# ğŸ”¥ ì„¹ì…˜ ìˆœì„œ ê³ ì • (7ê°œ)
SECTION_ORDER = ["exec", "money", "business", "team", "health", "calendar", "sprint"]

SECTION_SPECS = [
    {"id": "exec", "title": "Executive Summary", "order": 1, "icon": "ğŸ“Š"},
    {"id": "money", "title": "Money & Cashflow", "order": 2, "icon": "ğŸ’°"},
    {"id": "business", "title": "Business Strategy", "order": 3, "icon": "ğŸ¯"},
    {"id": "team", "title": "Team & Partner", "order": 4, "icon": "ğŸ¤"},
    {"id": "health", "title": "Health & Performance", "order": 5, "icon": "â¤ï¸"},
    {"id": "calendar", "title": "12-Month Calendar", "order": 6, "icon": "ğŸ“…"},
    {"id": "sprint", "title": "90-Day Sprint", "order": 7, "icon": "ğŸš€"},
]


def get_section_title(section_id: str) -> str:
    for spec in SECTION_SPECS:
        if spec["id"] == section_id:
            return spec["title"]
    return section_id or "Unknown"


def get_section_order(section_id: str) -> int:
    if section_id in SECTION_ORDER:
        return SECTION_ORDER.index(section_id) + 1
    return 99


def get_section_icon(section_id: str) -> str:
    for spec in SECTION_SPECS:
        if spec["id"] == section_id:
            return spec.get("icon", "ğŸ“„")
    return "ğŸ“„"


def extract_markdown_from_section(section: Dict) -> str:
    if section.get("markdown"):
        return section["markdown"]
    raw_json = section.get("raw_json") or {}
    if raw_json.get("body_markdown"):
        return raw_json["body_markdown"]
    if raw_json.get("content"):
        return raw_json["content"]
    return ""


def normalize_section(section: Dict) -> Dict:
    section_id = section.get("section_id") or section.get("id", "")
    raw_json = section.get("raw_json") or {}
    markdown = section.get("markdown") or extract_markdown_from_section(section)
    
    return {
        "section_id": section_id,
        "id": section_id,
        "title": section.get("title") or get_section_title(section_id),
        "icon": get_section_icon(section_id),
        "status": section.get("status", "completed"),
        "order": section.get("order") or get_section_order(section_id),
        "markdown": markdown,
        "content": markdown,
        "body_markdown": markdown,
        "raw_json": raw_json,
        "char_count": section.get("char_count") or len(markdown),
        "error": section.get("error"),
        "updated_at": section.get("updated_at"),
    }


def ensure_all_sections(sections_raw: List[Dict], job_id: str) -> List[Dict]:
    """
    ğŸ”¥ P0 íƒ­ ê°•ì œ: DBì— ì„¹ì…˜ì´ ì—†ì–´ë„ 7ê°œ íƒ­ ëª¨ë‘ ë°˜í™˜
    """
    sections_by_id = {s.get("section_id"): s for s in sections_raw}
    sections_normalized = []
    
    for spec in SECTION_SPECS:
        sid = spec["id"]
        s = sections_by_id.get(sid)
        
        if s:
            sections_normalized.append(normalize_section(s))
        else:
            # ğŸ”¥ íƒ­ ê°•ì œ: ì„¹ì…˜ì´ DBì— ì—†ì–´ë„ íƒ­ì€ ë³´ì—¬ì¤€ë‹¤
            sections_normalized.append({
                "section_id": sid,
                "id": sid,
                "title": spec["title"],
                "icon": spec.get("icon", "ğŸ“„"),
                "status": "empty",
                "order": spec["order"],
                "markdown": "â³ ì´ ì„¹ì…˜ì€ í˜„ì¬ ìƒì„± ì¤‘ì´ê±°ë‚˜ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "content": "",
                "body_markdown": "",
                "raw_json": {},
                "char_count": 0,
                "error": "SECTION_MISSING",
            })
            logger.warning(f"[Reports] ğŸ”¥ íƒ­ ê°•ì œ ìƒì„±: {sid} | job={job_id}")
    
    sections_normalized.sort(key=lambda x: x.get("order", 99))
    return sections_normalized


def build_full_markdown(sections: List[Dict], name: str = "ê³ ê°", target_year: int = 2026) -> str:
    lines = [f"# {name}ë‹˜ì˜ {target_year}ë…„ ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì„¸ ë¦¬í¬íŠ¸\n"]
    
    for section in sections:
        section_id = section.get("section_id") or section.get("id", "")
        title = section.get("title") or get_section_title(section_id)
        markdown = section.get("markdown") or ""
        
        if markdown and section.get("status") != "empty":
            lines.append(f"## {title}\n")
            lines.append(markdown)
            lines.append("\n---\n")
    
    return "\n".join(lines)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”¥ ë””ë²„ê·¸ ì—”ë“œí¬ì¸íŠ¸
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.get("/debug/{job_id}")
async def debug_job(job_id: str):
    supabase = get_supabase()
    if not supabase or not supabase.is_available():
        return {"error": "Supabase ë¯¸ì—°ê²°"}
    
    job = await supabase.get_job(job_id)
    if not job:
        return {"error": f"Job not found: {job_id}"}
    
    sections_raw = await supabase.get_sections_ordered(job_id)
    
    return {
        "job_id": job_id,
        "job_status": job.get("status"),
        "sections_count": len(sections_raw),
        "sections": [{
            "section_id": s.get("section_id"),
            "status": s.get("status"),
            "markdown_length": len(s.get("markdown") or ""),
        } for s in sections_raw],
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ê³ ì • ê²½ë¡œ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.post("/start")
async def start_report(payload: ReportStartRequest, background_tasks: BackgroundTasks, request: Request):
    input_data = {
        "name": payload.name,
        "question": payload.question,
        "concern_type": payload.concern_type,
        "target_year": payload.target_year,
        "survey_data": payload.survey_data,
        "saju_result": payload.saju_result,
        "year_pillar": payload.year_pillar,
        "month_pillar": payload.month_pillar,
        "day_pillar": payload.day_pillar,
        "hour_pillar": payload.hour_pillar,
    }
    
    supabase = get_supabase()
    
    if supabase and supabase.is_available():
        try:
            job = await supabase.create_job(
                email=payload.email,
                name=payload.name,
                input_data=input_data,
                target_year=payload.target_year
            )
            job_id = job["id"]
            public_token = job.get("public_token")
            
            logger.info(f"[Reports] Job ìƒì„±: {job_id}")
            
            try:
                await supabase.init_sections(job_id, SECTION_SPECS)
            except Exception as e:
                logger.warning(f"ì„¹ì…˜ ì´ˆê¸°í™” ìŠ¤í‚µ: {e}")
            
            rulestore = getattr(request.app.state, "rulestore", None)
            background_tasks.add_task(run_report_job, job_id, rulestore)
            
            return {
                "success": True,
                "job_id": job_id,
                "token": public_token,
                "status": "queued",
                "message": "ë¦¬í¬íŠ¸ ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            }
        except Exception as e:
            logger.error(f"Job ìƒì„± ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail=str(e)[:300])
    else:
        temp_id = str(uuid.uuid4())
        return {"success": True, "job_id": temp_id, "status": "queued"}


@router.get("/start")
async def start_report_get():
    return {"error": "Use POST method"}


@router.get("/sections-info")
async def get_sections_info():
    return {"sections": SECTION_SPECS}


@router.get("/view/{job_id}")
async def view_report(job_id: str, token: str = Query(..., description="Access token")):
    """
    ğŸ”¥ğŸ”¥ğŸ”¥ P0: íƒ­ ê°•ì œ - 7ê°œ ì„¹ì…˜ ë¬´ì¡°ê±´ ë°˜í™˜
    """
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id: {job_id}")
    
    supabase = get_supabase()
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    is_valid, job = await supabase.verify_job_token(job_id, token)
    if not is_valid or not job:
        raise HTTPException(status_code=404, detail="Invalid token or job not found")
    
    # DBì—ì„œ ì„¹ì…˜ ì¡°íšŒ
    sections_raw = await supabase.get_sections_ordered(job_id)
    sections_raw = [s for s in sections_raw if s.get("job_id") == job_id]
    
    # ğŸ”¥ P0 íƒ­ ê°•ì œ: 7ê°œ ì„¹ì…˜ ë¬´ì¡°ê±´ ë°˜í™˜
    sections_normalized = ensure_all_sections(sections_raw, job_id)
    
    # ìƒíƒœ ì²´í¬
    job_status = job.get("status")
    db_section_count = len([s for s in sections_raw if s.get("section_id")])
    
    if job_status == "completed" and db_section_count == 0:
        logger.error(f"[Reports] âŒ COMPLETEDì¸ë° DB ì„¹ì…˜ 0ê°œ: {job_id}")
    
    # full_markdown ìƒì„±
    input_json = job.get("input_json") or {}
    name = input_json.get("name", "ê³ ê°")
    target_year = input_json.get("target_year", 2026)
    full_markdown = build_full_markdown(sections_normalized, name, target_year)
    
    logger.info(f"[Reports] view_report: {job_id} | db_sections={db_section_count} | total_tabs=7 | markdown_len={len(full_markdown)}")
    
    return {
        "job": {
            "id": job["id"],
            "status": job.get("status"),
            "progress": job.get("progress", 0),
            "completed_at": job.get("completed_at"),
            "error": job.get("error"),
        },
        "input": input_json,
        "sections": sections_normalized,
        "full_markdown": full_markdown,
        "section_count": 7,  # ğŸ”¥ í•­ìƒ 7
    }


@router.get("/verify/{job_id}")
async def verify_token(job_id: str, token: str = Query(...)):
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id: {job_id}")
    
    supabase = get_supabase()
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    is_valid, job = await supabase.verify_job_token(job_id, token)
    if not is_valid:
        raise HTTPException(status_code=403, detail="Invalid token")
    
    return {"valid": True, "job_id": job["id"], "status": job.get("status")}


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë™ì  ê²½ë¡œ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.get("/{job_id}/status")
async def get_job_status(job_id: str):
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id: {job_id}")
    
    supabase = get_supabase()
    if not supabase or not supabase.is_available():
        return {"job_id": job_id, "status": "unknown", "progress": 0}
    
    try:
        job = await supabase.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")
        
        sections_data = await supabase.get_sections(job_id)
        completed = len([s for s in sections_data if s.get("status") in ("completed", "done", "success")])
        progress = max(job.get("progress", 0), int((completed / 7) * 100))
        
        return {
            "job_id": job_id,
            "status": job.get("status", "unknown"),
            "progress": progress,
            "sections": [{"id": s.get("section_id"), "status": s.get("status")} for s in sections_data],
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e)[:200])


@router.get("/{job_id}")
async def get_report_status(job_id: str, token: Optional[str] = Query(None)):
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id: {job_id}")
    
    supabase = get_supabase()
    if not supabase or not supabase.is_available():
        return {"job_id": job_id, "status": "unknown", "progress": 0}
    
    try:
        if token:
            is_valid, job = await supabase.verify_job_token(job_id, token)
            if not is_valid:
                raise HTTPException(status_code=403, detail="Invalid token")
        else:
            job = await supabase.get_job(job_id)
        
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")
        
        sections_data = await supabase.get_sections(job_id)
        
        return {
            "job_id": job_id,
            "status": job.get("status", "unknown"),
            "progress": job.get("progress", 0),
            "sections": [{"id": s.get("section_id"), "status": s.get("status")} for s in sections_data],
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e)[:200])


@router.get("/{job_id}/result")
async def get_report_result(job_id: str, token: Optional[str] = Query(None)):
    """
    ğŸ”¥ğŸ”¥ğŸ”¥ P0: íƒ­ ê°•ì œ - 7ê°œ ì„¹ì…˜ ë¬´ì¡°ê±´ ë°˜í™˜
    """
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id: {job_id}")
    
    supabase = get_supabase()
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    if token:
        is_valid, job = await supabase.verify_job_token(job_id, token)
        if not is_valid:
            raise HTTPException(status_code=403, detail="Invalid token")
    else:
        job = await supabase.get_job(job_id)
    
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")
    
    if job.get("status") != "completed":
        return {"completed": False, "status": job.get("status"), "progress": job.get("progress", 0)}
    
    # DBì—ì„œ ì„¹ì…˜ ì¡°íšŒ
    sections_raw = await supabase.get_sections_ordered(job_id)
    sections_raw = [s for s in sections_raw if s.get("job_id") == job_id]
    
    # ğŸ”¥ P0 íƒ­ ê°•ì œ: 7ê°œ ì„¹ì…˜ ë¬´ì¡°ê±´ ë°˜í™˜
    sections_normalized = ensure_all_sections(sections_raw, job_id)
    
    db_section_count = len([s for s in sections_raw if s.get("section_id")])
    if db_section_count == 0:
        logger.error(f"[Reports] âŒ result ìš”ì²­ì¸ë° DB ì„¹ì…˜ 0ê°œ: {job_id}")
    
    input_json = job.get("input_json") or {}
    name = input_json.get("name", "ê³ ê°")
    target_year = input_json.get("target_year", 2026)
    full_markdown = build_full_markdown(sections_normalized, name, target_year)
    
    logger.info(f"[Reports] get_report_result: {job_id} | db_sections={db_section_count} | total_tabs=7")
    
    return {
        "completed": True,
        "job": {"id": job["id"], "status": job.get("status"), "completed_at": job.get("completed_at")},
        "input": input_json,
        "sections": sections_normalized,
        "full_markdown": full_markdown,
        "section_count": 7,
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

async def run_report_job(job_id: str, rulestore):
    try:
        from app.services.report_worker import report_worker
        await report_worker.run_job(job_id, rulestore)
    except Exception as e:
        logger.error(f"Report job ì‹¤íŒ¨: {job_id} | {e}")
        supabase = get_supabase()
        if supabase:
            try:
                await supabase.fail_job(job_id, str(e))
            except:
                pass
