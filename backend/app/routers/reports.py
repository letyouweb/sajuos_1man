"""
Reports API Router v10 - P0 Fix: markdown ì»¬ëŸ¼ ê¸°ì¤€ ì¡°íšŒ + full_markdown ìƒì„±
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
P0 í•µì‹¬ ìˆ˜ì •:
1) /view, /resultì—ì„œ ì„¹ì…˜ì„ orderëŒ€ë¡œ ì •ë ¬
2) full_markdown = ì„¹ì…˜ë³„ markdownì„ ìˆœì„œëŒ€ë¡œ í•©ì¹¨
3) completedì¸ë° ì„¹ì…˜ ë¹„ë©´ â†’ ê²½ê³  ë¡œê·¸ + 500
4) sanitize_markdown() ì ìš©
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
from fastapi import APIRouter, HTTPException, Request, BackgroundTasks, Query
from fastapi.responses import JSONResponse
from pydantic import BaseModel, EmailStr
from typing import Optional, Dict, Any, List
import logging
import uuid

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/reports", tags=["reports"])


class ReportStartRequest(BaseModel):
    email: EmailStr
    gender: Optional[str] = None  # pass-through for daeun direction
    birth_info: Optional[Dict[str, Any]] = None  # pass-through for age/daeun
    name: str = "ê³ ê°"
    saju_result: Optional[Dict[str, Any]] = None
    year_pillar: Optional[str] = None
    month_pillar: Optional[str] = None
    day_pillar: Optional[str] = None
    hour_pillar: Optional[str] = None
    target_year: int = 2026
    question: str = ""
    concern_type: str = "career"
    survey_data: Optional[Dict[str, Any]] = None


def get_supabase():
    try:
        from app.services.supabase_service import supabase_service
        return supabase_service
    except Exception as e:
        logger.error(f"Supabase import ì‹¤íŒ¨: {e}")
        return None


# ğŸ”¥ ì„¹ì…˜ ìˆœì„œ (order)
SECTION_ORDER = ["exec", "money", "business", "team", "health", "calendar", "sprint"]

SECTION_SPECS = [
    {"id": "exec", "title": "Executive Summary", "order": 1},
    {"id": "money", "title": "Money & Cashflow", "order": 2},
    {"id": "business", "title": "Business Strategy", "order": 3},
    {"id": "team", "title": "Team & Partner", "order": 4},
    {"id": "health", "title": "Health & Performance", "order": 5},
    {"id": "calendar", "title": "12-Month Calendar", "order": 6},
    {"id": "sprint", "title": "90-Day Sprint", "order": 7},
]


def get_section_title(section_id: str) -> str:
    """section_idë¡œ title ì¡°íšŒ"""
    for spec in SECTION_SPECS:
        if spec["id"] == section_id:
            return spec["title"]
    return section_id or "Unknown"


def get_section_order(section_id: str) -> int:
    """section_idë¡œ order ì¡°íšŒ"""
    if section_id in SECTION_ORDER:
        return SECTION_ORDER.index(section_id) + 1
    return 99


def extract_markdown_from_section(section: Dict) -> str:
    """
    ğŸ”¥ P0: ì„¹ì…˜ì—ì„œ markdown ì¶”ì¶œ (ìš°ì„ ìˆœìœ„)
    1) section.markdown (DB ì»¬ëŸ¼)
    2) raw_json.body_markdown
    3) raw_json â†’ ë§ˆí¬ë‹¤ìš´ ë³€í™˜
    """
    # 1) ì§ì ‘ markdown í•„ë“œ (DB ì»¬ëŸ¼)
    if section.get("markdown"):
        return section["markdown"]
    
    # 2) raw_jsonì—ì„œ ì¶”ì¶œ
    raw_json = section.get("raw_json") or {}
    
    if raw_json.get("body_markdown"):
        return raw_json["body_markdown"]
    
    if raw_json.get("content"):
        return raw_json["content"]
    
    # 3) raw_json êµ¬ì¡°í™” ë°ì´í„° â†’ ë§ˆí¬ë‹¤ìš´ ë³€í™˜
    if raw_json:
        return build_markdown_from_raw_json(section.get("section_id", ""), raw_json)
    
    return ""


def build_markdown_from_raw_json(section_id: str, raw_json: Dict) -> str:
    """raw_jsonì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (fallback)"""
    lines = []
    title = raw_json.get("title") or get_section_title(section_id)
    
    # body_markdownì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    if raw_json.get("body_markdown"):
        return raw_json["body_markdown"]
    
    # diagnosis
    diagnosis = raw_json.get("diagnosis")
    if diagnosis:
        lines.append("### ì§„ë‹¨")
        if diagnosis.get("current_state"):
            lines.append(f"**í˜„ì¬ ìƒíƒœ**: {diagnosis['current_state']}")
        if diagnosis.get("key_issues"):
            lines.append("**í•µì‹¬ ì´ìŠˆ**:")
            for issue in diagnosis["key_issues"]:
                lines.append(f"- {issue}")
        lines.append("")
    
    # hypotheses
    hypotheses = raw_json.get("hypotheses") or []
    if hypotheses:
        lines.append("### ê°€ì„¤")
        for h in hypotheses:
            lines.append(f"- **{h.get('id', '')}**: {h.get('statement', '')} (ì‹ ë¢°ë„: {h.get('confidence', '')})")
        lines.append("")
    
    # strategy_options
    options = raw_json.get("strategy_options") or []
    if options:
        lines.append("### ì „ëµ ì˜µì…˜")
        for opt in options:
            lines.append(f"**{opt.get('name', '')}**: {opt.get('description', '')}")
        lines.append("")
    
    # recommended_strategy
    rec = raw_json.get("recommended_strategy")
    if rec:
        lines.append("### ì¶”ì²œ ì „ëµ")
        lines.append(f"**ì„ íƒ**: {rec.get('selected_option', '')}")
        lines.append(f"**ê·¼ê±°**: {rec.get('rationale', '')}")
        lines.append("")
    
    # kpis
    kpis = raw_json.get("kpis") or []
    if kpis:
        lines.append("### KPI")
        for kpi in kpis:
            lines.append(f"- **{kpi.get('metric', '')}**: ëª©í‘œ {kpi.get('target', '')}")
        lines.append("")
    
    # risks
    risks = raw_json.get("risks") or []
    if risks:
        lines.append("### ë¦¬ìŠ¤í¬")
        for risk in risks:
            lines.append(f"- **{risk.get('risk', '')}**: {risk.get('mitigation', '')}")
        lines.append("")
    
    return "\n".join(lines)


def build_full_markdown(sections: List[Dict], name: str = "ê³ ê°", target_year: int = 2026) -> str:
    """
    ğŸ”¥ P0: ì„¹ì…˜ë“¤ì„ orderëŒ€ë¡œ í•©ì³ì„œ full_markdown ìƒì„±
    """
    lines = []
    lines.append(f"# {name}ë‹˜ì˜ {target_year}ë…„ ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì„¸ ë¦¬í¬íŠ¸\n")
    
    for section in sections:
        section_id = section.get("section_id") or section.get("id", "")
        title = section.get("title") or get_section_title(section_id)
        markdown = section.get("markdown") or extract_markdown_from_section(section)
        
        if markdown:
            lines.append(f"## {title}\n")
            lines.append(markdown)
            lines.append("\n---\n")
    
    return "\n".join(lines)


def normalize_section(section: Dict) -> Dict:
    """
    ğŸ”¥ P0: ì„¹ì…˜ ì •ê·œí™” (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜)
    """
    section_id = section.get("section_id") or section.get("id", "")
    raw_json = section.get("raw_json") or {}
    markdown = section.get("markdown") or extract_markdown_from_section(section)
    
    return {
        "section_id": section_id,
        "id": section_id,  # í˜¸í™˜ì„±
        "title": section.get("title") or get_section_title(section_id),
        "status": section.get("status", "completed"),
        "order": section.get("order") or get_section_order(section_id),
        # ğŸ”¥ í•µì‹¬: markdown í•„ë“œ
        "markdown": markdown,
        "content": markdown,  # í˜¸í™˜ì„±
        "body_markdown": markdown,  # í˜¸í™˜ì„±
        # raw_json (ìƒì„¸ ë°ì´í„°)
        "raw_json": raw_json,
        # ì£¼ìš” í•„ë“œ ì§ì ‘ ë…¸ì¶œ
        "confidence": raw_json.get("confidence", "MEDIUM"),
        "diagnosis": raw_json.get("diagnosis"),
        "hypotheses": raw_json.get("hypotheses"),
        "strategy_options": raw_json.get("strategy_options"),
        "recommended_strategy": raw_json.get("recommended_strategy"),
        "kpis": raw_json.get("kpis"),
        "risks": raw_json.get("risks"),
        # Calendar
        "annual_theme": raw_json.get("annual_theme"),
        "monthly_plans": raw_json.get("monthly_plans"),
        "quarterly_milestones": raw_json.get("quarterly_milestones"),
        "peak_months": raw_json.get("peak_months"),
        "risk_months": raw_json.get("risk_months"),
        # Sprint
        "mission_statement": raw_json.get("mission_statement"),
        "phase_1_offer": raw_json.get("phase_1_offer"),
        "phase_2_funnel": raw_json.get("phase_2_funnel"),
        "phase_3_content": raw_json.get("phase_3_content"),
        "phase_4_automation": raw_json.get("phase_4_automation"),
        "milestones": raw_json.get("milestones"),
        "risk_scenarios": raw_json.get("risk_scenarios"),
        # ë©”íƒ€
        "char_count": section.get("char_count") or len(markdown),
        "error": section.get("error"),
        "updated_at": section.get("updated_at"),
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”¥ ë””ë²„ê·¸ ì—”ë“œí¬ì¸íŠ¸
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.get("/debug/{job_id}")
async def debug_job(job_id: str):
    """ë””ë²„ê·¸ìš©: DBì—ì„œ ì§ì ‘ job + sections ì¡°íšŒ"""
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        return {"error": "Supabase ë¯¸ì—°ê²°"}
    
    job = await supabase.get_job(job_id)
    if not job:
        return {"error": f"Job not found: {job_id}"}
    
    sections_raw = await supabase.get_sections_ordered(job_id)
    
    sections_debug = []
    for s in sections_raw:
        markdown = s.get("markdown") or ""
        raw_json = s.get("raw_json") or {}
        sections_debug.append({
            "section_id": s.get("section_id"),
            "status": s.get("status"),
            "order": s.get("order"),
            "markdown_length": len(markdown),
            "has_raw_json": bool(raw_json),
            "raw_json_body_length": len(raw_json.get("body_markdown", "")),
            "markdown_preview": markdown[:200] + "..." if len(markdown) > 200 else markdown,
        })
    
    return {
        "job_id": job_id,
        "job_status": job.get("status"),
        "job_progress": job.get("progress"),
        "completed_at": job.get("completed_at"),
        "sections_count": len(sections_raw),
        "sections_debug": sections_debug,
        "has_result_json": bool(job.get("result_json")),
        "has_markdown": bool(job.get("markdown")),
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”¥ ê³ ì • ê²½ë¡œ ë¨¼ì €
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.post("/start")
async def start_report(
    payload: ReportStartRequest,
    background_tasks: BackgroundTasks,
    request: Request
):
    """ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘"""
    input_data = {
        "name": payload.name,
        "question": payload.question,
        "concern_type": payload.concern_type,
        "target_year": payload.target_year,
        "survey_data": payload.survey_data,
        "saju_result": payload.saju_result,
        "year_pillar": payload.year_pillar,
        "month_pillar": payload.month_pillar,
        "day_pillar": payload.day_pillar,
        "hour_pillar": payload.hour_pillar,
        "gender": payload.gender,
        "birth_info": payload.birth_info,
    }
    
    supabase = get_supabase()
    
    if supabase and supabase.is_available():
        try:
            job = await supabase.create_job(
                email=payload.email,
                name=payload.name,
                input_data=input_data,
                target_year=payload.target_year
            )
            job_id = job["id"]
            public_token = job.get("public_token")
            
            logger.info(f"[Reports] Job ìƒì„±: {job_id}")
            
            # ì„¹ì…˜ ì´ˆê¸°í™”
            try:
                await supabase.init_sections(job_id, SECTION_SPECS)
            except Exception as e:
                logger.warning(f"ì„¹ì…˜ ì´ˆê¸°í™” ìŠ¤í‚µ: {e}")
            
            # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
            rulestore = getattr(request.app.state, "rulestore", None)
            background_tasks.add_task(run_report_job, job_id, rulestore)
            
            # ğŸ”¥ P0: í‘œì¤€í™”ëœ ì‘ë‹µ
            return {
                "success": True,
                "job_id": job_id,
                "token": public_token,
                "status": "queued",
                "message": "ë¦¬í¬íŠ¸ ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "view_url": f"https://sajuos.com/report/{job_id}?token={public_token}",
                "full_view_url": f"https://sajuos.com/report/{job_id}?token={public_token}&view=full",
            }
        except Exception as e:
            logger.error(f"Job ìƒì„± ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail=str(e)[:300])
    else:
        temp_id = str(uuid.uuid4())
        return {
            "success": True,
            "job_id": temp_id,
            "status": "queued",
            "message": "ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ (Supabase ë¯¸ì—°ê²°)",
        }


@router.get("/start")
async def start_report_get():
    """GET /startëŠ” ì§€ì›í•˜ì§€ ì•ŠìŒ"""
    return {"error": "Use POST method", "method": "POST /api/reports/start"}


@router.get("/sections-info")
async def get_sections_info():
    """ì„¹ì…˜ ì •ë³´"""
    return {"sections": SECTION_SPECS}


@router.get("/view/{job_id}")
async def view_report(job_id: str, token: str = Query(..., description="Access token")):
    """
    ğŸ”¥ğŸ”¥ğŸ”¥ P0 í•µì‹¬: job + sections(order ì •ë ¬) + full_markdown ë°˜í™˜
    ì¤‘ë³µ ë°©ì§€: job_idë¡œ í•„í„°ë§ëœ ì„¹ì…˜ë§Œ ë°˜í™˜
    """
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id format: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    # 1) token ê²€ì¦
    is_valid, job = await supabase.verify_job_token(job_id, token)
    
    if not is_valid or not job:
        raise HTTPException(status_code=404, detail="Invalid token or job not found")
    
    # 2) ğŸ”¥ P0: sections ì¡°íšŒ (order ì •ë ¬) - job_idë¡œ í•„í„°ë§ í™•ì‹¤íˆ
    sections_raw = await supabase.get_sections_ordered(job_id)
    
    # ğŸ”¥ P0: ì¤‘ë³µ ë°©ì§€ - job_idê°€ ì¼ì¹˜í•˜ëŠ”ì§€ ì¬í™•ì¸
    sections_raw = [s for s in sections_raw if s.get("job_id") == job_id]
    
    # 3) ì„¹ì…˜ ì •ê·œí™”
    sections_normalized = [normalize_section(s) for s in sections_raw]
    
    # 4) ğŸ”¥ P0: completedì¸ë° ì„¹ì…˜ ë¹„ë©´ ê²½ê³ 
    if job.get("status") == "completed":
        empty_sections = [s["section_id"] for s in sections_normalized if len(s.get("markdown", "")) < 100]
        if empty_sections:
            logger.error(f"[Reports] âš ï¸ COMPLETEDì¸ë° ë¹ˆ ì„¹ì…˜: {job_id} | {empty_sections}")
            logger.error(f"[Reports] ì„¹ì…˜ ê°œìˆ˜: {len(sections_normalized)} | Job: {job_id}")
    
    # 5) full_markdown ìƒì„±
    input_json = job.get("input_json") or {}
    name = input_json.get("name", "ê³ ê°")
    target_year = input_json.get("target_year", 2026)
    full_markdown = build_full_markdown(sections_normalized, name, target_year)
    
    # 6) saju_result.quality ê¸°ë³¸ê°’
    saju_result = input_json.get("saju_result") or {}
    if "quality" not in saju_result:
        saju_result["quality"] = {}
    
    quality_defaults = {
        "solar_term_boundary": None,
        "has_birth_time": bool(saju_result.get("saju", {}).get("hour_pillar")),
        "accuracy": "MEDIUM",
        "notes": [],
    }
    for key, default_val in quality_defaults.items():
        if key not in saju_result["quality"]:
            saju_result["quality"][key] = default_val
    
    input_json["saju_result"] = saju_result
    
    # ğŸ”¥ P0 FIX: ready í”Œë˜ê·¸ ê³„ì‚° (ë¹ˆ ë³¸ë¬¸ ë…¸ì¶œ ë°©ì§€)
    completed_sections = len([s for s in sections_normalized if len(s.get("markdown", "")) >= 200])
    total_markdown_length = sum(len(s.get("markdown", "")) for s in sections_normalized)
    is_ready = completed_sections >= 1 and total_markdown_length >= 500
    
    # 7) ì‘ë‹µ ë°˜í™˜
    logger.info(f"[Reports] view_report: {job_id} | sections={len(sections_normalized)} | markdown_length={len(full_markdown)} | ready={is_ready}")
    
    return {
        "job": {
            "id": job["id"],
            "status": job.get("status"),
            "progress": job.get("progress", 0),
            "result_json": job.get("result_json"),
            "completed_at": job.get("completed_at"),
            "error": job.get("error"),
            "target_year": input_json.get("target_year"),  # ğŸ”¥ P0: target_year ì¶”ê°€
        },
        "input": input_json,
        "sections": sections_normalized,
        "full_markdown": full_markdown,
        "section_count": len(sections_normalized),
        "ready": is_ready,  # ğŸ”¥ P0: ì½˜í…ì¸  ì¤€ë¹„ ì™„ë£Œ ì—¬ë¶€
        "completed_section_count": completed_sections,  # ğŸ”¥ P0: ì‹¤ì œ ì™„ë£Œëœ ì„¹ì…˜ ìˆ˜
    }


@router.get("/verify/{job_id}")
async def verify_token(job_id: str, token: str = Query(..., description="Access token")):
    """job_id + token ê²€ì¦"""
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id format: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    is_valid, job = await supabase.verify_job_token(job_id, token)
    
    if not is_valid:
        raise HTTPException(status_code=403, detail="Invalid token")
    
    return {
        "valid": True,
        "job_id": job["id"],
        "status": job.get("status"),
        "progress": job.get("progress", 0),
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”¥ ë™ì  ê²½ë¡œëŠ” ë§ˆì§€ë§‰ì—
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.get("/{job_id}/status")
async def get_job_status(job_id: str):
    """í´ë§ìš© ìƒíƒœ ì¡°íšŒ"""
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id format: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        return {"job_id": job_id, "status": "unknown", "progress": 0}
    
    try:
        job = await supabase.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")
        
        sections_data = await supabase.get_sections(job_id)
        completed = len([s for s in sections_data if s.get("status") in ("completed", "done", "success")])
        progress = max(job.get("progress", 0), int((completed / 7) * 100))
        
        return {
            "job_id": job_id,
            "status": job.get("status", "unknown"),
            "progress": progress,
            "sections": [{"id": s.get("section_id"), "status": s.get("status")} for s in sections_data],
            "error": job.get("error"),
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e)[:200])


@router.get("/{job_id}")
async def get_report_status(job_id: str, token: Optional[str] = Query(None)):
    """í´ë§ìš© ìƒíƒœ ì¡°íšŒ"""
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id format: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        return {"job_id": job_id, "status": "unknown", "progress": 0}
    
    try:
        if token:
            is_valid, job = await supabase.verify_job_token(job_id, token)
            if not is_valid:
                raise HTTPException(status_code=403, detail="Invalid token")
        else:
            job = await supabase.get_job(job_id)
        
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")
        
        sections_data = await supabase.get_sections(job_id)
        
        return {
            "job_id": job_id,
            "status": job.get("status", "unknown"),
            "progress": job.get("progress", 0),
            "sections": [{"id": s.get("section_id"), "status": s.get("status")} for s in sections_data],
            "error": job.get("error"),
            "result": job.get("result_json") if job.get("status") == "completed" else None,
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e)[:200])


@router.get("/{job_id}/result")
async def get_report_result(job_id: str, token: Optional[str] = Query(None)):
    """
    ğŸ”¥ğŸ”¥ğŸ”¥ P0 í•µì‹¬: /result - ì„¹ì…˜ orderëŒ€ë¡œ ì •ë ¬ + full_markdown ìƒì„±
    ì¤‘ë³µ ë°©ì§€: job_idë¡œ í•„í„°ë§ëœ ì„¹ì…˜ë§Œ ë°˜í™˜
    """
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    if token:
        is_valid, job = await supabase.verify_job_token(job_id, token)
        if not is_valid:
            raise HTTPException(status_code=403, detail="Invalid token")
    else:
        job = await supabase.get_job(job_id)
    
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")
    
    if job.get("status") != "completed":
        return {"completed": False, "status": job.get("status"), "progress": job.get("progress", 0)}
    
    # ğŸ”¥ P0: sections ì¡°íšŒ (order ì •ë ¬) - job_idë¡œ í•„í„°ë§ í™•ì‹¤íˆ
    sections_raw = await supabase.get_sections_ordered(job_id)
    
    # ğŸ”¥ P0: ì¤‘ë³µ ë°©ì§€ - job_idê°€ ì¼ì¹˜í•˜ëŠ”ì§€ ì¬í™•ì¸
    sections_raw = [s for s in sections_raw if s.get("job_id") == job_id]
    
    # ì„¹ì…˜ ì •ê·œí™”
    sections_normalized = [normalize_section(s) for s in sections_raw]
    
    # ğŸ”¥ P0: completedì¸ë° ì„¹ì…˜ ë¹„ë©´ ê²½ê³  (500ì€ ë„ˆë¬´ ê³¼í•¨)
    empty_sections = [s["section_id"] for s in sections_normalized if len(s.get("markdown", "")) < 100]
    if empty_sections:
        logger.error(f"[Reports] âš ï¸ COMPLETEDì¸ë° ë¹ˆ ì„¹ì…˜: {job_id} | {empty_sections}")
        logger.error(f"[Reports] ì„¹ì…˜ ê°œìˆ˜: {len(sections_normalized)} | Job: {job_id}")
        # ê²½ê³ ë§Œ ë‚¨ê¸°ê³  ì§„í–‰
    
    # full_markdown ìƒì„±
    input_json = job.get("input_json") or {}
    name = input_json.get("name", "ê³ ê°")
    target_year = input_json.get("target_year", 2026)
    full_markdown = build_full_markdown(sections_normalized, name, target_year)
    
    logger.info(f"[Reports] get_report_result: {job_id} | sections={len(sections_normalized)} | markdown_length={len(full_markdown)}")
    
    return {
        "completed": True,
        "job": {
            "id": job["id"],
            "status": job.get("status"),
            "completed_at": job.get("completed_at"),
            "result_json": job.get("result_json"),
        },
        "input": input_json,
        "sections": sections_normalized,
        "full_markdown": full_markdown,
        "section_count": len(sections_normalized),
        "result": job.get("result_json"),
        "markdown": full_markdown,
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

async def run_report_job(job_id: str, rulestore):
    """ë°±ê·¸ë¼ìš´ë“œ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        from app.services.report_worker import report_worker
        await report_worker.run_job(job_id, rulestore)
    except Exception as e:
        logger.error(f"Report job ì‹¤íŒ¨: {job_id} | {e}")
        supabase = get_supabase()
        if supabase:
            try:
                await supabase.fail_job(job_id, str(e))
            except:
                pass
